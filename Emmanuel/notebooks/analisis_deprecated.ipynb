{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis deprecated\n",
    "aca figuran analisis hechos que no fueron incluidos en el analisis final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the os package\n",
    "import os\n",
    "\n",
    "# Confirm the current working directory \n",
    "os.getcwd()\n",
    "\n",
    "# Use '\\\\' while changing the directory \n",
    "os.chdir(\"C:\\\\Users\\someo\\Downloads\\Review_EDA_Emotion_Recognition\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparacion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Liberias y DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar librerias a usar\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pycountry\n",
    "import plotly.express as px\n",
    "import zepid\n",
    "from zepid.graphics import EffectMeasurePlot\n",
    "import networkx as nx\n",
    "from numpy import genfromtxt\n",
    "\n",
    "#Creación de data frames a usar\n",
    "df_metadata = pd.read_csv('.\\data\\Tabla Normalizada - Metadata.csv')\n",
    "df_data_type = pd.read_csv('.\\data\\Tabla Normalizada - Data type.csv')\n",
    "df_participants = pd.read_csv('.\\data\\Tabla Normalizada - Participants.csv')\n",
    "df_self_report = pd.read_csv('.\\data\\Tabla Normalizada - Self report.csv')\n",
    "df_emotion_elicitation_techniques = pd.read_csv('.\\data\\Tabla Normalizada - Emotion elicitation techniques.csv')\n",
    "df_eda = pd.read_csv('.\\data\\Tabla Normalizada - EDA.csv')\n",
    "df_statistical_learning_models = pd.read_csv('.\\data\\Tabla Normalizada - Statistical Learning model.csv')\n",
    "df_performances = pd.read_csv('.\\data\\Tabla Normalizada - Performances.csv')\n",
    "df_alg_perf = pd.read_csv('.\\data\\Tabla Normalizada - Alg_Perf.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set características generales de los gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [20, 10]\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette('colorblind')\n",
    "\n",
    "plt.rcParams[\"legend.fontsize\"] = 15\n",
    "plt.rcParams[\"xtick.labelsize\"] = 15\n",
    "plt.rcParams[\"ytick.labelsize\"] = 15\n",
    "plt.rcParams[\"axes.labelsize\"] = 15\n",
    "plt.rcParams[\"axes.titlesize\"] = 20"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_reversing(df,col_id, col_values):\n",
    "    \"\"\"la funcion toma nos da la frecuencia de los datos distribuidos en distintas columnas.\n",
    "    Toma una variable distribuida en varias columnas (one hot encoding), y aplica la funcion melt para cambiar el formato\n",
    "    de la tabla a long. Luego devuelve una columna donde aparece el nombre de cada columna, la cantidad de veces que fue\n",
    "    marcada con una 'x' (si accuracy fue marcada 50 veces, aparecera el str 'accuracy' 50 veces, lo que permite graficar su frecuencia\n",
    "    de aparicion)\n",
    "\n",
    "    Args:\n",
    "        df (dataframe): dataframe con el que se desea trabajar, debe poseer las columnas de id_vars y list_value_vars\n",
    "        in_id_vars (str): nombre de la columna que se usa como identificador de variables \n",
    "        value_vars (str o lista): str o lista con el nombre de las columnas de las cuales se desea obtener los datos (se puede\n",
    "        obviamente subsetear (p.e. dataframe.iloc['columna_1',...,columna_n']))\n",
    "\n",
    "    Returns:\n",
    "        dataframe: _description_\n",
    "    \"\"\"\n",
    "    df_raw = pd.melt(df, id_vars = col_id, value_vars = col_values)\n",
    "    return df_raw[df_raw.value == 'x']\n",
    "\n",
    "def multi_reversing_n(df,col_id, col_values):\n",
    "    \"\"\"exactamente lo mismo que multi_reversing, solo que para casos donde lo que se busca es un numero y no una x\n",
    "    \"\"\"\n",
    "    df_raw = pd.melt(df, id_vars = col_id, value_vars = col_values)\n",
    "    return df_raw[df_raw.value != 0]\n",
    "\n",
    "def bar_plot(col, data, titulos):\n",
    "    var_x = col\n",
    "    df = data\n",
    "    g = sns.countplot(x=var_x, data=df, order = getattr(df, var_x).value_counts().index)\n",
    "    g.set(title = titulos[0], xlabel = titulos[1], ylabel = titulos[2])\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()\n",
    "\n",
    "def t_student(x,y):\n",
    "\tprint('Students t-test')\n",
    "\tfrom scipy.stats import ttest_ind\n",
    "\tstat, p = ttest_ind(x, y, alternative = 'greater')\n",
    "\tprint('stat=%.3f, p=%.3f' % (stat, p))\n",
    "\tif p > 0.05:\n",
    "\t\tprint('Probably the same distribution')\n",
    "\telse:\n",
    "\t\tprint('Probably different distributions')\n",
    "\n",
    "def mann_whitney_u(x,y):\n",
    "\tprint('Mann-Whitney U Test')\n",
    "\tfrom scipy.stats import mannwhitneyu\n",
    "\tstat, p = mannwhitneyu(x, y, alternative = 'greater')\n",
    "\tprint('stat=%.3f, p=%.3f' % (stat, p))\n",
    "\tif p > 0.05:\n",
    "\t\tprint('Probably the same distribution')\n",
    "\telse:\n",
    "\t\tprint('Probably different distributions')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graficos exploratorios"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Análisis estadístico para determinar si modelos de detección de arousal performan mejor que los basados en valence (Algoritmos de clasificación)\n",
    "- Procedimiento: subsetear para quedarnos con modelos dimensionales(columna affective model), quedarse solo con clasificación binarias (LA,HA/LV,HV), quedarse con la medida de performance que mas aparezca. hacer el test estadístico correspondiente (t, wettney, etc), que depende del supuesto (si hay normalidad se aplica paramétrico, sino no-parametrico).\n",
    "- Resultado: no existe diferencia estadisticamente significativa entre grupos, por lo que los algoritmos clasificadores basados en modelos dimensionales de clasificacion binaria (HA/LA, HV/LV) no performan mejor uno sobre otros (Segun t de student y u de mann-whitney).\n",
    "- Tener en cuenta el tamaño de la muestra que cumple con todos los criterios mencionados en el Procedimiento: poco mas de 35 modelos en total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creacion data frame y subseteo por: modelos dimensionales, tipo clasiffier, categorias HA/LA y HV/LV\n",
    "df_alg_perf = df_alg_perf.fillna(0)\n",
    "df_2 = df_alg_perf\n",
    "df_2 = df_2[df_2['affective_model'] == 'dimensional']\n",
    "df_2 = df_2[df_2['is_classifier'].isin(['x', 'X'])]\n",
    "df_2 = df_2[df_2['class_model_output_categories'].isin(['HA, LA', 'HV, LV'])]\n",
    "\n",
    "df2_performance_medidas = multi_reversing_n(df_2, 'model_id',df_2.iloc[:,57:])\n",
    "\n",
    "titulos = ['Algoritmos mas usados para modelos de clasificacion dimensionales (inputs HA, LA y HV, LV)', 'Medida de performance', 'Cantidad de modelos']\n",
    "bar_plot('variable',df2_performance_medidas,titulos)\n",
    "\n",
    "#subseteo por la medida de performance que mas aparece (accuracy)\n",
    "df_2 = df_2.fillna('-')\n",
    "df_2 = df_2[df_2['accuracy'] != '-']\n",
    "\n",
    "#print(df_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos los estadísticos\n",
    "\n",
    "obtenido de: https://machinelearningmastery.com/statistical-hypothesis-tests-in-python-cheat-sheet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creacion lista con la performance para arousal y valence\n",
    "df_arousal = df_2[df_2['class_model_output_categories'] == 'HA, LA']\n",
    "df_arousal = df_arousal['accuracy']\n",
    "arousal1 = df_arousal.values.tolist()\n",
    "arousal1 = list(map(float, arousal1))\n",
    "\n",
    "df_valence = df_2[df_2['class_model_output_categories'] == 'HV, LV']\n",
    "df_valence = df_valence['accuracy']\n",
    "valence1 = df_valence.values.tolist()\n",
    "valence1 = list(map(float, valence1))\n",
    "\n",
    "#print(arousal1, valence1)\n",
    "\n",
    "#Test parametrico - t de student\n",
    "t_student(arousal1, valence1)\n",
    "\n",
    "#Test no parametrico - U de Mann-Whitney\n",
    "mann_whitney_u(arousal1, valence1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graficos extra"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Frecuencia de papers por tipo de source (conference, journal, pre-print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metadata=df_metadata.fillna('-')\n",
    "df_metadata_sin_duplicates = df_metadata.drop_duplicates(subset='paper_id')\n",
    "\n",
    "df_sources = df_metadata_sin_duplicates.iloc[:,7:10]\n",
    "def get_value(row):\n",
    "     for c in df_sources.columns:\n",
    "         if row[c]== 'x':\n",
    "             return c\n",
    "\n",
    "df_sources = df_sources.apply(get_value, axis=1)\n",
    "df_sources = pd.DataFrame(df_sources)\n",
    "df_sources.columns = ['Source type']\n",
    "\n",
    "#ploteo\n",
    "quantity = df_sources['Source type'].value_counts()\n",
    "df_quantity = pd.DataFrame(quantity)\n",
    "\n",
    "\n",
    "sns.countplot(x='Source type', data=df_sources)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pie plot\n",
    "\n",
    "names = 'Journal', 'Conference', 'Pre-print'\n",
    "plt.pie(df_quantity['Source type'], labels = names, labeldistance = 1.15, wedgeprops = { 'linewidth' : 3, 'edgecolor' : 'white' })\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Gráfico de barras papers por país y continente\n",
    "Interpretación: primacía de trabajos provenientes de China y Asia. Seguidos estos por trabajos europeos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paises = df_metadata_sin_duplicates[\"first_author_country_affiliation\"].unique()\n",
    "\n",
    "countries = df_metadata_sin_duplicates.pivot_table(columns=['first_author_country_affiliation'], aggfunc='size')\n",
    "df_countries = pd.DataFrame(countries)\n",
    "\n",
    "order = ['China','USA', 'Germany', 'India','Turkey','Italy', 'Malaysia','Spain','Iran', 'Switzerland','Romania','Pakistan', 'Taiwan','Greece', 'Japan',\n",
    "'Austria', 'Tunisia','Macedonian', 'Finland', 'Slovenia', 'Portugal', 'Korea',\n",
    "'UK', 'Indonesia','Canada', 'France', 'Lithuania', \n",
    "'Egypt','Colombia', 'Australia', 'Poland']\n",
    "\n",
    "df_countries.loc[order].plot(kind='bar', title='Cantidad de papers por país', xlabel='country', ylabel='paper quantity')\n",
    "plt.show()\n",
    "\n",
    "#Papers por continente - plot\n",
    "papers_continents = {'continents' : ['Asia', 'Europa','America','Africa','Australia'],\n",
    "'quantity' : [49, 39, 9, 3, 1]}\n",
    "df_continents = pd.DataFrame(papers_continents)\n",
    "print(df_continents)\n",
    "\n",
    "df_continents.set_index('continents').plot(kind='bar', title='Cantidad de papers por continente', xlabel='continent', ylabel='paper quantity')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pycountry.countries.get(name=\"spain\")#ESP\n",
    "\n",
    "#df_countries.loc[order].plot(kind='bar', title='Cantidad de papers por país', xlabel='country', ylabel='paper quantity')\n",
    "#plt.show()\n",
    "\n",
    "#df_paises = pd.read_excel('c:\\\\Users\\\\LENOVO\\\\Downloads\\\\Review_EDA_Emotion_Recognition\\\\EMMA\\\\data\\\\cleaned\\\\Paises.xlsx')\n",
    "df_countries1 = df_countries.index\n",
    "\n",
    "def get_alpha_3(location):\n",
    "    try:\n",
    "        return pycountry.countries.get(name=location).alpha_3\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "df_countries.reset_index(inplace = True, drop = True)\n",
    "df_countries['country'] = df_countries1\n",
    "\n",
    "\n",
    "\n",
    "df_countries = df_countries.replace('Korea','Korea, Republic of')\n",
    "df_countries = df_countries.replace('Iran','Iran, Islamic Republic of')\n",
    "df_countries = df_countries.replace('UK','United Kingdom')\n",
    "df_countries = df_countries.replace('USA','United States')\n",
    "df_countries = df_countries.replace('Macedonian','North Macedonia')\n",
    "\n",
    "df_countries[\"code\"] = df_countries[\"country\"].apply(lambda x: get_alpha_3(x))\n",
    "\n",
    "fig = px.choropleth(df_countries,\n",
    "                    locations=\"code\",\n",
    "                    color=0,\n",
    "                    hover_name=\"country\",\n",
    "                    title = \"Cantidad de papers por pais\")\n",
    "\n",
    "#fig.show()\n",
    "\n",
    "#CSV archive to Tableau\n",
    "df_countries.to_csv(\".\\data\\Countries.csv\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Grafico base de datos, privadas y composicion de publicas\n",
    "\n",
    "Incluir en un grafico, dentro de las bases de datos publicas, cada base de dato publica (AMIGOS, MAHNOB, etc.)\n",
    "\n",
    "* cantidad total bases de datos: 101 (igual que la cantidad de papers, suponiendo que es solo un uso de base de datos por paper, que los papers 37 y 62 no siguen)\n",
    "    * db privada: 58\n",
    "    * db databases: 38\n",
    "        * DEAP 10\n",
    "        * MAHNOB 7\n",
    "        * AMIGOS 7\n",
    "        * PMEmo 3\n",
    "        * Ascertein 2\n",
    "        * RECOLA 2\n",
    "        * Otros 7\n",
    "    * db publica: 3\n",
    "    * db uppon request: 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teniendo en cuenta la divergencia de los papers 37 y 62\n",
    "\n",
    "* cantidad total bases de datos: 107 (101 + 6)\n",
    "    * db privada: 58\n",
    "    * db databases: 44\n",
    "        * DEAP 11\n",
    "        * MAHNOB 9\n",
    "        * AMIGOS 8\n",
    "        * PMEmo 3\n",
    "        * Ascertein 2\n",
    "        * RECOLA 2\n",
    "        * Otros 9\n",
    "    * db publica: 3\n",
    "    * db uppon request: 1\n",
    "\n",
    "Gráfico realizado en Tableau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rellenar datos faltantes y dropeo de duplicados\n",
    "df_data_type=df_data_type.fillna('-')\n",
    "df_data_type_sin_duplicates = df_data_type.drop_duplicates(subset='paper_id')\n",
    "\n",
    "df_db_types = df_data_type_sin_duplicates.iloc[:,6:11]\n",
    "print(df_db_types)\n",
    "def get_value(row):\n",
    "     for c in df_db_types.columns:\n",
    "         if row[c]== 'x':\n",
    "             return c\n",
    "\n",
    "df_db_types = df_db_types.apply(get_value, axis=1)\n",
    "df_db_types = pd.DataFrame(df_db_types)\n",
    "df_db_types.columns = ['Database type']\n",
    "\n",
    "#ploteo\n",
    "g = sns.countplot(x='Database type', data=df_db_types)\n",
    "g.set(title = 'Frecuencia de tipo de base de datos', xlabel = 'Tipo de base de datos', ylabel = 'Cantidad')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "print(df_db_types.value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Análisis estadístico para determinar si modelos de detección de arousal performan mejor que los basados en valence (Algoritmos de regresión)\n",
    "* Procedimiento: subsetear para quedarnos con modelos dimensionales(columna affective model), subsetear con regressor, donde nos quedamos solo con las dimensiones que sean arousal/valence, quedarse con la medida de perforrmace que mas aparezca (count), hacer el test estadístico correspondiente (t, wettney, etc)\n",
    "* Resultado: no existe diferencia estadisticamente significativa entre grupos, por lo que los algoritmos de regresión basados en modelos dimensionales (basados en arousal o valence) no performan mejor uno sobre otros (Segun t de student y u de mann-whitney).\n",
    "* Tener en cuenta el tamaño de la muestra que cumple con todos los criterios mencionados en el Procedimiento: 16 modelos en total.\n",
    "* **Revision**, la obtencion con get_value no funciona, de todas formas RMSE es el algoritmo mas usado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creacion del data frames, y subseteo por: modelos dimensionales, tipo regressor, dimensiones arousal/valence\n",
    "df = df_alg_perf\n",
    "df = df[df['affective_model'] == 'dimensional']\n",
    "df = df[df['is_regressor'].isin(['x', 'X'])]\n",
    "df = df[df['regre_model_output_dimensions'].isin(['arousal', 'valence'])]\n",
    "\n",
    "#que medida de performance mas aparece?\n",
    "#dataframe con performances\n",
    "df_performance_medidas = df.iloc[:,58:]\n",
    "\n",
    "#print(df_performance_medidas)\n",
    "\n",
    "#busqueda de la medida de performance mas recurrente, paso de los valores a 0 y 1 para facilitar su conteo\n",
    "df_performance_medidas = df_performance_medidas.fillna('No')\n",
    "df_performance_medidas = df_performance_medidas.replace('-', 'No')\n",
    "df_performance_medidas=df_performance_medidas.mask(df_performance_medidas != 'No','Yes')\n",
    "\n",
    "#obtener performance mas frecuente\n",
    "def get_value(row):\n",
    "    for c in df_performance_medidas.columns:\n",
    "        if row[c] == 'Yes':\n",
    "            return c\n",
    "\n",
    "df_performance_medidas = df_performance_medidas.apply(get_value, axis=1)\n",
    "df_performance_medidas = pd.DataFrame(df_performance_medidas)\n",
    "df_performance_medidas.columns = ['Performances']\n",
    "\n",
    "sns.countplot(x='Performances', data=df_performance_medidas)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "#subseteo por la medida de performance que mas aparece (RMSE)\n",
    "df = df.fillna('-')\n",
    "df = df[df['Root-Mean-Square-Error-(RMSE)'] != '-']\n",
    "\n",
    "print(df)\n",
    "#la muestra es de 16 modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_arousal = df[df['regre_model_output_dimensions'] == 'arousal']\n",
    "df_arousal = df_arousal['Root-Mean-Square-Error-(RMSE)']\n",
    "arousal = df_arousal.values.tolist()\n",
    "arousal = list(map(float, arousal))\n",
    "\n",
    "df_valence = df[df['regre_model_output_dimensions'] == 'valence']\n",
    "df_valence = df_valence['Root-Mean-Square-Error-(RMSE)']\n",
    "valence = df_valence.values.tolist()\n",
    "valence = list(map(float, valence))\n",
    "\n",
    "#Test parametrico - t de student\n",
    "print('Students t-test')\n",
    "from scipy.stats import ttest_ind\n",
    "stat, p = ttest_ind(arousal, valence, alternative = 'greater')\n",
    "print('stat=%.3f, p=%.3f' % (stat, p))\n",
    "if p > 0.05:\n",
    "\tprint('Probably the same distribution')\n",
    "else:\n",
    "\tprint('Probably different distributions')\n",
    "\n",
    "\n",
    "#Test no parametrico - U de Mann-Whitney\n",
    "print('Mann-Whitney U Test')\n",
    "from scipy.stats import mannwhitneyu\n",
    "stat, p = mannwhitneyu(arousal, valence, alternative = 'greater')\n",
    "print('stat=%.3f, p=%.3f' % (stat, p))\n",
    "if p > 0.05:\n",
    "\tprint('Probably the same distribution')\n",
    "else:\n",
    "\tprint('Probably different distributions')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  (obsoleto) Cambios, teniendo en cuenta los resultados obtenidos en el analisis exploratorio y estadistico anterior\n",
    "\n",
    "* Se partia del analisis hecho primeramente, sobre que la medida mas usada era UAR, y los papers sacados aca no corresponden con los que podrian ser ahora que se sabe cual es la mas frecuente (accuracy). Para actualizarse esta parte debe tenerse en cuenta eso.\n",
    "* Nos quedamos solo con los modelos de clasificacion, y tenemos en cuenta los papers que posean ambos (High y Low para arousal y valencia)\n",
    "* Solamente se dropearon dos papers, que testeaban solo modelos o de valencia o de arousal. Con esto se prosiguió con el análisis estadístico y los resultados fueron los mismos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "papers_titles = title_dimensions.drop_duplicates(subset='apa_citation')\n",
    "\n",
    "#print(title_dimensions)\n",
    "#Kołodziej, M., Tarnowski, P., Majkowski, A., &...   vuela\n",
    "#Greco, A., Marzi, C., Lanata, A., Scilingo, E.\n",
    "\n",
    "df_arousal = df_3[df_3['class_model_output_categories'] == 'HA, LA']\n",
    "df_arousal = df_arousal['accuracy']\n",
    "arousal = df_arousal.values.tolist()\n",
    "arousal = list(map(float, arousal))\n",
    "\n",
    "df_valence = df_3[df_3['class_model_output_categories'] == 'HV, LV']\n",
    "df_valence = df_valence['accuracy']\n",
    "valence = df_valence.values.tolist()\n",
    "valence = list(map(float, valence))\n",
    "\n",
    "#Test parametrico - t de student\n",
    "print('Students t-test')\n",
    "from scipy.stats import ttest_ind\n",
    "stat, p = ttest_ind(arousal, valence, alternative = 'greater')\n",
    "print('stat=%.3f, p=%.3f' % (stat, p))\n",
    "if p > 0.05:\n",
    "\tprint('Probably the same distribution')\n",
    "else:\n",
    "\tprint('Probably different distributions')\n",
    "\n",
    "\n",
    "#Test no parametrico - U de Mann-Whitney\n",
    "print('Mann-Whitney U Test')\n",
    "from scipy.stats import mannwhitneyu\n",
    "stat, p = mannwhitneyu(arousal, valence, alternative = 'greater')\n",
    "print('stat=%.3f, p=%.3f' % (stat, p))\n",
    "if p > 0.05:\n",
    "\tprint('Probably the same distribution')\n",
    "else:\n",
    "\tprint('Probably different distributions')\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo mismo pero con HAHV, HALV, LAHV, LALV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#creacion data frame y subseteo por: modelos dimensionales, tipo clasiffier, categorias HA/LA y HV/LV\n",
    "df_hvlv_hala = df_alg_perf\n",
    "df_hvlv_hala = df_hvlv_hala[df_hvlv_hala['affective_model'] == 'dimensional']\n",
    "df_hvlv_hala = df_hvlv_hala[df_hvlv_hala['is_classifier'].isin(['x', 'X'])]\n",
    "df_hvlv_hala = df_hvlv_hala[df_hvlv_hala['class_model_output_categories'].isin(['HAHV, HALV, LAHV, LALV'])]\n",
    "\n",
    "#que medida de performance mas aparece en este grupo?\n",
    "#dataframe con performances\n",
    "title_dimensions_hvlv_hala = df_hvlv_hala[['apa_citation', 'class_model_output_categories']]\n",
    "\n",
    "df_hvlv_hala_performances = df_hvlv_hala.iloc[:,58:]\n",
    "df_hvlv_hala_performances = df_hvlv_hala_performances.fillna('-')\n",
    "\n",
    "#subseteo por la medida de performance que mas aparece (accuracy)\n",
    "df_hvlv_hala = df_hvlv_hala[df_hvlv_hala['accuracy'] != '-']\n",
    "\n",
    "print(df_hvlv_hala)\n",
    "df_ayv = df_hvlv_hala[df_hvlv_hala['class_model_output_categories'] == 'HAHV, HALV, LAHV, LALV']\n",
    "df_ayv = df_ayv['accuracy']\n",
    "hvlv_hala = df_ayv.values.tolist()\n",
    "hvlv_hala = list(map(float, hvlv_hala))\n",
    "\n",
    "print(hvlv_hala)\n",
    "\n",
    "#Test parametrico - t de student\n",
    "print('Students t-test')\n",
    "from scipy.stats import ttest_ind\n",
    "stat, p = ttest_ind(arousal, valence, alternative = 'greater')\n",
    "print('stat=%.3f, p=%.3f' % (stat, p))\n",
    "if p > 0.05:\n",
    "\tprint('Probably the same distribution')\n",
    "else:\n",
    "\tprint('Probably different distributions')\n",
    "\n",
    "\n",
    "#Test no parametrico - U de Mann-Whitney\n",
    "print('Mann-Whitney U Test')\n",
    "from scipy.stats import mannwhitneyu\n",
    "stat, p = mannwhitneyu(arousal, valence, alternative = 'greater')\n",
    "print('stat=%.3f, p=%.3f' % (stat, p))\n",
    "if p > 0.05:\n",
    "\tprint('Probably the same distribution')\n",
    "else:\n",
    "\tprint('Probably different distributions')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frecuencia de medidas de performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_performances = df_performances.fillna('-')\n",
    "df_performances = df_performances.drop([df_performances.index[143],df_performances.index[144],df_performances.index[145]])\n",
    "df = multi_reversing_n(df_performances, 'model_id', df_performances.iloc[:,3:])\n",
    "df = df[df['value'] != '-']\n",
    "\n",
    "g = sns.countplot(x='variable', data=df, order=df.variable.value_counts().index)\n",
    "g.set(title = 'Medidas de performance por cantidad de observaciones (frecuencia de uso)', xlabel = 'Medida de performance', ylabel = 'Cantidad de modelos')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(base,medida):\n",
    "    performance = medida\n",
    "    dataframe = base[base['variable'] == performance]\n",
    "    dataframe = dataframe['value']\n",
    "\n",
    "    lst = dataframe.values.tolist()\n",
    "    lst = list(map(float, lst))\n",
    "    return lst\n",
    "\n",
    "f_measure = pd.DataFrame(func(df,'f-measure'))\n",
    "accuracy = pd.DataFrame(func(df,'accuracy'))\n",
    "#recall = pd.DataFrame(func(df,'recall-sensitivity-true_positive_rate'))\n",
    "precision = pd.DataFrame(func(df,'precision'))\n",
    "mae = pd.DataFrame(func(df,'MAE-(Mean-Absolute-Error)'))\n",
    "rmse = pd.DataFrame(func(df,'Root-Mean-Square-Error-(RMSE)'))\n",
    "spearman = pd.DataFrame(func(df,'Spearman’s-ranking-correlation'))\n",
    "uar = pd.DataFrame(func(df,'unweighted-average-recall-(UAR)'))\n",
    "ccc = pd.DataFrame(func(df,'Concordance-Correlation-Coefficient-(CCC)'))\n",
    "#specificity = pd.DataFrame(func(df,'specificity_true-negative-rate'))\n",
    "#false_pr = pd.DataFrame(func(df,'false-positive-rate'))\n",
    "roc_auc = pd.DataFrame(func(df,'roc-auc'))\n",
    "#false_negative_rate = pd.DataFrame(func(df,'false-negative-rate'))\n",
    "pearson = pd.DataFrame(func(df,'Pearson-Correlation Coefficient-(r)'))\n",
    "matthews = pd.DataFrame(func(df,'Matthews-Correlation-Coefficient'))\n",
    "r = pd.DataFrame(func(df,'R'))\n",
    "r2 = pd.DataFrame(func(df,'R2'))\n",
    "g_mean = pd.DataFrame(func(df,'G-mean-(Geometric-mean)'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performances = pd.DataFrame()\n",
    "\n",
    "performances['accuracy'] = pd.Series(accuracy.iloc[:,0])\n",
    "performances['f_measure'] = pd.Series(f_measure.iloc[:,0])\n",
    "#performances['recall'] = pd.Series(recall.iloc[:,0])\n",
    "performances['precision'] = pd.Series(precision.iloc[:,0])\n",
    "performances['mae'] = pd.Series(mae.iloc[:,0])\n",
    "performances['rmse'] = pd.Series(rmse.iloc[:,0])\n",
    "performances['spearman'] = pd.Series(spearman.iloc[:,0])\n",
    "performances['uar'] = pd.Series(uar.iloc[:,0])\n",
    "performances['ccc'] = pd.Series(ccc.iloc[:,0])\n",
    "#performances['specificity'] = pd.Series(specificity.iloc[:,0])\n",
    "#performances['false_pr'] = pd.Series(false_pr.iloc[:,0])\n",
    "performances['roc_auc'] = pd.Series(roc_auc.iloc[:,0])\n",
    "#performances['false_negative_rate'] = pd.Series(false_negative_rate.iloc[:,0])\n",
    "performances['pearson'] = pd.Series(pearson.iloc[:,0])\n",
    "performances['matthews'] = pd.Series(matthews.iloc[:,0])\n",
    "performances['r'] = pd.Series(r.iloc[:,0])\n",
    "performances['r2'] = pd.Series(r2.iloc[:,0])\n",
    "performances['g_mean'] = pd.Series(g_mean.iloc[:,0])\n",
    "\n",
    "performances = pd.melt(performances)\n",
    "performances = performances.fillna('-')\n",
    "performances = performances[performances['value'] != '-']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.boxplot(x='value', y='variable',data=performances,\n",
    "            whis=[0, 100], width=.6, palette=\"vlag\")\n",
    "sns.stripplot(x='value', y='variable',data=performances,\n",
    "              size=5, color=\".3\", linewidth=0)\n",
    "g.set(title = 'Comparacion performances de medidas de performance usadas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"accuracy = np.array(accuracy)\n",
    "f_measure = np.array(f_measure)\n",
    "#recall = np.array(recall)\n",
    "precision = np.array(precision)\n",
    "#Mean_ab_error = np.array(Mean_ab_error)\n",
    "print(\n",
    "    'accuracy:',np.mean(accuracy),', f-measure:',np.mean(f_measure),', recall:',np.mean(recall),', precision:',np.mean(precision),', mean absolute error:',np.mean(Mean_ab_error)\n",
    "    )\n",
    "list_performances = [np.mean(accuracy),np.mean(f_measure),np.mean(recall),np.mean(precision),np.mean(Mean_ab_error)]\n",
    "list_performances\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b2e637689e3f8b5962031bb00bd419bdecd681b5fd76726fb03d874837e7027d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
