{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis exploratorio de los datos\n",
    "\n",
    "https://stackoverflow.com/questions/38334296/reversing-one-hot-encoding-in-pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Liberias y DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importar librerias a usar\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pycountry\n",
    "import plotly.express as px\n",
    "import zepid\n",
    "from zepid.graphics import EffectMeasurePlot\n",
    "import networkx as nx\n",
    "from numpy import genfromtxt\n",
    "\n",
    "#Creación de data frames a usar\n",
    "df_metadata = pd.read_csv(\"c:\\\\Users\\\\LENOVO\\\\Downloads\\\\Review_EDA_Emotion_Recognition\\\\Emmanuel\\\\data\\\\cleaned\\\\Tabla Normalizada - Metadata.csv\")\n",
    "df_data_type = pd.read_csv('c:\\\\Users\\\\LENOVO\\\\Downloads\\\\Review_EDA_Emotion_Recognition\\\\Emmanuel\\\\data\\\\cleaned\\\\Tabla Normalizada - Data type.csv')\n",
    "df_participants = pd.read_csv('c:\\\\Users\\\\LENOVO\\\\Downloads\\\\Review_EDA_Emotion_Recognition\\\\Emmanuel\\\\data\\\\cleaned\\\\Tabla Normalizada - Participants.csv')\n",
    "df_self_report = pd.read_csv('c:\\\\Users\\\\LENOVO\\\\Downloads\\\\Review_EDA_Emotion_Recognition\\\\Emmanuel\\\\data\\\\cleaned\\\\Tabla Normalizada - Self report.csv')\n",
    "df_emotion_elicitation_techniques = pd.read_csv('c:\\\\Users\\\\LENOVO\\\\Downloads\\\\Review_EDA_Emotion_Recognition\\\\Emmanuel\\\\data\\\\cleaned\\\\Tabla Normalizada - Emotion elicitation techniques.csv')\n",
    "df_eda = pd.read_csv('c:\\\\Users\\\\LENOVO\\\\Downloads\\\\Review_EDA_Emotion_Recognition\\\\Emmanuel\\\\data\\\\cleaned\\\\Tabla Normalizada - EDA.csv')\n",
    "df_statistical_learning_models = pd.read_csv('c:\\\\Users\\\\LENOVO\\\\Downloads\\\\Review_EDA_Emotion_Recognition\\\\Emmanuel\\\\data\\\\cleaned\\\\Tabla Normalizada - Statistical Learning model.csv')\n",
    "df_performances = pd.read_csv('c:\\\\Users\\\\LENOVO\\\\Downloads\\\\Review_EDA_Emotion_Recognition\\\\Emmanuel\\\\data\\\\cleaned\\\\Tabla Normalizada - Performances.csv')\n",
    "df_alg_perf = pd.read_csv('c:\\\\Users\\\\LENOVO\\\\Downloads\\\\Review_EDA_Emotion_Recognition\\\\Emmanuel\\\\data\\\\cleaned\\\\Tabla Normalizada - Alg_Perf.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set tamaño de gráficos para todos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [20, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "savefig(fname, *, dpi='figure', format=None, metadata=None,\n",
    "        bbox_inches=None, pad_inches=0.1,\n",
    "        facecolor='auto', edgecolor='auto',\n",
    "        backend=None, **kwargs\n",
    "       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funciones milagrosas\n",
    "* multi_reversing = para casos donde un dato toma mas de valor, o en casos tipicos de one hot encoding (un dato toma un solo valor)\n",
    "* multi_reversing_n = mismo que el anterior, pero para numeros distintos de cero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_reversing(df,col_id, col_values):\n",
    "    \"\"\"la funcion toma nos da la frecuencia de los datos distribuidos en distintas columnas.\n",
    "    Toma una variable distribuida en varias columnas (one hot encoding), y aplica la funcion melt para cambiar el formato\n",
    "    de la tabla a long. Luego devuelve una columna donde aparece el nombre de cada columna, la cantidad de veces que fue\n",
    "    marcada con una 'x' (si accuracy fue marcada 50 veces, aparecera el str 'accuracy' 50 veces, lo que permite graficar su frecuencia\n",
    "    de aparicion)\n",
    "\n",
    "    Args:\n",
    "        df (dataframe): dataframe con el que se desea trabajar, debe poseer las columnas de id_vars y list_value_vars\n",
    "        in_id_vars (str): nombre de la columna que se usa como identificador de variables \n",
    "        value_vars (str o lista): str o lista con el nombre de las columnas de las cuales se desea obtener los datos (se puede\n",
    "        obviamente subsetear (p.e. dataframe.iloc['columna_1',...,columna_n']))\n",
    "\n",
    "    Returns:\n",
    "        dataframe: _description_\n",
    "    \"\"\"\n",
    "    df_raw = pd.melt(df, id_vars = col_id, value_vars = col_values)\n",
    "    return df_raw[df_raw.value == 'x']\n",
    "\n",
    "def multi_reversing_n(df,col_id, col_values):\n",
    "    \"\"\"exactamente lo mismo que multi_reversing, solo que para casos donde lo que se busca es un numero y no una x\n",
    "    \"\"\"\n",
    "    df_raw = pd.melt(df, id_vars = col_id, value_vars = col_values)\n",
    "    return df_raw[df_raw.value != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gráficos\n",
    "\n",
    "* La lista de los gráficos se encuentra en el README de esta carpeta (notebooks/README.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Gráfico de barra por año (2010-2020) por paper según modelos de emociones empleado (categoriales o dimensionales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rellenar datos faltantes y NO SE DROPEAN los duplicados (hay papers que usan multiples modelos)\n",
    "df_statistical_learning_models=df_statistical_learning_models.fillna('-')\n",
    "\n",
    "#ploteo\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_palette('colorblind')\n",
    "plt.rcParams[\"legend.fontsize\"] = 15\n",
    "plt.rcParams[\"xtick.labelsize\"] = 15\n",
    "plt.rcParams[\"ytick.labelsize\"] = 15\n",
    "plt.rcParams[\"axes.labelsize\"] = 15\n",
    "plt.rcParams[\"axes.titlesize\"] = 20\n",
    "\n",
    "category_order = [2010, 2011, 2012, 2013, 2014, 2015, 2015, 2016, 2017, 2018, 2019, 2020]\n",
    "g= sns.countplot(x='year', \n",
    "    data= df_statistical_learning_models, \n",
    "    hue='affective_model', \n",
    "    order=category_order)\n",
    "g.set(title = 'Cantidad de papers por año (2010 - 2020)', xlabel = 'Año', ylabel = 'Cantidad de papers')\n",
    "plt.savefig('c:\\\\Users\\\\LENOVO\\\\Downloads\\\\Review_EDA_Emotion_Recognition\\\\Emmanuel\\\\figures\\\\1. Cantidad de papers por año (2010-2020) segun tipo de modelo emocional.png')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Análisis estadístico para determinar si modelos de detección de arousal performan mejor que los basados en valence (Algoritmos de clasificación)\n",
    "- Procedimiento: subsetear para quedarnos con modelos dimensionales(columna affective model), quedarse solo con clasificación binarias (LA,HA/LV,HV), quedarse con la medida de performance que mas aparezca. hacer el test estadístico correspondiente (t, wettney, etc), que depende del supuesto (si hay normalidad se aplica paramétrico, sino no-parametrico).\n",
    "- Resultado: no existe diferencia estadisticamente significativa entre grupos, por lo que los algoritmos clasificadores basados en modelos dimensionales de clasificacion binaria (HA/LA, HV/LV) no performan mejor uno sobre otros (Segun t de student y u de mann-whitney).\n",
    "- Tener en cuenta el tamaño de la muestra que cumple con todos los criterios mencionados en el Procedimiento: poco mas de 35 modelos en total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creacion data frame y subseteo por: modelos dimensionales, tipo clasiffier, categorias HA/LA y HV/LV\n",
    "df_alg_perf = df_alg_perf.fillna(0)\n",
    "df_2 = df_alg_perf\n",
    "df_2 = df_2[df_2['affective_model'] == 'dimensional']\n",
    "df_2 = df_2[df_2['is_classifier'].isin(['x', 'X'])]\n",
    "df_2 = df_2[df_2['class_model_output_categories'].isin(['HA, LA', 'HV, LV'])]\n",
    "\n",
    "df2_performance_medidas = multi_reversing_n(df_2, 'model_id',df_2.iloc[:,58:])\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_palette('colorblind')\n",
    "g = sns.countplot(x='variable', data=df2_performance_medidas, order=df2_performance_medidas.variable.value_counts().index)\n",
    "g.set(title = 'Algoritmos mas usados para modelos de clasificacion dimensionales (inputs HA, LA y HV, LV)', xlabel = 'Algoritmo', ylabel = 'Cantidad de modelos')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "#subseteo por la medida de performance que mas aparece (accuracy)\n",
    "df_2 = df_2.fillna('-')\n",
    "df_2 = df_2[df_2['accuracy'] != '-']\n",
    "\n",
    "#print(df_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos los estadísticos\n",
    "\n",
    "obtenido de: https://machinelearningmastery.com/statistical-hypothesis-tests-in-python-cheat-sheet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arousal = df_2[df_2['class_model_output_categories'] == 'HA, LA']\n",
    "df_arousal = df_arousal['accuracy']\n",
    "arousal1 = df_arousal.values.tolist()\n",
    "arousal1 = list(map(float, arousal1))\n",
    "\n",
    "df_valence = df_2[df_2['class_model_output_categories'] == 'HV, LV']\n",
    "df_valence = df_valence['accuracy']\n",
    "valence1 = df_valence.values.tolist()\n",
    "valence1 = list(map(float, valence1))\n",
    "\n",
    "#print(arousal1, valence1)\n",
    "\n",
    "#Test parametrico - t de student\n",
    "print('Students t-test')\n",
    "from scipy.stats import ttest_ind\n",
    "stat, p = ttest_ind(arousal1, valence1, alternative = 'greater')\n",
    "print('stat=%.3f, p=%.3f' % (stat, p))\n",
    "if p > 0.05:\n",
    "\tprint('Probably the same distribution')\n",
    "else:\n",
    "\tprint('Probably different distributions')\n",
    "\n",
    "\n",
    "#Test no parametrico - U de Mann-Whitney\n",
    "print('Mann-Whitney U Test')\n",
    "from scipy.stats import mannwhitneyu\n",
    "stat, p = mannwhitneyu(arousal1, valence1, alternative = 'greater')\n",
    "print('stat=%.3f, p=%.3f' % (stat, p))\n",
    "if p > 0.05:\n",
    "\tprint('Probably the same distribution')\n",
    "else:\n",
    "\tprint('Probably different distributions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Gráficos frencuencia de los modelos algoritimicos, según modelos de regresión y clasificación\n",
    "\n",
    "- Interpretaciones: Los algoritmos clasificadores son por mucho los mas usados, ademas de ser los que mas variedad representan. Que implica esto? Es lo mismo aplicar algoritmos clasificadores o regresores?\n",
    "- Nota: ordenar los valores de los gráficos y unirlos en uno, buscar graficar los mas usados (primeros 5 o 10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_statistical_learning_models = df_statistical_learning_models.fillna('-')\n",
    "\n",
    "#para regressor\n",
    "df_algoritmos_regre = multi_reversing(df_statistical_learning_models, 'model_id', df_statistical_learning_models.iloc[:,43:57])\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_palette('colorblind')\n",
    "g = sns.countplot(x='variable', data=df_algoritmos_regre, order=df_algoritmos_regre.variable.value_counts().index)\n",
    "g.set(title = 'Cantidad de modelos de tipo regressor', xlabel = 'Algoritmo', ylabel = 'Cantidad de modelos')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "#para classifier\n",
    "\n",
    "df_algoritmos_class = multi_reversing(df_statistical_learning_models, 'model_id', df_statistical_learning_models.iloc[:,8:40])\n",
    "\n",
    "#Lista de algoritmos unicos de clasificacion\n",
    "algoritmos_de_clasificacion = df_algoritmos_class[\"variable\"].unique()\n",
    "#print(algoritmos_de_clasificacion)\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_palette('colorblind')\n",
    "g = sns.countplot(x='variable', data=df_algoritmos_class, order=df_algoritmos_class.variable.value_counts().index)\n",
    "g.set(title = 'Cantidad de modelos de tipo regressor', xlabel = 'Algoritmo', ylabel = 'Cantidad de modelos')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "#cantidad de algoritmos de regresion y clasificacion\n",
    "df_class_or_regre = multi_reversing(df_statistical_learning_models, 'model_id', df_statistical_learning_models.iloc[:,[5,40]])\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_palette('colorblind')\n",
    "g = sns.countplot(x='variable', data=df_class_or_regre, order=df_class_or_regre.variable.value_counts().index)\n",
    "g.set(title = 'Cantidad de modelos de tipo regressor', xlabel = 'Algoritmo', ylabel = 'Cantidad de modelos')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "#pie plot\n",
    "quantity = df_class_or_regre['variable'].value_counts()\n",
    "df_class_or_regre_quantity = pd.DataFrame(quantity)\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_palette('colorblind')\n",
    "names = 'Classifier', 'Regressor'\n",
    "plt.pie(df_class_or_regre_quantity['variable'], labels = names, labeldistance = 1.15, wedgeprops = { 'linewidth' : 3, 'edgecolor' : 'white' })\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Emotion elicitation techniques\n",
    "\n",
    "Nota: Falta organizar bien la data en la tabla, para obtener las siguientes barras: multimodal, modalidad visual, mod auditory, mod somatosensory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frecuencia por modalidad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frecuencia por technique_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task activo or passive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# por modalidad visual (pictures, videos, words, other)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# por modalidad auditiva (musica otro)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elicitation time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple techniques?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frecuencia desde driving a puzzle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Gráfico de barra por año (2010-2020) según tipos de base de datos (privada, pública)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rellenar datos faltantes y dropeo de duplicados\n",
    "df_data_type=df_data_type.fillna('-')\n",
    "df_data_type_sin_duplicates = df_data_type.drop_duplicates(subset='paper_id')\n",
    "\n",
    "#ploteo\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_palette('colorblind')\n",
    "plt.rcParams[\"legend.fontsize\"] = 15\n",
    "plt.rcParams[\"xtick.labelsize\"] = 15\n",
    "plt.rcParams[\"ytick.labelsize\"] = 15\n",
    "plt.rcParams[\"axes.labelsize\"] = 15\n",
    "plt.rcParams[\"axes.titlesize\"] = 20\n",
    "\n",
    "category_order = [2010, 2011, 2012, 2013, 2014, 2015, 2015, 2016, 2017, 2018, 2019, 2020]\n",
    "g = sns.countplot(x='year', \n",
    "    data= df_data_type, \n",
    "    hue='db_type', \n",
    "    order=category_order)\n",
    "g.set(title = 'Frecuencia de uso de bases de datos públicas y privadas por año (2010 - 2020)', xlabel = 'Año', ylabel = 'Cantidad')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Gráfico frencuencia de uso de cada base de datos pública encontrada\n",
    "- Interpretacion: Un predominio de pocas bases de datos. Estamos todo el tiempo sacando conclusiones sobre los mismos sujetos? Ver predominio de bases de datos publicas por sobre las privadas\n",
    "- No se ha tenido en cuenta el dato aportado por Lorenzo (mas de una db por paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bases de datos\n",
    "df_data_type=df_data_type.fillna('-')\n",
    "df_data_type_sin_duplicates = df_data_type.drop_duplicates(subset='paper_id')\n",
    "\n",
    "df_db = multi_reversing(df_data_type_sin_duplicates, 'paper_id', df_data_type_sin_duplicates.iloc[:,11:])\n",
    "\n",
    "df_db = df_db.replace('Multimodal Dyadic Behavior (MMDB)', 'MMDB')\n",
    "\n",
    "#plot\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_palette('colorblind')\n",
    "plt.rcParams[\"legend.fontsize\"] = 15\n",
    "plt.rcParams[\"xtick.labelsize\"] = 15\n",
    "plt.rcParams[\"ytick.labelsize\"] = 15\n",
    "plt.rcParams[\"axes.labelsize\"] = 15\n",
    "plt.rcParams[\"axes.titlesize\"] = 20\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_palette('colorblind')\n",
    "g = sns.countplot(x='variable', data=df_db, order = df_db.variable.value_counts().index)\n",
    "g.set(title = 'Frecuencia de uso de bases de datos públicas', xlabel = 'Base de datos', ylabel = 'Cantidad')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Gráfico frecuencia de papers según revista científica de origen, distinguiendo entre las que poseen orientación en ingeniería de datos y las que no\n",
    "\n",
    "Nota: falta filtrar bien cuales son journal, y cuales de estas son de ingenieria o no (diferenciarlas con color o hue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#por revista\n",
    "df_metadata=df_metadata.fillna('-')\n",
    "df_metadata_sin_duplicates = df_metadata.drop_duplicates(subset='paper_id')\n",
    "\n",
    "df_source_title = df_metadata_sin_duplicates[['paper_id','source_title','source_type_journal']]\n",
    "df_source_title = df_source_title[df_source_title['source_type_journal'].isin(['x', 'X'])]\n",
    "\n",
    "plt.rcParams[\"legend.fontsize\"] = 15\n",
    "plt.rcParams[\"xtick.labelsize\"] = 15\n",
    "plt.rcParams[\"ytick.labelsize\"] = 15\n",
    "plt.rcParams[\"axes.labelsize\"] = 15\n",
    "plt.rcParams[\"axes.titlesize\"] = 20\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_palette('colorblind')\n",
    "g = sns.countplot(x='source_title', data=df_source_title, order = df_source_title.source_title.value_counts().index)\n",
    "g.set(title = 'Cantidad de papers por journal', xlabel = 'Journal', ylabel = 'Cantidad')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "lista_journals = df_source_title[\"source_title\"].value_counts()\n",
    "#print(lista_journals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Box plot comparando performance de modelos de arousal y de valencia \n",
    "\n",
    "* Las medidas de performance fueron sacadas del analisis estadistico del punto 2 (medidas de performance de modelos de clasificacion, para valencia y arousal, tomando la medida de performance mas frecuente (accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#performances para arousal y valencia\n",
    "performances_av = pd.read_excel(\"c:\\\\Users\\\\LENOVO\\\\Downloads\\\\Review_EDA_Emotion_Recognition\\\\Emmanuel\\\\data\\\\cleaned\\\\modelos.xlsx\")\n",
    "performances_av = pd.DataFrame(performances_av)\n",
    "\n",
    "#plot\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_palette('colorblind')\n",
    "\n",
    "g = sns.boxplot(x=\"performance\", y=\"dimension\", data=performances_av,\n",
    "            whis=[0, 100], width=.6, palette=\"vlag\")\n",
    "\n",
    "sns.stripplot(x=\"performance\", y=\"dimension\", data=performances_av,\n",
    "              size=10, color=\".3\", linewidth=0)\n",
    "\n",
    "g.set(title = 'Comparación performance para modelos de clasificación arousal y valencia, usando accuracy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Node plot, para categorias emocionales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primero obtenemos las categorias emocionales usadas y su frecuencia\n",
    "\n",
    "* Hubo 55 modelos que usaron categorias emocionales, siendo disgust, fear, y sadness las mas repetidas.\n",
    "* Tener en cuenta que un modelo puede usar mas de una categoria, por lo que la funcion get_values no funciona en este caso, y un paper puede concentrar la mayoria de los usos de un conjunto de categorias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_self_report=df_self_report.fillna('-')\n",
    "#df_self_report = df_self_report.drop_duplicates(subset='paper_id')\n",
    "df_self_report = df_self_report[df_self_report['is_categorial'] == 'x']\n",
    "df_self_report = df_self_report\n",
    "\n",
    "emotional_categories = multi_reversing(df_self_report, 'model_id', df_self_report.iloc[:,18:])\n",
    "\n",
    "#print(emotional_categories['variable'].value_counts())\n",
    "#print(emotional_categories['variable'].unique())\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_palette('colorblind')\n",
    "g = sns.countplot(x='variable', data=emotional_categories, order=emotional_categories.variable.value_counts().index)\n",
    "g.set(title = 'Frecuencia uso categorias emocionales', xlabel = 'categoria', ylabel = 'frecuencia')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creamos el grafo\n",
    "* Vemos que las categorias de stress, joy y relaxation no se han usado junto a otras para la prediccion de emociones\n",
    "* disgust, fear, sadness y neutral son las que tienen mas conexiones (8), seguidas por anger, surprise y happiness (6), pleasent y anxiety (4), y funny y boredom (1)\n",
    "* falta customizar el tamaño de las lineas, segun la cantidad de veces que ambas categorias fueron testeadas juntas\n",
    "* siguiendo con lo anterior, tener en cuenta que, a pesar de lo mencionado,disgust fear y sadnes han sido las categorias mas utilizadas en modelos (apareciendo en 35), seguidas de cerca por pleasent y anxiety (cerca de 35 cada una). \n",
    "* Neutral, por ejemplo, se ha testeado solo en 4 modelos, pero ha aparecido en total junto a otras 8 categorias. Pleasent y anxiety han aparecido solo con otras 4 categorias, pero fueron testeadas cerca de 35 veces cada una."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creacion matrix de adyacencia\n",
    "df_matrix = df_self_report.iloc[:,18:]\n",
    "df_matrix = df_matrix[['Anger', 'Stress', 'Disgust', 'Fear', 'Sadness', 'Surprise', 'Happiness','Pleasant', 'Anxiety', 'Neutral', 'Funny', 'Boredom', 'Relaxation', 'Joy']]\n",
    "df_matrix = df_matrix.replace('-', 0)\n",
    "df_matrix = df_matrix.replace('x', 1)\n",
    "\n",
    "adj_matrix = df_matrix.T.dot(df_matrix)\n",
    "np.fill_diagonal(adj_matrix.values, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph(adj_matrix)\n",
    "\n",
    "nx.draw_circular(G, with_labels=True, node_size=1500, node_color=\"skyblue\", linewidths=40,\n",
    "                    font_size=18, font_color=\"black\", font_weight=\"bold\", width=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eda = df_eda.fillna('-')\n",
    "df_eda_sin_duplicates = df_eda.drop_duplicates(subset='paper_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dispositivos homemade\n",
    "homemade_dev = pd.DataFrame(df_eda_sin_duplicates['eda_device_is_homemade'])\n",
    "homemade_dev = homemade_dev[homemade_dev['eda_device_is_homemade'] != '-']\n",
    "homemade_dev = homemade_dev[homemade_dev['eda_device_is_homemade'] != 'No']\n",
    "#print(homemade_dev['eda_device_is_homemade'].value_counts())\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_palette('colorblind')\n",
    "g = sns.countplot(x='eda_device_is_homemade', data=homemade_dev, order=homemade_dev.eda_device_is_homemade.value_counts().index)\n",
    "g.set(title = 'Uso de dispositivos homemade', xlabel = '¿dispositivo homemade?', ylabel = 'Frecuencia')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dispositivos de eda usados\n",
    "device = pd.DataFrame(df_eda_sin_duplicates['eda_device_specification'])\n",
    "device = device[device['eda_device_specification'] != '-']\n",
    "#print(device['eda_device_specification'].value_counts())\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_palette('colorblind')\n",
    "g = sns.countplot(x='eda_device_specification', data=device, order=device.eda_device_specification.value_counts().index)\n",
    "g.set(title = 'Frecuencia de uso de dispositivos de EDA', xlabel = 'Dispotivo', ylabel = 'Frecuencia')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#locaciones usadas\n",
    "hemibody = pd.DataFrame(df_eda_sin_duplicates['location_hemibody'])\n",
    "hemibody = hemibody[hemibody['location_hemibody'] != '-']\n",
    "#print(location['location_hemibody'].value_counts())\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_palette('colorblind')\n",
    "g = sns.countplot(x='location_hemibody', data=hemibody, order=hemibody.location_hemibody.value_counts().index)\n",
    "g.set(title = 'Dominancia de la zona de colocación de los electrodos', xlabel = 'Localizacion', ylabel = 'Frecuencia')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "localization = pd.DataFrame(df_eda_sin_duplicates[['is_hands', 'wrist', 'chest','left_lobe_temporalis']])\n",
    "df_localization = multi_reversing(df_eda_sin_duplicates,'paper_id',df_eda_sin_duplicates[['is_hands', 'wrist', 'chest','left_lobe_temporalis']])\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_palette('colorblind')\n",
    "g = sns.countplot(x='variable', data=df_localization, order=df_localization.variable.value_counts().index)\n",
    "g.set(title = 'Localización en el cuerpo de los electrodos', xlabel = 'Localización', ylabel = 'Frecuencia')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "hand_localization = pd.DataFrame(df_eda_sin_duplicates.iloc[:,7:16])\n",
    "df_hand_localization = multi_reversing(df_eda_sin_duplicates,'paper_id',df_eda_sin_duplicates.iloc[:,7:16])\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_palette('colorblind')\n",
    "g = sns.countplot(x='variable', data=df_hand_localization, order=df_hand_localization.variable.value_counts().index)\n",
    "g.set(title = 'Localización en las manos de los electrodos', xlabel = 'Localización', ylabel = 'Frecuencia')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e31aef8222fb7c235d2ed8e74ce17e973738f89b37261e7466b7a63a6dfb1214"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
