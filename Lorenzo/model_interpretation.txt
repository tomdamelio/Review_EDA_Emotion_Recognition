By using the gradient fields (see Fig. 6(c,d)), the affective HMPM indirectly supports that the affective valence and arousal have their origins in human brain’s motivational circuits. It seems to be reasonable that evaluative affective components (valence and arousal) are associated with the broad functions of brain’s motivational circuits—appetitive subcircuits activation (pleasant) and defensive subcircuits activation (unpleasant) and an intensity of these two subcircuits activation (arousal)9 . Affective cues can induce skin conductance activations through the limbic-hypothalamic EDA1 pathway, and the pleasant affect may additionally induce skin conductance activations through the premotor-basal ganglia EDA2 pathway37. The gradient field of valence (Fig. 6(c)) indicates that the valence factor is mainly determined by the two dimensions: gain, that has neural activation intensity meanings, and decay time constant, that has the meanings of skin conductance different pathways37,45. The gradient field of arousal (Fig. 6(d)) indicates that arousal factor is mainly determined by the gain dimension. These findings may indirectly support prior researches9,48. The HMPR is an important supplement to emotional estimation methodology. The HMPR, in fact, is not only theoretically supported by the Taylor theorem, but also able to obtain an intuitive HMPM to efficiently estimate the affective valence and arousal from pure skin conductance responses. Moreover, the result of comparing the HMPR with the ANN models (see Supplementary Table S7) showed that both the HMPR and ANN can obtain relative accurate computing results. Such accurate estimation results surely increases the impact in the wearable computing fields such as smart watches, Mi Band, and Google Glass, etc. It is a trend now to detect human affect by multimodal signals (e.g., neural activations, facial videos, voice recordings, body gestures, and physiological signals, etc.Figure 6 shows similar EDA signal behaviour during resting and recovery phases. Signal constantly rises to a limit at this point before declining and rising again. Signals at these phases had low fluctuation and sudden rise of amplitude because the subject sits in a relaxed phase. This situation is similar to a neutral simulated driving condition. The most frequent fluctuation of EDA signal was observed during anger-simulated driving, followed by stress and neutral driving. This finding shows that the subject is endowed with the most intense sympathetic response during anger, followed by stress and neutral emotion. Further processing was required to determine significant differences of EDA properties during different simulated driving tasks. Figure 7 indicates that band-pass-filtered EDA signals at neutral simulated driving tasks had similar response to control and recovery sessions, wherein the subject demonstrates the least physiological response because of the simplicity of driving scenario. The subject possesses a high level of physiological response during states of anger than in stress-simulated driving tasks. The overall amplitude of signals is high and the fluctuations of spikes occurred frequently.After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1 and SD2 measures mainly reflect parasympathetic, and both sympathetic and parasympathetic activities, respectively. The results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices. In addition, positive LEs revealed that GSR signals have a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of GSR signals during fear. The lower RQA measures during all emotional stimuli, a higher dimensional GSR signal can be concluded. VMAX and LAM mark a time period in which the state changes very slowly or does not change. Consequently, higher values of the indices during rest condition reveal the system stability. Next, three feature selection algorithms were applied to the dataThe relationship between visual descriptors and other kind of subjective information like aesthetics or appeal reported deliberately by participants via a score, for instance, had been already demonstrated in previous works [16]. However, finding some correlation with EDA has a great interest because it is a psychophysiological reaction controlled by the autonomous nervous system, thus it is automatic and is directly related to actual emotional and attentional activation, avoiding the implicit bias of opinions and judgments. Correlation between the set of visual descriptors and SCL and SCR was not so clear as in the case of SUM. One explanation for this is that these measures alone reflect subtleties that are more difficult to capture by simple methods and a relatively small set of featuresPhysiological measures in the real world are more complex than those under laboratory conditions. In this paper, we have shown that ER (Emotion Recognition) by using physiological signals is influenced by human movements. We investigate the recognition of a group of emotions by using various physiological signals and commonly used algorithms in both, the lab and a real-world scenario. Our results show that the ST (Skin Temperature), EDA (Electrodermal Activity), and EMG (Electromyography) signals achieve the highest accuracies when the data is collected when the participants are at rest. Our results show that the Decision Tree is the best classification algorithm. From our work we can conclude, that human movement influences the physiological signals measured from a user, and therefore, influence the results of the ER. For this reason, one must take this effect into account when developing models for emotion recognition. ER models based on controlled experiments cannot be accurately used to recognize emotion in real-world scenarios. Furthermore, it is worth noting that quality adaptive arousal and valence classifiers performed significantly above chance on all the modalities except on valence recognition using GSR that is in corroboration with the finding in [7]. It is worthy to mention that low unimodal performances on GSR could be due to the fact that GSR responses are slow. Therefore, GSR is an unsuitable modality for an experiment with short recordings like ours.Poor classification accuracy may arise because anger, fear, or stress emotions fall at the same section according to the valence–arousal and pleasant–unpleasant models [20][25]. Consequently, humans possess similar physiological characteristics during these two emotions, leading to poor classification accuracy. A number of research have also demonstrated that the emotions of drivers differ considerably in vulnerability to disturbance. Therefore, EDA measurements for this experiment are still insufficient in detecting slight physiological changes between anger and stress.Compare to some references [1], [3], [4], the proposed features used in this study offered better results for the 3-class problem, see highlighted results in Table 1 and 2. These are the second major findings in this study and will serve as baselines for future studies using the MAHNOB-HCI, especially for EDA-based features only. However, recognizing medium valence looked challenging, while low valence showed the easiest ones. This study was limited by the absence of nonlinear features as Yang and Liu found that relationship between EDA signal and emotion is nonlinear [8]. Deeper studies using nonlinear features, e.g. Lanata et al. [6] proposed recurrent plot, deterministic chaos, and detrended fluctuation analysis, were left for future works. Electrodermal Activity. Interestingly, EDA seems to be the most generalizable signal as it performed the best in the across prediction setup compared to the other physiological sources, and also performed better than EDA in the within prediction setup. It is also interesting that the low classification performances of some participants in the within setup (e.g., P10, P17, P22) were largely improved in the across setup. One possible explanation is that EDA features are quite generalizable across participants; for some participants, the effect might be small, and therefore the model’s performance improves when the amount of training data increases, even when the data belongs to other participants.  Figure 5 shows the grand average across participants and trials of the EDA for the time-locked, fixed-time windows (initial, end, and special windows). EDA is known to present a relatively high latency as compared to other physiological signals. As a matter of fact, capturing the EDA responses to the humor appraisal was one of the main motivations to define the special window that continues for 5 seconds after the end of a trial. The grand average of the EDA signal shows a very large difference in the signal from 2 to 4 seconds after the end of a trial. More specifically, Funny trials elicited higher EDA than Not funny trials. This is captured in the most relevant features for the trained models (see Table 4), as the top EDA features are the ones capturing the amount of activity (i.e., wS.sum.Eda) and amount of change (i.e., wS.diff.Eda, wS.diffsq.Eda) within the special window   EDA showed increased values for humorous content, as expected because of increased activity of the sympathetic nervous system due to the feeling of amusement (Foster et al. 1998; Martin 2010) (Figure 5). In addition, the results indicate that the most discriminative differences in the physiological signals related to humor appraisal occur in the later stages of the information consumption process, as shown in the most highly weighted features of the predictive models (see Table 4). This finding is compatible with the incongruity model of humor, which posits that humor results from solving ambiguities and conceptual incongruities using alternative formulations to the discrepancy. To put it in colloquial terms, the punchline comes at the end (Polimeni and Reiss 2006). As a matter of fact, the discriminative physiological differences were mostly found in the special window, which continued for several seconds after the trial ended, overlapping with the next stimulus. Initially, we expected this to be the case only for the EDA signal, which is known to have a temporal delay; but the same post-decision changes were apparent in EEG and ECG features as well. This holds important implications for the design of affective systems for humor appraisal, as it proves the delayed nature of physiological responses related to humor appraisal, as well as their capability to capture it, despite overlapping with the next stimulusAdditionally, we showed that psychological traits can guide this task by correcting profile-driven differences, opening a new direction on how to measure affective interactions. The quantitative assessment shows that emotion recognition significantly improves when adopting more flexible methods to mine the electrodermal signal. Additionally, feature correlation analysis and discriminative mining of generative models show meaningful differences among emotional stimuli and experimental settings. These answers to the target research questions trigger new implications not only for psychophysiology and neuroscience, but especially to human-robot and social interaction research.Additionally, analyzing the results of the state-of-art, clearly, feature engineering for subject-independent and subject-dependent human emotion detection based on EDA does not lead to high performance. In particular, when the number of classes is higher than two. This is because extracting the sympathetic response patterns which are part of each emotion is difficult. Furthermore, when trying to overcome this fact by analyzing more basic features such as level, response amplitude, rate, rise time, and recovery time, they discard flexible elicited behavior which might improve emotion recognition. Therefore, it has been proven in this work that DL can overcome this drawback quite well. Regarding the point of testing the proposed model using different datasets from different labs, it is because human emotions do not form similar patterns. Consequently, the research community should develop generalized models to recognize human emotions, where subjects, elicitation materials, and physiological sensors brands are different from the ones involved in the initial training.Another major finding is that EEG and GSR appear to correlate with boredom, thus supporting the conclusion of Bench and Lench [34] that boredom and autonomic nervous system are linked.Another reason for the better performance of AMIGOS as compared to DREAMER is due to the nature of the self-assessment acquisition process. Self-assessment for the AMIGOS dataset was obtained on a scale of 1–9 for arousal and valence separately. However, for the DREAMER dataset, self-assessment rom subjects was acquired on the scale of 1–5 for both valence and arousal. The scale of 1–5 not only exhibits half the freedom of choice on an intensity scale of emotion but also restricts the imbalance created by avoiding the midpoint between 1–5 scale as participants can only provide integer data for the intensity of arousal and valence. However, AMIGOS gives participants the liberty to self-assess in a floating-point number for the scale of 1–9, hence better categorization of emotion can be made which implied better performance of the algorithm on this dataset comparativelyParticularly, although EDA is one of the most popular signals for measuring emotional arousal, and the same processing methods have been successfully applied in previous studies using emotional videos, images, sounds, and touch [28]–[30], the recognition accuracy obtained in this case was not much higher than 50%. The cause could be found in the altered respiration activity induced by speech that affects ANS dynamics and covers up the sympathetic arousal responseFinally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation coefficients analysis of this database demonstrated that the energy in prefrontal part is positively correlated with the level of positive emotion states and negative correlated with the level of negative emotion states. The difference of coefficients distribution between positive emotions and negative emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar, which validated that negative emotion categories are to a large extent overlapped.This research analyzed the physiological component of emotion in different emotional conditions (fear, happiness and neutral), using automatic systems for emotion identification. Our results suggest that the ECG signal seems to be the most informative in emotion stratification. The use of facial EMG in emotion is dependent on monitoring two (or more) muscles, allowing to identify facial expression changes by corresponding muscular contractions. Nevertheless, if all signals are used on emotion identification, a higher accuracy is achieved, since all signals are representative of different information. This physiological model of emotions has important research and clinical implications, by providing valuable information about the value and weight of physiological signals for emotional classification, which can critically drive effective evaluation, monitoring, and intervention regarding emotional processing and regulation, considering multiple contextsWhile our study shows that with TEM, the emotion recognition accuracy increases, which could mean that the users were able to better feel the emotions as the video content intended to deliver. The use of physiological sensors also ensures that the true sensation of emotion is detected which is subjectively independent of users.Physiological datasets with a large number of instances are optimal for the proposed experiments since these directly influence the emotion prediction, a the greater the number of instances, the more effective the model. Consequently, several annotations of arousal and valence must be recorded, since, when subjecting a participant to the stimulus of a short video, it can manifest different levels of emotion during of experiment.The proposed framework has enhanced the performance of emotion recognition. The reason might be as follows. First, as human being has the multivariate characteristics, it is difficult to accurately reflect the emotional changes by means of specific peripheral physiological signal. ECG, EMG and SCL might complement each other to reflect the emotional changes well. Second, the most emotion-related physiological features might be discovered by using feature selection. Furthermore, the adverse interference between different physiological signals could be totally avoided with decision fusion. As for future work, the following attempts are deserved. We will try to extract the unseen features with deep neural networks to form multi-level feature set in order to get rid of the problem of weak generalization ability caused by using features in lowdimension space. On the other hand, other dataset could be considered, such as DEAP and MAHNOB to evaluate and optimize our framework. Last but not least, as feature selection methods greatly affect the recognition results, we will try more feature selection methods. And further experiments on classifying extensive emotion states would be conducted in the next stage. relevant information on the ANS activity can be retrieved from the superimposed phasic behavior of HRV time-varying bispectral measures. Furthermore, the proposed new indices characterizing the cardiovascular control through EDA and HRV seem to provide a more effective indicator of the sympathovagal balance then traditional indices from HRV series onlthe initial analysis also shows some noticeable difference of our data driven arousal model from our observers’ perspective, when compared to the (abstract) standard models in the literature. The data-derived model with neutral as the baseline is quite similar to the standard abstract model, with the only changes being Happy and Sad changing sides as Low/High arousal. Further analysis will be conducted and evaluated to identify the reasons. Questions to be answered are whether the dataset was biased, whether our 20 participants were somehow different from the expected population reaction, or whether the abstract model is just incorrect. It is also important to point out that EDA activity can vary according to the difference in stimuli types, participants’ age, gender etc [6]. Also the number of samples might be considered small, although experiments have shown that it is reasonable [9]. Arguably, it makes more sense to use the overall average reaction to be the baseline between high and low arousal, which spreads the emotional reactions over a wider range. This differs more from the standard model.Second, our error analysis suggests that the types of stimuli could also be a key component in affecting the physiological responses and potentially inducing the bias in the self emotion assessment. Through better understanding the relationship of these multiple perspectives of emotion annotations and the measured physiological responses could help enhance the robustness of affective recognition module that can be integrated for many human behavior modeling applications The best features that were repeated in the selection results were: MaxAmpPeak, VarAmpPeak, StdAmpPeak, MaxAbsAmpPeak, VarSC, StdSC, ActivitySC, MaxDeltaForward, MaxDeltaBack, KurtosisAmpPeak, SkewnessAmpPeak. These features are related to the maximum values, energy or statistical properties of the phasic component. The results indicate that such features should be used in the analysis of the EDA for the level of arousal recognition. Of great importance is the quality of the recorded SC signals and the pre-processing methods. In conjunction with the features of other physiological signals (such as ECG, EEG, and EMG), the proposed analysis can produce better results.