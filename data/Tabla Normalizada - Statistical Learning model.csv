paper_id,model_id,apa_citation,year,affective_model,is_classifier,class_model_output_number,class_model_output_categories,class_Logistic Regression,class_Support Vector Machine (SVM),class_k-Nearest Neighbor (k-NN),class_Quadratic discrimant clasifier (QDA),class_Linear Discriminant Analysis (LDA),class_Tree based models,class_Naive Bayes,class_AVG,class_LASSO-T,class_Ridge-T,class_LASSO-VAR,class_Ridge-VAR,class_TPA,class_HDC-MER,class_HMM,class_Gradient boostingclass,class_Fully connected NN (or Multi layer perceptron),class_Convolutional NN,class_Recurrent NN,class_GRU (Gated Recurrent Units),class_LSTM,class_Cellular Neural Networks,class_AdaBoost DT,class_Quantum Neural Network (QNN),class_Probabilistic Neural Network (PNN),class_Backpropagation (BP),class_Extreme Learning Machine (ELM),class_ANN,class_Spiking Deep Belief Network (SDBN),"class_radial basis function
(RBF) ",class_1R rule,class_JRip,is_regressor,regre_model_output_number,regre_model_output_dimensions,regre_Linear Regression,regre_Support Vector Regression (SVR),regre_Polynomial Regression,regre_Ridge regression,regre_Logistic regression,regre_knn,regre_decision tree,regre_Multilayer regression,regre_Boosted regression trees,regre_Fully connected NN (or Multi layer perceptron),regre_Convolutional NN,regre_Recurrent NN,regre_LSTM,regre_PNN (probabilistic neural network),model_level_intersubject,model_level_intrasubject,n_model_input,is_physiologicall_interpretation,model_interpretation,is_public_code,public_code_location
1,1,"Zangróniz, R., Martínez-Rodrigo, A., Pastor, J. M., López, M. T., & Fernández-Caballero, A. (2017). Electrodermal Activity Sensor for Classification of Calm/Distress Condition. Sensors (Basel, Switzerland), 17(10), E2324. https://doi.org/10.3390/s17102324
",2017,dimensional,x,2,"calm, distress",-,-,-,,-,x,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,,x,-,-,-,-,-,-
2,2,"Liu, M., Fan, D., Zhang, X., & Gong, X. (2017). Human Emotion Recognition Based on Galvanic Skin Response Signal Feature Selection and SVM. 157–160. Scopus. https://doi.org/10.1109/ICSCSE.2016.0051
",2016,categorical,x,5,"Happiness, Grief, Fear, Anger, Calm",-,x,-,-,-,,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,-,-,-,,-,-,-,-
3,3,"Ayata, D., Yaslan, Y., & Kamasak, M. E. (2018). Emotion Based Music Recommendation System Using Wearable Physiological Sensors. IEEE Transactions on Consumer Electronics, 64(2), 196–203. Scopus. https://doi.org/10.1109/TCE.2018.2844736
",2018,dimensional,x,2,"LA, HA",-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,-,-,-,-,-,-,-,-
3,4,"Ayata, D., Yaslan, Y., & Kamasak, M. E. (2018). Emotion Based Music Recommendation System Using Wearable Physiological Sensors. IEEE Transactions on Consumer Electronics, 64(2), 196–203. Scopus. https://doi.org/10.1109/TCE.2018.2844736
",2018,dimensional,x,2,"LV, HV",-,-,-,-,-,,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,-,x,,,-,-,x,-
4,5,"Ali, M., Machot, F. A., Mosa, A. H., Jdeed, M., Machot, E. A., & Kyamakya, K. (2018). A Globally Generalized Emotion Recognition System Involving Different Physiological Signals. Sensors (Basel, Switzerland), 18(6), E1905. https://doi.org/10.3390/s18061905",2018,dimensional,x,4,"HAHV, HALV, LAHV, LALV",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
4,6,"Ali, M., Machot, F. A., Mosa, A. H., Jdeed, M., Machot, E. A., & Kyamakya, K. (2018). A Globally Generalized Emotion Recognition System Involving Different Physiological Signals. Sensors (Basel, Switzerland), 18(6), E1905. https://doi.org/10.3390/s18061906",2018,dimensional,x,4,"HAHV, HALV, LAHV, LALV",-,-,-,-,-,-,x,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
4,7,"Ali, M., Machot, F. A., Mosa, A. H., Jdeed, M., Machot, E. A., & Kyamakya, K. (2018). A Globally Generalized Emotion Recognition System Involving Different Physiological Signals. Sensors (Basel, Switzerland), 18(6), E1905. https://doi.org/10.3390/s18061907",2018,dimensional,x,4,"HAHV, HALV, LAHV, LALV",-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
4,8,"Ali, M., Machot, F. A., Mosa, A. H., Jdeed, M., Machot, E. A., & Kyamakya, K. (2018). A Globally Generalized Emotion Recognition System Involving Different Physiological Signals. Sensors (Basel, Switzerland), 18(6), E1905. https://doi.org/10.3390/s18061908",2018,dimensional,x,4,"HAHV, HALV, LAHV, LALV",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
4,9,"Ali, M., Machot, F. A., Mosa, A. H., Jdeed, M., Machot, E. A., & Kyamakya, K. (2018). A Globally Generalized Emotion Recognition System Involving Different Physiological Signals. Sensors (Basel, Switzerland), 18(6), E1905. https://doi.org/10.3390/s18061909",2018,dimensional,x,4,"HAHV, HALV, LAHV, LALV",-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,x,,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
5,10,"Wei, J., Chen, T., Liu, G., & Yang, J. (2016). Higher-order Multivariable Polynomial Regression to Estimate Human Affective States. Scientific Reports, 6, 23384. https://doi.org/10.1038/srep23384",2016,dimensional,,-,-,-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,x,-,arousal,-,-,-,,,,,,,-,-,-,-,-,-,-,-,x,"By using the gradient fields (see Fig. 6(c,d)), the affective HMPM indirectly supports that the affective valence
and arousal have their origins in human brain’s motivational circuits. It seems to be reasonable that evaluative
affective components (valence and arousal) are associated with the broad functions of brain’s motivational circuits—appetitive subcircuits activation (pleasant) and defensive subcircuits activation (unpleasant) and an intensity of these two subcircuits activation (arousal)9
. Affective cues can induce skin conductance activations through
the limbic-hypothalamic EDA1 pathway, and the pleasant affect may additionally induce skin conductance activations through the premotor-basal ganglia EDA2 pathway37. The gradient field of valence (Fig. 6(c)) indicates
that the valence factor is mainly determined by the two dimensions: gain, that has neural activation intensity
meanings, and decay time constant, that has the meanings of skin conductance different pathways37,45. The gradient field of arousal (Fig. 6(d)) indicates that arousal factor is mainly determined by the gain dimension. These
findings may indirectly support prior researches9,48.
The HMPR is an important supplement to emotional estimation methodology. The HMPR, in fact, is not only
theoretically supported by the Taylor theorem, but also able to obtain an intuitive HMPM to efficiently estimate
the affective valence and arousal from pure skin conductance responses. Moreover, the result of comparing the
HMPR with the ANN models (see Supplementary Table S7) showed that both the HMPR and ANN can obtain
relative accurate computing results. Such accurate estimation results surely increases the impact in the wearable
computing fields such as smart watches, Mi Band, and Google Glass, etc. It is a trend now to detect human affect
by multimodal signals (e.g., neural activations, facial videos, voice recordings, body gestures, and physiological
signals, etc.",-,-
5,11,"Wei, J., Chen, T., Liu, G., & Yang, J. (2016). Higher-order Multivariable Polynomial Regression to Estimate Human Affective States. Scientific Reports, 6, 23384. https://doi.org/10.1038/srep23384",2016,categorical,,-,-,-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,x,,valence,-,-,x,,,,,,,-,-,-,-,-,-,-,-,x,-,-,-
6,12,"Feng, H., Golshan, H. M., & Mahoor, M. H. (2018). A wavelet-based approach to emotion classification using EDA signals. Expert Systems with Applications, 112, 77–86. Scopus. https://doi.org/10.1016/j.eswa.2018.06.014",2018,categorical,x,2,"acceptance, boredom",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,-,?,?,-,-,-,-,-
6,13,"Feng, H., Golshan, H. M., & Mahoor, M. H. (2018). A wavelet-based approach to emotion classification using EDA signals. Expert Systems with Applications, 112, 77–86. Scopus. https://doi.org/10.1016/j.eswa.2018.06.014",2018,categorical,x,2,"acceptance, joy",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,-,?,?,-,-,-,-,-
6,14,"Feng, H., Golshan, H. M., & Mahoor, M. H. (2018). A wavelet-based approach to emotion classification using EDA signals. Expert Systems with Applications, 112, 77–86. Scopus. https://doi.org/10.1016/j.eswa.2018.06.014",2018,categorical,x,2,"boredom, joy",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,-,?,?,-,-,-,-,-
6,15,"Feng, H., Golshan, H. M., & Mahoor, M. H. (2018). A wavelet-based approach to emotion classification using EDA signals. Expert Systems with Applications, 112, 77–86. Scopus. https://doi.org/10.1016/j.eswa.2018.06.014",2018,categorical,x,3,"acceptance, joy, boredom",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,-,?,?,-,-,-,-,-
6,16,"Feng, H., Golshan, H. M., & Mahoor, M. H. (2018). A wavelet-based approach to emotion classification using EDA signals. Expert Systems with Applications, 112, 77–86. Scopus. https://doi.org/10.1016/j.eswa.2018.06.014",2018,categorical,x,2,"acceptance, boredom",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,-,?,?,-,-,-,-,-
6,17,"Feng, H., Golshan, H. M., & Mahoor, M. H. (2018). A wavelet-based approach to emotion classification using EDA signals. Expert Systems with Applications, 112, 77–86. Scopus. https://doi.org/10.1016/j.eswa.2018.06.014",2018,categorical,x,2,"acceptance, joy",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,-,?,?,-,-,-,-,-
6,18,"Feng, H., Golshan, H. M., & Mahoor, M. H. (2018). A wavelet-based approach to emotion classification using EDA signals. Expert Systems with Applications, 112, 77–86. Scopus. https://doi.org/10.1016/j.eswa.2018.06.014",2018,categorical,x,2,"boredom, joy",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,-,?,?,-,-,-,-,-
6,19,"Feng, H., Golshan, H. M., & Mahoor, M. H. (2018). A wavelet-based approach to emotion classification using EDA signals. Expert Systems with Applications, 112, 77–86. Scopus. https://doi.org/10.1016/j.eswa.2018.06.014",2018,categorical,x,3,"baseline, stress, amusement",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,-,?,?,-,-,-,-,-
7,20,"Schmidt, P., Reiss, A., Duerichen, R., & Van Laerhoven, K. (2018). Introducing WeSAD, a multimodal dataset for wearable stress and affect detection. 400–408. Scopus. https://doi.org/10.1145/3242969.3242985",2018,categorical,x,3,"baseline, stress, amusement",-,-,-,-,-,x,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,,-,-,-,-,-,-,-,-,-,-,-
7,21,"Schmidt, P., Reiss, A., Duerichen, R., & Van Laerhoven, K. (2018). Introducing WeSAD, a multimodal dataset for wearable stress and affect detection. 400–408. Scopus. https://doi.org/10.1145/3242969.3242985",2018,categorical,x,3,"baseline, stress, amusement",-,-,-,-,-,x,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,,-,-,-,-,-,-,-,-,-,-,-
7,22,"Schmidt, P., Reiss, A., Duerichen, R., & Van Laerhoven, K. (2018). Introducing WeSAD, a multimodal dataset for wearable stress and affect detection. 400–408. Scopus. https://doi.org/10.1145/3242969.3242985",2018,categorical,x,3,"baseline, stress, amusement",-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,x,,,,,,,,,-,,-,-,-,-,,,,,,,,,-,-,-,-,-,-,-,-,-,-,-
7,23,"Schmidt, P., Reiss, A., Duerichen, R., & Van Laerhoven, K. (2018). Introducing WeSAD, a multimodal dataset for wearable stress and affect detection. 400–408. Scopus. https://doi.org/10.1145/3242969.3242985",2018,categorical,x,3,"baseline, stress, amusement",-,-,-,-,x,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,,-,-,-,-,-,-,-,-,-,-,-
7,24,"Schmidt, P., Reiss, A., Duerichen, R., & Van Laerhoven, K. (2018). Introducing WeSAD, a multimodal dataset for wearable stress and affect detection. 400–408. Scopus. https://doi.org/10.1145/3242969.3242985",2018,categorical,x,3,"baseline, stress, amusement",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,,-,-,-,-,-,-,-,-,-,-,-
7,25,"Schmidt, P., Reiss, A., Duerichen, R., & Van Laerhoven, K. (2018). Introducing WeSAD, a multimodal dataset for wearable stress and affect detection. 400–408. Scopus. https://doi.org/10.1145/3242969.3242985",2018,categorical,x,3,"baseline, stress, amusement",-,-,-,-,-,x,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,-,-,-,-,-,-,-,-
7,26,"Schmidt, P., Reiss, A., Duerichen, R., & Van Laerhoven, K. (2018). Introducing WeSAD, a multimodal dataset for wearable stress and affect detection. 400–408. Scopus. https://doi.org/10.1145/3242969.3242985",2018,categorical,x,3,"baseline, stress, amusement",-,-,-,-,-,x,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,-,-,-,-,-,-,-,-
7,27,"Schmidt, P., Reiss, A., Duerichen, R., & Van Laerhoven, K. (2018). Introducing WeSAD, a multimodal dataset for wearable stress and affect detection. 400–408. Scopus. https://doi.org/10.1145/3242969.3242985",2018,categorical,x,3,"baseline, stress, amusement",-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,x,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,-,-,-,-,-,-,-,-
7,28,"Schmidt, P., Reiss, A., Duerichen, R., & Van Laerhoven, K. (2018). Introducing WeSAD, a multimodal dataset for wearable stress and affect detection. 400–408. Scopus. https://doi.org/10.1145/3242969.3242985",2018,categorical,x,3,"baseline, stress, amusement",-,-,-,-,x,-,-,,,,,,,,,,-,,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,-,-,-,-,-,-,-,-
7,29,"Schmidt, P., Reiss, A., Duerichen, R., & Van Laerhoven, K. (2018). Introducing WeSAD, a multimodal dataset for wearable stress and affect detection. 400–408. Scopus. https://doi.org/10.1145/3242969.3242985",2018,dimensional,x,2,"stress,  not stress",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,-,-,-,-,-,-,-,-
7,30,"Schmidt, P., Reiss, A., Duerichen, R., & Van Laerhoven, K. (2018). Introducing WeSAD, a multimodal dataset for wearable stress and affect detection. 400–408. Scopus. https://doi.org/10.1145/3242969.3242985",2018,dimensional,x,2,"stress,  not stress",-,-,-,-,-,x,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,,-,-,-,-,-,-,-,-,-,-,-
7,31,"Schmidt, P., Reiss, A., Duerichen, R., & Van Laerhoven, K. (2018). Introducing WeSAD, a multimodal dataset for wearable stress and affect detection. 400–408. Scopus. https://doi.org/10.1145/3242969.3242985",2018,dimensional,x,2,"stress,  not stress",-,-,-,-,-,x,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,,-,-,-,-,-,-,-,-,-,-,-
7,32,"Schmidt, P., Reiss, A., Duerichen, R., & Van Laerhoven, K. (2018). Introducing WeSAD, a multimodal dataset for wearable stress and affect detection. 400–408. Scopus. https://doi.org/10.1145/3242969.3242985",2018,dimensional,x,2,"stress,  not stress",-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,,x,,,,,,,,,-,,-,-,-,-,,,,,,,,,-,-,-,-,-,-,-,-,-,-,-
7,33,"Schmidt, P., Reiss, A., Duerichen, R., & Van Laerhoven, K. (2018). Introducing WeSAD, a multimodal dataset for wearable stress and affect detection. 400–408. Scopus. https://doi.org/10.1145/3242969.3242985",2018,dimensional,x,2,"stress,  not stress",-,-,-,-,x,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,,-,-,-,-,-,-,-,-,-,-,-
7,34,"Schmidt, P., Reiss, A., Duerichen, R., & Van Laerhoven, K. (2018). Introducing WeSAD, a multimodal dataset for wearable stress and affect detection. 400–408. Scopus. https://doi.org/10.1145/3242969.3242985",2018,dimensional,x,2,"stress,  not stress",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,,-,-,-,-,-,-,-,-,-,-,-
7,35,"Schmidt, P., Reiss, A., Duerichen, R., & Van Laerhoven, K. (2018). Introducing WeSAD, a multimodal dataset for wearable stress and affect detection. 400–408. Scopus. https://doi.org/10.1145/3242969.3242985",2018,dimensional,x,2,"stress,  not stress",-,-,-,-,-,x,-,,,,,,,,,,-,,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,-,-,-,-,-,-,-,-
7,36,"Schmidt, P., Reiss, A., Duerichen, R., & Van Laerhoven, K. (2018). Introducing WeSAD, a multimodal dataset for wearable stress and affect detection. 400–408. Scopus. https://doi.org/10.1145/3242969.3242985",2018,dimensional,x,2,"stress,  not stress",-,-,-,-,-,x,-,,,,,,,,,,-,,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,-,-,-,-,-,-,-,-
7,37,"Schmidt, P., Reiss, A., Duerichen, R., & Van Laerhoven, K. (2018). Introducing WeSAD, a multimodal dataset for wearable stress and affect detection. 400–408. Scopus. https://doi.org/10.1145/3242969.3242985",2018,dimensional,x,2,"stress,  not stress",-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,x,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,-,-,-,-,-,-,-,-
7,38,"Schmidt, P., Reiss, A., Duerichen, R., & Van Laerhoven, K. (2018). Introducing WeSAD, a multimodal dataset for wearable stress and affect detection. 400–408. Scopus. https://doi.org/10.1145/3242969.3242985",2018,dimensional,x,2,"stress,  not stress",-,-,-,-,x,-,-,,,,,,,,,,-,,-,,-,-,-,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,-,-,-,-,-,-,-,-
7,39,"Schmidt, P., Reiss, A., Duerichen, R., & Van Laerhoven, K. (2018). Introducing WeSAD, a multimodal dataset for wearable stress and affect detection. 400–408. Scopus. https://doi.org/10.1145/3242969.3242985",2018,dimensional,x,2,"stress,  not stress",-,-,x,-,-,,-,,,,,,,,,,-,,-,,-,,-,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,-,-,-,-,-,-,-,-
8,40,"Dobbins, C., Fairclough, S., Lisboa, P., & Navarro, F. F. G. (2018). A Lifelogging Platform Towards Detecting Negative Emotions in Everyday Life using Wearable Devices. 306–311. Scopus. https://doi.org/10.1109/PERCOMW.2018.8480180",2018,dimensional,x,2,"relaxed, stress",-,-,-,-,x,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
8,41,"Dobbins, C., Fairclough, S., Lisboa, P., & Navarro, F. F. G. (2018). A Lifelogging Platform Towards Detecting Negative Emotions in Everyday Life using Wearable Devices. 306–311. Scopus. https://doi.org/10.1109/PERCOMW.2018.8480180",2018,categorical,x,2,"relaxed, stress",-,-,-,x,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
8,42,"Dobbins, C., Fairclough, S., Lisboa, P., & Navarro, F. F. G. (2018). A Lifelogging Platform Towards Detecting Negative Emotions in Everyday Life using Wearable Devices. 306–311. Scopus. https://doi.org/10.1109/PERCOMW.2018.8480180",2018,dimensional,x,2,"relaxed, stress",-,-,-,-,-,x,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
9,43,"Amalan, S., Shyam, A., Anusha, A. S., Preejith, S. P., Tony, A., Jayaraj, J., & Mohanasankar, S. (2018). Electrodermal Activity based Classification of Induced Stress in a Controlled Setting. MeMeA 2018 - 2018 IEEE International Symposium on Medical Measurements and Applications, Proceedings. Scopus. https://doi.org/10.1109/MeMeA.2018.8438703",2018,dimensional,x,2,"stress, not stress",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
10,44,"Machot, F. A., Ali, M., Ranasinghe, S., Mosa, A. H., & Kyandoghere, K. (2018). Improving subject-independent human emotion recognition using electrodermal activity sensors for active and assisted living. 222–228. Scopus. https://doi.org/10.1145/3197768.3201523",2018,dimensional,x,4,"HAHV, HALV, LAHV, LALV",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
11,45,"Girardi, D., Lanubile, F., & Novielli, N. (2018). Emotion detection using noninvasive low cost sensors. 2018-January, 125–130. Scopus. https://doi.org/10.1109/ACII.2017.8273589",2018,dimensional,x,2,"LA, HA",-,-,-,-,-,x,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
11,46,"Girardi, D., Lanubile, F., & Novielli, N. (2018). Emotion detection using noninvasive low cost sensors. 2018-January, 125–130. Scopus. https://doi.org/10.1109/ACII.2017.8273589",2018,dimensional,x,2,"LV, HV",-,-,-,-,-,x,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
12,47,"Ooi, J. S. K., Ahmad, S. A., Ishak, A. J., Minhad, K. N., Md Ali, S. H., & Chong, Y. Z. (2018). Grove: An auxiliary device for sympathetic assessment via EDA measurement of neutral, stress, and anger emotions during simulated driving conditions. International Journal of Medical Engineering and Informatics, 10(1), 16–29. Scopus. https://doi.org/10.1504/IJMEI.2018.090076",2018,categorical,x,2,"neutral, stress",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,x,"Figure 6 shows similar EDA signal behaviour during resting and recovery phases.
Signal constantly rises to a limit at this point before declining and rising again. Signals at
these phases had low fluctuation and sudden rise of amplitude because the subject sits in
a relaxed phase. This situation is similar to a neutral simulated driving condition. The
most frequent fluctuation of EDA signal was observed during anger-simulated driving,
followed by stress and neutral driving. This finding shows that the subject is endowed
with the most intense sympathetic response during anger, followed by stress and neutral
emotion. Further processing was required to determine significant differences of EDA
properties during different simulated driving tasks.
Figure 7 indicates that band-pass-filtered EDA signals at neutral simulated driving
tasks had similar response to control and recovery sessions, wherein the subject
demonstrates the least physiological response because of the simplicity of driving
scenario. The subject possesses a high level of physiological response during states of
anger than in stress-simulated driving tasks. The overall amplitude of signals is high and
the fluctuations of spikes occurred frequently.",-,-
12,48,"Ooi, J. S. K., Ahmad, S. A., Ishak, A. J., Minhad, K. N., Md Ali, S. H., & Chong, Y. Z. (2018). Grove: An auxiliary device for sympathetic assessment via EDA measurement of neutral, stress, and anger emotions during simulated driving conditions. International Journal of Medical Engineering and Informatics, 10(1), 16–29. Scopus. https://doi.org/10.1504/IJMEI.2018.090076",2018,categorical,x,2,"neutral, anger",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
12,49,"Ooi, J. S. K., Ahmad, S. A., Ishak, A. J., Minhad, K. N., Md Ali, S. H., & Chong, Y. Z. (2018). Grove: An auxiliary device for sympathetic assessment via EDA measurement of neutral, stress, and anger emotions during simulated driving conditions. International Journal of Medical Engineering and Informatics, 10(1), 16–29. Scopus. https://doi.org/10.1504/IJMEI.2018.090076",2018,categorical,x,2,"stress, anger",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
12,50,"Ooi, J. S. K., Ahmad, S. A., Ishak, A. J., Minhad, K. N., Md Ali, S. H., & Chong, Y. Z. (2018). Grove: An auxiliary device for sympathetic assessment via EDA measurement of neutral, stress, and anger emotions during simulated driving conditions. International Journal of Medical Engineering and Informatics, 10(1), 16–29. Scopus. https://doi.org/10.1504/IJMEI.2018.090076",2018,categorical,x,3,"neutral, stress, anger",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
13,51,"Setyohadi, D. B., Kusrohmaniah, S., Gunawan, S. B., Pranowo, & Prabuwono, A. S. (2018). Galvanic skin response data classification for emotion detection. International Journal of Electrical and Computer Engineering, 8(5), 4004–4014. Scopus. https://doi.org/10.11591/ijece.v8i5.pp4004-4014",2018,dimensional,x,3,"neutral, negative, positive",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,-,-,-,-,-,-,-
14,52,"Soleymani, M., & Mortillaro, M. (2018). Behavioral and physiological responses to visual interest and appraisals: Multimodal analysis and automatic recognition. Frontiers in ICT, 5(JUL). Scopus. https://doi.org/10.3389/fict.2018.00017",2018,dimensional,,-,-,-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,x,1,interest,-,-,-,,,,x,,,-,-,-,-,-,-,x,,-,-,,
14,53,"Soleymani, M., & Mortillaro, M. (2018). Behavioral and physiological responses to visual interest and appraisals: Multimodal analysis and automatic recognition. Frontiers in ICT, 5(JUL). Scopus. https://doi.org/10.3389/fict.2018.00017",2018,dimensional,,-,-,-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,x,1,curiosity,-,-,-,,,,x,,,-,-,-,-,-,-,x,,-,-,,
14,54,"Soleymani, M., & Mortillaro, M. (2018). Behavioral and physiological responses to visual interest and appraisals: Multimodal analysis and automatic recognition. Frontiers in ICT, 5(JUL). Scopus. https://doi.org/10.3389/fict.2018.00017",2018,dimensional,,-,-,-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,x,1,coping potential,-,-,-,,,,x,,,-,-,-,-,-,-,x,,-,-,,
14,55,"Soleymani, M., & Mortillaro, M. (2018). Behavioral and physiological responses to visual interest and appraisals: Multimodal analysis and automatic recognition. Frontiers in ICT, 5(JUL). Scopus. https://doi.org/10.3389/fict.2018.00017",2018,dimensional,,-,-,-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,x,1,novelty,-,-,-,,,,x,,,-,-,-,-,-,-,x,,-,-,,
14,56,"Soleymani, M., & Mortillaro, M. (2018). Behavioral and physiological responses to visual interest and appraisals: Multimodal analysis and automatic recognition. Frontiers in ICT, 5(JUL). Scopus. https://doi.org/10.3389/fict.2018.00017",2018,dimensional,,-,-,-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,x,1,complexity,-,-,-,,,,x,,,-,-,-,-,-,-,x,,-,-,,
14,57,"Soleymani, M., & Mortillaro, M. (2018). Behavioral and physiological responses to visual interest and appraisals: Multimodal analysis and automatic recognition. Frontiers in ICT, 5(JUL). Scopus. https://doi.org/10.3389/fict.2018.00017",2018,dimensional,,-,-,-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,x,1,interest,-,-,-,,,,x,,,-,-,-,-,-,-,x,,-,-,,
14,58,"Soleymani, M., & Mortillaro, M. (2018). Behavioral and physiological responses to visual interest and appraisals: Multimodal analysis and automatic recognition. Frontiers in ICT, 5(JUL). Scopus. https://doi.org/10.3389/fict.2018.00017",2018,dimensional,,-,-,-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,x,1,curiosity,-,-,-,,,,x,,,-,-,-,-,-,-,x,,-,-,,
14,59,"Soleymani, M., & Mortillaro, M. (2018). Behavioral and physiological responses to visual interest and appraisals: Multimodal analysis and automatic recognition. Frontiers in ICT, 5(JUL). Scopus. https://doi.org/10.3389/fict.2018.00017",2018,dimensional,,-,-,-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,x,1,coping potential,-,-,-,,,,x,,,-,-,-,-,-,-,x,,-,-,,
14,60,"Soleymani, M., & Mortillaro, M. (2018). Behavioral and physiological responses to visual interest and appraisals: Multimodal analysis and automatic recognition. Frontiers in ICT, 5(JUL). Scopus. https://doi.org/10.3389/fict.2018.00017",2018,dimensional,,-,-,-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,x,1,novelty,-,-,-,,,,x,,,-,-,-,-,-,-,x,,-,-,,
14,61,"Soleymani, M., & Mortillaro, M. (2018). Behavioral and physiological responses to visual interest and appraisals: Multimodal analysis and automatic recognition. Frontiers in ICT, 5(JUL). Scopus. https://doi.org/10.3389/fict.2018.00017",2018,dimensional,,-,-,-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,x,1,complexity,-,-,-,,,,x,,,-,-,-,-,-,-,x,,-,-,,
14,62,"Soleymani, M., & Mortillaro, M. (2018). Behavioral and physiological responses to visual interest and appraisals: Multimodal analysis and automatic recognition. Frontiers in ICT, 5(JUL). Scopus. https://doi.org/10.3389/fict.2018.00017",2018,dimensional,,-,-,-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,x,1,interest,-,-,-,,,,x,,,-,-,-,-,-,x,-,,-,-,,
14,63,"Soleymani, M., & Mortillaro, M. (2018). Behavioral and physiological responses to visual interest and appraisals: Multimodal analysis and automatic recognition. Frontiers in ICT, 5(JUL). Scopus. https://doi.org/10.3389/fict.2018.00017",2018,dimensional,,-,-,-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,x,1,curiosity,-,-,-,,,,x,,,-,-,-,-,-,x,-,,-,-,,
14,64,"Soleymani, M., & Mortillaro, M. (2018). Behavioral and physiological responses to visual interest and appraisals: Multimodal analysis and automatic recognition. Frontiers in ICT, 5(JUL). Scopus. https://doi.org/10.3389/fict.2018.00017",2018,dimensional,,-,-,-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,x,1,coping potential,-,-,-,,,,x,,,-,-,-,-,-,x,-,,-,-,,
14,65,"Soleymani, M., & Mortillaro, M. (2018). Behavioral and physiological responses to visual interest and appraisals: Multimodal analysis and automatic recognition. Frontiers in ICT, 5(JUL). Scopus. https://doi.org/10.3389/fict.2018.00017",2018,dimensional,,-,-,-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,x,1,novelty,-,-,-,,,,x,,,-,-,-,-,-,x,-,,-,-,,
14,66,"Soleymani, M., & Mortillaro, M. (2018). Behavioral and physiological responses to visual interest and appraisals: Multimodal analysis and automatic recognition. Frontiers in ICT, 5(JUL). Scopus. https://doi.org/10.3389/fict.2018.00017",2018,dimensional,,-,-,-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,x,1,complexity,-,-,-,,,,x,,,-,-,-,-,-,x,-,,-,-,,
15,67,"Md Ali, S. H., Ibne Reaz, M., Ahmad, S. A., Minhad, K. N., & Ooi, J. S. K. (2017). Low cost wearable sensor for human emotion recognition using skin conductance response. IEICE Transactions on Information and Systems, E100D(12), 3010–3017. Scopus. https://doi.org/10.1587/transinf.2017EDP7067",2017,categorical,x,2,"happy, anger",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
15,68,"Md Ali, S. H., Ibne Reaz, M., Ahmad, S. A., Minhad, K. N., & Ooi, J. S. K. (2017). Low cost wearable sensor for human emotion recognition using skin conductance response. IEICE Transactions on Information and Systems, E100D(12), 3010–3017. Scopus. https://doi.org/10.1587/transinf.2017EDP7067",2017,categorical,x,2,"happy, anger",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
15,69,"Md Ali, S. H., Ibne Reaz, M., Ahmad, S. A., Minhad, K. N., & Ooi, J. S. K. (2017). Low cost wearable sensor for human emotion recognition using skin conductance response. IEICE Transactions on Information and Systems, E100D(12), 3010–3017. Scopus. https://doi.org/10.1587/transinf.2017EDP7067",2017,categorical,x,2,"happy, neutral",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
15,70,"Md Ali, S. H., Ibne Reaz, M., Ahmad, S. A., Minhad, K. N., & Ooi, J. S. K. (2017). Low cost wearable sensor for human emotion recognition using skin conductance response. IEICE Transactions on Information and Systems, E100D(12), 3010–3017. Scopus. https://doi.org/10.1587/transinf.2017EDP7067",2017,categorical,x,2,"happy, recovery",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
15,71,"Md Ali, S. H., Ibne Reaz, M., Ahmad, S. A., Minhad, K. N., & Ooi, J. S. K. (2017). Low cost wearable sensor for human emotion recognition using skin conductance response. IEICE Transactions on Information and Systems, E100D(12), 3010–3017. Scopus. https://doi.org/10.1587/transinf.2017EDP7067",2017,categorical,x,2,"anger, neutral",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
15,72,"Md Ali, S. H., Ibne Reaz, M., Ahmad, S. A., Minhad, K. N., & Ooi, J. S. K. (2017). Low cost wearable sensor for human emotion recognition using skin conductance response. IEICE Transactions on Information and Systems, E100D(12), 3010–3017. Scopus. https://doi.org/10.1587/transinf.2017EDP7067",2017,categorical,x,2,"anger, recovery",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
15,73,"Md Ali, S. H., Ibne Reaz, M., Ahmad, S. A., Minhad, K. N., & Ooi, J. S. K. (2017). Low cost wearable sensor for human emotion recognition using skin conductance response. IEICE Transactions on Information and Systems, E100D(12), 3010–3017. Scopus. https://doi.org/10.1587/transinf.2017EDP7067",2017,categorical,x,2,"happy, anger",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
15,74,"Md Ali, S. H., Ibne Reaz, M., Ahmad, S. A., Minhad, K. N., & Ooi, J. S. K. (2017). Low cost wearable sensor for human emotion recognition using skin conductance response. IEICE Transactions on Information and Systems, E100D(12), 3010–3017. Scopus. https://doi.org/10.1587/transinf.2017EDP7067",2017,categorical,x,2,"happy, neutral",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
15,75,"Md Ali, S. H., Ibne Reaz, M., Ahmad, S. A., Minhad, K. N., & Ooi, J. S. K. (2017). Low cost wearable sensor for human emotion recognition using skin conductance response. IEICE Transactions on Information and Systems, E100D(12), 3010–3017. Scopus. https://doi.org/10.1587/transinf.2017EDP7067",2017,categorical,x,2,"happy, recovery",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
15,76,"Md Ali, S. H., Ibne Reaz, M., Ahmad, S. A., Minhad, K. N., & Ooi, J. S. K. (2017). Low cost wearable sensor for human emotion recognition using skin conductance response. IEICE Transactions on Information and Systems, E100D(12), 3010–3017. Scopus. https://doi.org/10.1587/transinf.2017EDP7067",2017,categorical,x,2,"anger, neutral",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
15,77,"Md Ali, S. H., Ibne Reaz, M., Ahmad, S. A., Minhad, K. N., & Ooi, J. S. K. (2017). Low cost wearable sensor for human emotion recognition using skin conductance response. IEICE Transactions on Information and Systems, E100D(12), 3010–3017. Scopus. https://doi.org/10.1587/transinf.2017EDP7067",2017,categorical,x,2,"anger, recovery",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
15,78,"Md Ali, S. H., Ibne Reaz, M., Ahmad, S. A., Minhad, K. N., & Ooi, J. S. K. (2017). Low cost wearable sensor for human emotion recognition using skin conductance response. IEICE Transactions on Information and Systems, E100D(12), 3010–3017. Scopus. https://doi.org/10.1587/transinf.2017EDP7067",2017,categorical,x,2,"happy, anger",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
15,79,"Md Ali, S. H., Ibne Reaz, M., Ahmad, S. A., Minhad, K. N., & Ooi, J. S. K. (2017). Low cost wearable sensor for human emotion recognition using skin conductance response. IEICE Transactions on Information and Systems, E100D(12), 3010–3017. Scopus. https://doi.org/10.1587/transinf.2017EDP7067",2017,categorical,x,2,"happy, neutral",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
15,80,"Md Ali, S. H., Ibne Reaz, M., Ahmad, S. A., Minhad, K. N., & Ooi, J. S. K. (2017). Low cost wearable sensor for human emotion recognition using skin conductance response. IEICE Transactions on Information and Systems, E100D(12), 3010–3017. Scopus. https://doi.org/10.1587/transinf.2017EDP7067",2017,categorical,x,2,"happy, recovery",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
15,81,"Md Ali, S. H., Ibne Reaz, M., Ahmad, S. A., Minhad, K. N., & Ooi, J. S. K. (2017). Low cost wearable sensor for human emotion recognition using skin conductance response. IEICE Transactions on Information and Systems, E100D(12), 3010–3017. Scopus. https://doi.org/10.1587/transinf.2017EDP7067",2017,categorical,x,2,"anger, neutral",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
15,82,"Md Ali, S. H., Ibne Reaz, M., Ahmad, S. A., Minhad, K. N., & Ooi, J. S. K. (2017). Low cost wearable sensor for human emotion recognition using skin conductance response. IEICE Transactions on Information and Systems, E100D(12), 3010–3017. Scopus. https://doi.org/10.1587/transinf.2017EDP7067",2017,categorical,x,2,"anger, recovery",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
15,83,"Md Ali, S. H., Ibne Reaz, M., Ahmad, S. A., Minhad, K. N., & Ooi, J. S. K. (2017). Low cost wearable sensor for human emotion recognition using skin conductance response. IEICE Transactions on Information and Systems, E100D(12), 3010–3017. Scopus. https://doi.org/10.1587/transinf.2017EDP7067",2017,categorical,x,2,"anger, stress",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
15,84,"Md Ali, S. H., Ibne Reaz, M., Ahmad, S. A., Minhad, K. N., & Ooi, J. S. K. (2017). Low cost wearable sensor for human emotion recognition using skin conductance response. IEICE Transactions on Information and Systems, E100D(12), 3010–3017. Scopus. https://doi.org/10.1587/transinf.2017EDP7067",2017,categorical,x,2,"anger, neutral",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
15,85,"Md Ali, S. H., Ibne Reaz, M., Ahmad, S. A., Minhad, K. N., & Ooi, J. S. K. (2017). Low cost wearable sensor for human emotion recognition using skin conductance response. IEICE Transactions on Information and Systems, E100D(12), 3010–3017. Scopus. https://doi.org/10.1587/transinf.2017EDP7067",2017,categorical,x,2,"stress, neutral",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
15,86,"Md Ali, S. H., Ibne Reaz, M., Ahmad, S. A., Minhad, K. N., & Ooi, J. S. K. (2017). Low cost wearable sensor for human emotion recognition using skin conductance response. IEICE Transactions on Information and Systems, E100D(12), 3010–3017. Scopus. https://doi.org/10.1587/transinf.2017EDP7067",2017,categorical,x,3,"happy, anger, neutral",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
15,87,"Md Ali, S. H., Ibne Reaz, M., Ahmad, S. A., Minhad, K. N., & Ooi, J. S. K. (2017). Low cost wearable sensor for human emotion recognition using skin conductance response. IEICE Transactions on Information and Systems, E100D(12), 3010–3017. Scopus. https://doi.org/10.1587/transinf.2017EDP7067",2017,categorical,x,3,"happy, anger, recovery",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
15,88,"Md Ali, S. H., Ibne Reaz, M., Ahmad, S. A., Minhad, K. N., & Ooi, J. S. K. (2017). Low cost wearable sensor for human emotion recognition using skin conductance response. IEICE Transactions on Information and Systems, E100D(12), 3010–3017. Scopus. https://doi.org/10.1587/transinf.2017EDP7067",2017,categorical,x,3,"happy, anger, neutral",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
15,89,"Md Ali, S. H., Ibne Reaz, M., Ahmad, S. A., Minhad, K. N., & Ooi, J. S. K. (2017). Low cost wearable sensor for human emotion recognition using skin conductance response. IEICE Transactions on Information and Systems, E100D(12), 3010–3017. Scopus. https://doi.org/10.1587/transinf.2017EDP7067",2017,categorical,x,3,"happy, anger, recovery",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
15,90,"Md Ali, S. H., Ibne Reaz, M., Ahmad, S. A., Minhad, K. N., & Ooi, J. S. K. (2017). Low cost wearable sensor for human emotion recognition using skin conductance response. IEICE Transactions on Information and Systems, E100D(12), 3010–3017. Scopus. https://doi.org/10.1587/transinf.2017EDP7067",2017,categorical,x,3,"happy, anger, neutral",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
15,91,"Md Ali, S. H., Ibne Reaz, M., Ahmad, S. A., Minhad, K. N., & Ooi, J. S. K. (2017). Low cost wearable sensor for human emotion recognition using skin conductance response. IEICE Transactions on Information and Systems, E100D(12), 3010–3017. Scopus. https://doi.org/10.1587/transinf.2017EDP7067",2017,categorical,x,3,"happy, anger, recovery",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
15,92,"Md Ali, S. H., Ibne Reaz, M., Ahmad, S. A., Minhad, K. N., & Ooi, J. S. K. (2017). Low cost wearable sensor for human emotion recognition using skin conductance response. IEICE Transactions on Information and Systems, E100D(12), 3010–3017. Scopus. https://doi.org/10.1587/transinf.2017EDP7067",2017,categorical,x,3,"anges, stress, neutral",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
16,93,"Wiem, M. B. H., & Lachiri, Z. (2017). Emotion sensing from physiological signals using three defined areas in arousal-valence model. 219–223. Scopus. https://doi.org/10.1109/CADIAG.2017.8075660",2017,dimensional,x,3,"calm arousal, medium arousal, excited arousal",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,,-,-,-,-,-
16,94,"Wiem, M. B. H., & Lachiri, Z. (2017). Emotion sensing from physiological signals using three defined areas in arousal-valence model. 219–223. Scopus. https://doi.org/10.1109/CADIAG.2017.8075660",2017,dimensional,x,3,"LV, neutral valence, HV",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,,-,-,-,-,-
17,95,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017,categorical,x,2,"happiness, rest",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-
17,96,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017,categorical,x,2,"happiness, rest",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-
17,97,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017,categorical,x,2,"happiness, rest",-,-,-,-,x,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-
17,98,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017,categorical,x,2,"happiness, rest",-,-,-,x,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-
17,99,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017,categorical,x,2,"happiness, others emotions",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-
17,100,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017,categorical,x,2,"happiness, others emotions",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-
17,101,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017,categorical,x,2,"happiness, others emotions",-,-,-,-,x,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-
17,102,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017,categorical,x,2,"happiness, others emotions",-,-,-,x,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-
17,103,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017,categorical,x,2,"peacefulness, rest",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-
17,104,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017,categorical,x,2,"peacefulness, rest",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-
17,105,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017,categorical,x,2,"peacefulness, rest",-,-,-,-,x,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-
17,106,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017,categorical,x,2,"peacefulness, rest",-,-,-,x,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-
17,107,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017,categorical,x,2,"peacefulness, others emotions",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-
17,108,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017,categorical,x,2,"peacefulness, others emotions",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-
17,109,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017,categorical,x,2,"peacefulness, others emotions",-,-,-,-,x,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-
17,110,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017,categorical,x,2,"peacefulness, others emotions",-,-,-,x,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-
17,111,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017,categorical,x,2,"sadness, rest",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-
17,112,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017,categorical,x,2,"sadness, rest",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-
17,113,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017,categorical,x,2,"sadness, rest",-,-,-,-,x,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-
17,114,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017,categorical,x,2,"sadness, rest",-,-,-,x,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-
17,115,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017,categorical,x,2,"sadness, others emotions",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-
17,116,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017,categorical,x,2,"sadness, others emotions",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-
17,117,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017,categorical,x,2,"sadness, others emotions",-,-,-,-,x,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-
17,118,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017,categorical,x,2,"sadness, others emotions",-,-,-,x,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-
17,119,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017,categorical,x,2,"fear, rest",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-
17,120,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017,categorical,x,2,"fear, rest",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-
17,121,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017,categorical,x,2,"fear, rest",-,-,-,-,x,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-
17,122,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017,categorical,x,2,"fear, rest",-,-,-,x,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-
17,123,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017,categorical,x,2,"fear, others emotions",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-
17,124,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017,categorical,x,2,"fear, others emotions",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-
17,125,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017,categorical,x,2,"fear, others emotions",-,-,-,-,x,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-
17,126,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2017). Discrimination between different emotional states based on the chaotic behavior of galvanic skin responses. Signal, Image and Video Processing, 11(7), 1347–1355. Scopus. https://doi.org/10.1007/s11760-017-1092-9",2017,categorical,x,2,"fear, others emotions",-,-,-,x,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,x,"After preprocessing and windowing the signals, several nonlinear features were extracted (Fig. 1). Lower SD1/SD2 ratios
emphasized on a more regular pattern of signals during happiness and sadness compared to fear and peacefulness. SD1
and SD2 measures mainly reflect parasympathetic, and both
sympathetic and parasympathetic activities, respectively. The
results revealed that based on the dimensional model, opposite emotions may have the same patterns of Poincare indices.
In addition, positive LEs revealed that GSR signals have
a chaotic trajectory which are derived from a chaotic system. The higher entropies indicated the higher irregularity of
GSR signals during fear. The lower RQA measures during all
emotional stimuli, a higher dimensional GSR signal can be
concluded. VMAX and LAM mark a time period in which the
state changes very slowly or does not change. Consequently,
higher values of the indices during rest condition reveal the
system stability. Next, three feature selection algorithms were
applied to the data",-,-
18,127,"Keren, G., Kirschstein, T., Marchi, E., Ringeval, F., & Schuller, B. (2017). End-to-end learning for dimensional emotion recognition from physiological signals. 985–990. Scopus. https://doi.org/10.1109/ICME.2017.8019533",2017,dimensional,,-,-,-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,x,1,arousal,-,-,-,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
18,128,"Keren, G., Kirschstein, T., Marchi, E., Ringeval, F., & Schuller, B. (2017). End-to-end learning for dimensional emotion recognition from physiological signals. 985–990. Scopus. https://doi.org/10.1109/ICME.2017.8019533",2017,dimensional,,-,-,-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,x,1,valence,-,-,-,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
19,129,"Hernández-García, A., Fernández-Martínez, F., & Díaz-De-maría, F. (2017). Emotion and attention: Predicting electrodermal activity through video visual descriptors. 914–923. Scopus. https://doi.org/10.1145/3106426.3109418",2017,dimensional,,-,-,-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,x,1,arousal,x,-,-,,,,,,,-,-,-,-,-,?,?,-,x,"The relationship between visual descriptors and other kind of
subjective information like aesthetics or appeal reported deliberately by participants via a score, for instance, had been already
demonstrated in previous works [16]. However, finding some correlation with EDA has a great interest because it is a psychophysiological reaction controlled by the autonomous nervous system,
thus it is automatic and is directly related to actual emotional and
attentional activation, avoiding the implicit bias of opinions and
judgments.
Correlation between the set of visual descriptors and SCL and
SCR was not so clear as in the case of SUM. One explanation for
this is that these measures alone reflect subtleties that are more
difficult to capture by simple methods and a relatively small set of
features",-,-
20,130,"Wiem, M. B. H., & Lachiri, Z. (2017). Emotion assessing using valence-arousal evaluation based on peripheral physiological signals and support vector machine. 4th International Conference on Control Engineering and Information Technology, CEIT 2016. Scopus. https://doi.org/10.1109/CEIT.2016.7929117",2017,dimensional,x,2,"LA, HA",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
20,131,"Wiem, M. B. H., & Lachiri, Z. (2017). Emotion assessing using valence-arousal evaluation based on peripheral physiological signals and support vector machine. 4th International Conference on Control Engineering and Information Technology, CEIT 2016. Scopus. https://doi.org/10.1109/CEIT.2016.7929117",2017,dimensional,x,2,"LV, HV",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,,-,-,x,-,-,-,-,-,-
21,132,"Xu, Y., Hubener, I., Seipp, A.-K., Ohly, S., & David, K. (2017). From the lab to the real-world: An investigation on the influence of human movement on Emotion Recognition using physiological signals. 345–350. Scopus. https://doi.org/10.1109/PERCOMW.2017.7917586",2017,dimensional,x,5,"HAHV, HALV, LAHV, LALV, neutral",,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Physiological measures in the real world are more complex
than those under laboratory conditions. In this paper, we have
shown that ER (Emotion Recognition) by using physiological
signals is influenced by human movements. We investigate
the recognition of a group of emotions by using various
physiological signals and commonly used algorithms in both,
the lab and a real-world scenario. Our results show that
the ST (Skin Temperature), EDA (Electrodermal Activity),
and EMG (Electromyography) signals achieve the highest
accuracies when the data is collected when the participants
are at rest. Our results show that the Decision Tree is the
best classification algorithm. From our work we can conclude,
that human movement influences the physiological signals
measured from a user, and therefore, influence the results of
the ER. For this reason, one must take this effect into account
when developing models for emotion recognition. ER models
based on controlled experiments cannot be accurately used to
recognize emotion in real-world scenarios.",,
21,133,"Xu, Y., Hubener, I., Seipp, A.-K., Ohly, S., & David, K. (2017). From the lab to the real-world: An investigation on the influence of human movement on Emotion Recognition using physiological signals. 345–350. Scopus. https://doi.org/10.1109/PERCOMW.2017.7917586",2017,dimensional,x,5,"HAHV, HALV, LAHV, LALV, neutral",,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Physiological measures in the real world are more complex
than those under laboratory conditions. In this paper, we have
shown that ER (Emotion Recognition) by using physiological
signals is influenced by human movements. We investigate
the recognition of a group of emotions by using various
physiological signals and commonly used algorithms in both,
the lab and a real-world scenario. Our results show that
the ST (Skin Temperature), EDA (Electrodermal Activity),
and EMG (Electromyography) signals achieve the highest
accuracies when the data is collected when the participants
are at rest. Our results show that the Decision Tree is the
best classification algorithm. From our work we can conclude,
that human movement influences the physiological signals
measured from a user, and therefore, influence the results of
the ER. For this reason, one must take this effect into account
when developing models for emotion recognition. ER models
based on controlled experiments cannot be accurately used to
recognize emotion in real-world scenarios.",,
21,134,"Xu, Y., Hubener, I., Seipp, A.-K., Ohly, S., & David, K. (2017). From the lab to the real-world: An investigation on the influence of human movement on Emotion Recognition using physiological signals. 345–350. Scopus. https://doi.org/10.1109/PERCOMW.2017.7917586",2017,dimensional,x,5,"HAHV, HALV, LAHV, LALV, neutral",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Physiological measures in the real world are more complex
than those under laboratory conditions. In this paper, we have
shown that ER (Emotion Recognition) by using physiological
signals is influenced by human movements. We investigate
the recognition of a group of emotions by using various
physiological signals and commonly used algorithms in both,
the lab and a real-world scenario. Our results show that
the ST (Skin Temperature), EDA (Electrodermal Activity),
and EMG (Electromyography) signals achieve the highest
accuracies when the data is collected when the participants
are at rest. Our results show that the Decision Tree is the
best classification algorithm. From our work we can conclude,
that human movement influences the physiological signals
measured from a user, and therefore, influence the results of
the ER. For this reason, one must take this effect into account
when developing models for emotion recognition. ER models
based on controlled experiments cannot be accurately used to
recognize emotion in real-world scenarios.",,
21,135,"Xu, Y., Hubener, I., Seipp, A.-K., Ohly, S., & David, K. (2017). From the lab to the real-world: An investigation on the influence of human movement on Emotion Recognition using physiological signals. 345–350. Scopus. https://doi.org/10.1109/PERCOMW.2017.7917586",2017,dimensional,x,5,"HAHV, HALV, LAHV, LALV, neutral",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Physiological measures in the real world are more complex
than those under laboratory conditions. In this paper, we have
shown that ER (Emotion Recognition) by using physiological
signals is influenced by human movements. We investigate
the recognition of a group of emotions by using various
physiological signals and commonly used algorithms in both,
the lab and a real-world scenario. Our results show that
the ST (Skin Temperature), EDA (Electrodermal Activity),
and EMG (Electromyography) signals achieve the highest
accuracies when the data is collected when the participants
are at rest. Our results show that the Decision Tree is the
best classification algorithm. From our work we can conclude,
that human movement influences the physiological signals
measured from a user, and therefore, influence the results of
the ER. For this reason, one must take this effect into account
when developing models for emotion recognition. ER models
based on controlled experiments cannot be accurately used to
recognize emotion in real-world scenarios.",,
21,136,"Xu, Y., Hubener, I., Seipp, A.-K., Ohly, S., & David, K. (2017). From the lab to the real-world: An investigation on the influence of human movement on Emotion Recognition using physiological signals. 345–350. Scopus. https://doi.org/10.1109/PERCOMW.2017.7917586",2017,dimensional,x,5,"HAHV, HALV, LAHV, LALV, neutral",,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Physiological measures in the real world are more complex
than those under laboratory conditions. In this paper, we have
shown that ER (Emotion Recognition) by using physiological
signals is influenced by human movements. We investigate
the recognition of a group of emotions by using various
physiological signals and commonly used algorithms in both,
the lab and a real-world scenario. Our results show that
the ST (Skin Temperature), EDA (Electrodermal Activity),
and EMG (Electromyography) signals achieve the highest
accuracies when the data is collected when the participants
are at rest. Our results show that the Decision Tree is the
best classification algorithm. From our work we can conclude,
that human movement influences the physiological signals
measured from a user, and therefore, influence the results of
the ER. For this reason, one must take this effect into account
when developing models for emotion recognition. ER models
based on controlled experiments cannot be accurately used to
recognize emotion in real-world scenarios.",,
21,137,"Xu, Y., Hubener, I., Seipp, A.-K., Ohly, S., & David, K. (2017). From the lab to the real-world: An investigation on the influence of human movement on Emotion Recognition using physiological signals. 345–350. Scopus. https://doi.org/10.1109/PERCOMW.2017.7917586",2017,dimensional,x,5,"HAHV, HALV, LAHV, LALV, neutral",,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Physiological measures in the real world are more complex
than those under laboratory conditions. In this paper, we have
shown that ER (Emotion Recognition) by using physiological
signals is influenced by human movements. We investigate
the recognition of a group of emotions by using various
physiological signals and commonly used algorithms in both,
the lab and a real-world scenario. Our results show that
the ST (Skin Temperature), EDA (Electrodermal Activity),
and EMG (Electromyography) signals achieve the highest
accuracies when the data is collected when the participants
are at rest. Our results show that the Decision Tree is the
best classification algorithm. From our work we can conclude,
that human movement influences the physiological signals
measured from a user, and therefore, influence the results of
the ER. For this reason, one must take this effect into account
when developing models for emotion recognition. ER models
based on controlled experiments cannot be accurately used to
recognize emotion in real-world scenarios.",,
21,138,"Xu, Y., Hubener, I., Seipp, A.-K., Ohly, S., & David, K. (2017). From the lab to the real-world: An investigation on the influence of human movement on Emotion Recognition using physiological signals. 345–350. Scopus. https://doi.org/10.1109/PERCOMW.2017.7917586",2017,dimensional,x,5,"HAHV, HALV, LAHV, LALV, neutral",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Physiological measures in the real world are more complex
than those under laboratory conditions. In this paper, we have
shown that ER (Emotion Recognition) by using physiological
signals is influenced by human movements. We investigate
the recognition of a group of emotions by using various
physiological signals and commonly used algorithms in both,
the lab and a real-world scenario. Our results show that
the ST (Skin Temperature), EDA (Electrodermal Activity),
and EMG (Electromyography) signals achieve the highest
accuracies when the data is collected when the participants
are at rest. Our results show that the Decision Tree is the
best classification algorithm. From our work we can conclude,
that human movement influences the physiological signals
measured from a user, and therefore, influence the results of
the ER. For this reason, one must take this effect into account
when developing models for emotion recognition. ER models
based on controlled experiments cannot be accurately used to
recognize emotion in real-world scenarios.",,
21,139,"Xu, Y., Hubener, I., Seipp, A.-K., Ohly, S., & David, K. (2017). From the lab to the real-world: An investigation on the influence of human movement on Emotion Recognition using physiological signals. 345–350. Scopus. https://doi.org/10.1109/PERCOMW.2017.7917586",2017,dimensional,x,5,"HAHV, HALV, LAHV, LALV, neutral",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Physiological measures in the real world are more complex
than those under laboratory conditions. In this paper, we have
shown that ER (Emotion Recognition) by using physiological
signals is influenced by human movements. We investigate
the recognition of a group of emotions by using various
physiological signals and commonly used algorithms in both,
the lab and a real-world scenario. Our results show that
the ST (Skin Temperature), EDA (Electrodermal Activity),
and EMG (Electromyography) signals achieve the highest
accuracies when the data is collected when the participants
are at rest. Our results show that the Decision Tree is the
best classification algorithm. From our work we can conclude,
that human movement influences the physiological signals
measured from a user, and therefore, influence the results of
the ER. For this reason, one must take this effect into account
when developing models for emotion recognition. ER models
based on controlled experiments cannot be accurately used to
recognize emotion in real-world scenarios.",,
21,140,"Xu, Y., Hubener, I., Seipp, A.-K., Ohly, S., & David, K. (2017). From the lab to the real-world: An investigation on the influence of human movement on Emotion Recognition using physiological signals. 345–350. Scopus. https://doi.org/10.1109/PERCOMW.2017.7917586",2017,dimensional,x,5,"HAHV, HALV, LAHV, LALV, neutral",,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Physiological measures in the real world are more complex
than those under laboratory conditions. In this paper, we have
shown that ER (Emotion Recognition) by using physiological
signals is influenced by human movements. We investigate
the recognition of a group of emotions by using various
physiological signals and commonly used algorithms in both,
the lab and a real-world scenario. Our results show that
the ST (Skin Temperature), EDA (Electrodermal Activity),
and EMG (Electromyography) signals achieve the highest
accuracies when the data is collected when the participants
are at rest. Our results show that the Decision Tree is the
best classification algorithm. From our work we can conclude,
that human movement influences the physiological signals
measured from a user, and therefore, influence the results of
the ER. For this reason, one must take this effect into account
when developing models for emotion recognition. ER models
based on controlled experiments cannot be accurately used to
recognize emotion in real-world scenarios.",,
21,141,"Xu, Y., Hubener, I., Seipp, A.-K., Ohly, S., & David, K. (2017). From the lab to the real-world: An investigation on the influence of human movement on Emotion Recognition using physiological signals. 345–350. Scopus. https://doi.org/10.1109/PERCOMW.2017.7917586",2017,dimensional,x,5,"HAHV, HALV, LAHV, LALV, neutral",,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Physiological measures in the real world are more complex
than those under laboratory conditions. In this paper, we have
shown that ER (Emotion Recognition) by using physiological
signals is influenced by human movements. We investigate
the recognition of a group of emotions by using various
physiological signals and commonly used algorithms in both,
the lab and a real-world scenario. Our results show that
the ST (Skin Temperature), EDA (Electrodermal Activity),
and EMG (Electromyography) signals achieve the highest
accuracies when the data is collected when the participants
are at rest. Our results show that the Decision Tree is the
best classification algorithm. From our work we can conclude,
that human movement influences the physiological signals
measured from a user, and therefore, influence the results of
the ER. For this reason, one must take this effect into account
when developing models for emotion recognition. ER models
based on controlled experiments cannot be accurately used to
recognize emotion in real-world scenarios.",,
21,142,"Xu, Y., Hubener, I., Seipp, A.-K., Ohly, S., & David, K. (2017). From the lab to the real-world: An investigation on the influence of human movement on Emotion Recognition using physiological signals. 345–350. Scopus. https://doi.org/10.1109/PERCOMW.2017.7917586",2017,dimensional,x,5,"HAHV, HALV, LAHV, LALV, neutral",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Physiological measures in the real world are more complex
than those under laboratory conditions. In this paper, we have
shown that ER (Emotion Recognition) by using physiological
signals is influenced by human movements. We investigate
the recognition of a group of emotions by using various
physiological signals and commonly used algorithms in both,
the lab and a real-world scenario. Our results show that
the ST (Skin Temperature), EDA (Electrodermal Activity),
and EMG (Electromyography) signals achieve the highest
accuracies when the data is collected when the participants
are at rest. Our results show that the Decision Tree is the
best classification algorithm. From our work we can conclude,
that human movement influences the physiological signals
measured from a user, and therefore, influence the results of
the ER. For this reason, one must take this effect into account
when developing models for emotion recognition. ER models
based on controlled experiments cannot be accurately used to
recognize emotion in real-world scenarios.",,
21,143,"Xu, Y., Hubener, I., Seipp, A.-K., Ohly, S., & David, K. (2017). From the lab to the real-world: An investigation on the influence of human movement on Emotion Recognition using physiological signals. 345–350. Scopus. https://doi.org/10.1109/PERCOMW.2017.7917586",2017,dimensional,x,5,"HAHV, HALV, LAHV, LALV, neutral",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Physiological measures in the real world are more complex
than those under laboratory conditions. In this paper, we have
shown that ER (Emotion Recognition) by using physiological
signals is influenced by human movements. We investigate
the recognition of a group of emotions by using various
physiological signals and commonly used algorithms in both,
the lab and a real-world scenario. Our results show that
the ST (Skin Temperature), EDA (Electrodermal Activity),
and EMG (Electromyography) signals achieve the highest
accuracies when the data is collected when the participants
are at rest. Our results show that the Decision Tree is the
best classification algorithm. From our work we can conclude,
that human movement influences the physiological signals
measured from a user, and therefore, influence the results of
the ER. For this reason, one must take this effect into account
when developing models for emotion recognition. ER models
based on controlled experiments cannot be accurately used to
recognize emotion in real-world scenarios.",,
22,144,"Nisa’Minhad, K., Ali, S. H. M., Khai, J. O. S., & Ahmad, S. A. (2017). Human emotion classifications for automotive driver using skin conductance response signal. 371–375. Scopus. https://doi.org/10.1109/ICAEES.2016.7888072",2017,categorical,x,5,"happy, sad, anger, disgust, fear",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,,,,-,-,,
22,145,"Nisa’Minhad, K., Ali, S. H. M., Khai, J. O. S., & Ahmad, S. A. (2017). Human emotion classifications for automotive driver using skin conductance response signal. 371–375. Scopus. https://doi.org/10.1109/ICAEES.2016.7888072",2017,categorical,x,5,"happy, sad, anger, disgust, fear",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,,,,-,-,,
22,146,"Nisa’Minhad, K., Ali, S. H. M., Khai, J. O. S., & Ahmad, S. A. (2017). Human emotion classifications for automotive driver using skin conductance response signal. 371–375. Scopus. https://doi.org/10.1109/ICAEES.2016.7888072",2017,categorical,x,5,"happy, sad, anger, disgust, fear",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,,,,-,-,,
23,147,"Ayata, D., Yaslan, Y., & Kamasak, M. (2017). Emotion recognition via random forest and galvanic skin response: Comparison of time based feature sets, window sizes and wavelet approaches. 2016 Medical Technologies National Conference, TIPTEKNO 2016. Scopus. https://doi.org/10.1109/TIPTEKNO.2016.7863130",2017,dimensional,x,2,"LA, HA",-,-,-,-,-,x,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,1280,-,-,-,-
23,148,"Ayata, D., Yaslan, Y., & Kamasak, M. (2017). Emotion recognition via random forest and galvanic skin response: Comparison of time based feature sets, window sizes and wavelet approaches. 2016 Medical Technologies National Conference, TIPTEKNO 2016. Scopus. https://doi.org/10.1109/TIPTEKNO.2016.7863130",2017,dimensional,x,2,"LV, HV",-,-,-,-,-,x,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
24,149,"Greco, A., Valenza, G., Citi, L., & Scilingo, E. P. (2017). Arousal and valence recognition of affective sounds based on electrodermal activity. IEEE Sensors Journal, 17(3), 716–725. Scopus. https://doi.org/10.1109/JSEN.2016.2623677",2017,dimensional,x,3,"LA, medium arousal, HA",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,,-,-,,,,,,,-,-,-,-,-,x,-,75,-,-,-,-
24,150,"Greco, A., Valenza, G., Citi, L., & Scilingo, E. P. (2017). Arousal and valence recognition of affective sounds based on electrodermal activity. IEEE Sensors Journal, 17(3), 716–725. Scopus. https://doi.org/10.1109/JSEN.2016.2623677",2017,dimensional,x,2,"LV, HV",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,,-,-,,,,,,,-,-,-,-,-,x,-,150,-,-,-,-
25,151,"Minhad, K. N., Ali, S. H. M. D., & Reaz, M. B. I. (2017). A design framework for human emotion recognition using electrocardiogram and skin conductance response signals. Journal of Engineering Science and Technology, 12(11), 3102–3119. Scopus.",2017,categorical,x,5,"happy, sad, anger, disgust, fear",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,,,,-,-,-,-
25,152,"Minhad, K. N., Ali, S. H. M. D., & Reaz, M. B. I. (2017). A design framework for human emotion recognition using electrocardiogram and skin conductance response signals. Journal of Engineering Science and Technology, 12(11), 3102–3119. Scopus.",2017,categorical,x,5,"happy, sad, anger, disgust, fear",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,,,,-,-,-,-
25,153,"Minhad, K. N., Ali, S. H. M. D., & Reaz, M. B. I. (2017). A design framework for human emotion recognition using electrocardiogram and skin conductance response signals. Journal of Engineering Science and Technology, 12(11), 3102–3119. Scopus.",2017,categorical,x,5,"happy, sad, anger, disgust, fear",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,,,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,,,-,-,-,-,-
26,154,"Zhang, Q., Lai, X., & Liu, G. (2016). Emotion recognition of GSR based on an improved quantum neural network. 1, 488–492. Scopus. https://doi.org/10.1109/IHMSC.2016.66",2016,categorical,x,5,"happy, grief, fear, angry, calm",-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,x,,,,,,,,-,,-,-,,-,-,,,,,,,-,-,-,-,-,x,-,175,-,-,-,-
27,155,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2016). A novel signal-based fusion approach for accurate music emotion recognition. Biomedical Engineering - Applications, Basis and Communications, 28(6). Scopus. https://doi.org/10.4015/S101623721650040X",2016,categorical,x,5,"happy, sad, scary, peaceful, rest",-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,,-,-,-,x,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
27,156,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2016). A novel signal-based fusion approach for accurate music emotion recognition. Biomedical Engineering - Applications, Basis and Communications, 28(6). Scopus. https://doi.org/10.4015/S101623721650040X",2016,dimensional,x,3,"LA, HA, rest",-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,,-,-,-,x,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
27,157,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2016). A novel signal-based fusion approach for accurate music emotion recognition. Biomedical Engineering - Applications, Basis and Communications, 28(6). Scopus. https://doi.org/10.4015/S101623721650040X",2016,dimensional,x,3,"LV, HV, rest",-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,,-,-,-,x,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
28,158,"Das, P., Khasnobish, A., & Tibarewala, D. N. (2016). Emotion recognition employing ECG and GSR signals as markers of ANS. 37–42. Scopus. https://doi.org/10.1109/CASP.2016.7746134",2016,categorical,x,2,"happy, sad",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,-,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,-,-,-,-,-,-,-
28,159,"Das, P., Khasnobish, A., & Tibarewala, D. N. (2016). Emotion recognition employing ECG and GSR signals as markers of ANS. 37–42. Scopus. https://doi.org/10.1109/CASP.2016.7746134",2016,categorical,x,2,"happy, sad",-,-,-,-,-,-,x,,,,,,,,,,-,-,-,,-,-,-,-,-,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,-,-,-,-,-,-,-
28,160,"Das, P., Khasnobish, A., & Tibarewala, D. N. (2016). Emotion recognition employing ECG and GSR signals as markers of ANS. 37–42. Scopus. https://doi.org/10.1109/CASP.2016.7746134",2016,categorical,x,2,"happy, sad",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,-,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,-,-,-,-,-,-,-
28,161,"Das, P., Khasnobish, A., & Tibarewala, D. N. (2016). Emotion recognition employing ECG and GSR signals as markers of ANS. 37–42. Scopus. https://doi.org/10.1109/CASP.2016.7746134",2016,categorical,x,2,"happy, neutral",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,-,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,-,-,-,-,-,-,-
28,162,"Das, P., Khasnobish, A., & Tibarewala, D. N. (2016). Emotion recognition employing ECG and GSR signals as markers of ANS. 37–42. Scopus. https://doi.org/10.1109/CASP.2016.7746134",2016,categorical,x,2,"happy, neutral",-,-,-,-,-,-,x,,,,,,,,,,-,-,-,,-,-,-,-,-,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,-,-,-,-,-,-,-
28,163,"Das, P., Khasnobish, A., & Tibarewala, D. N. (2016). Emotion recognition employing ECG and GSR signals as markers of ANS. 37–42. Scopus. https://doi.org/10.1109/CASP.2016.7746134",2016,categorical,x,2,"happy, neutral",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,-,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,-,-,-,-,-,-,-
28,164,"Das, P., Khasnobish, A., & Tibarewala, D. N. (2016). Emotion recognition employing ECG and GSR signals as markers of ANS. 37–42. Scopus. https://doi.org/10.1109/CASP.2016.7746134",2016,categorical,x,2,"sad, neutral",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,-,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,-,-,-,-,-,-,-
28,165,"Das, P., Khasnobish, A., & Tibarewala, D. N. (2016). Emotion recognition employing ECG and GSR signals as markers of ANS. 37–42. Scopus. https://doi.org/10.1109/CASP.2016.7746134",2016,categorical,x,2,"sad, neutral",-,-,-,-,-,-,x,,,,,,,,,,-,-,-,,-,-,-,-,-,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,-,-,-,-,-,-,-
28,166,"Das, P., Khasnobish, A., & Tibarewala, D. N. (2016). Emotion recognition employing ECG and GSR signals as markers of ANS. 37–42. Scopus. https://doi.org/10.1109/CASP.2016.7746134",2016,categorical,x,2,"sad, neutral",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,-,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,-,-,-,-,-,-,-
29,167,"Gupta, R., Abadi, M. K., Cabré, J. A. C., Morreale, F., Falk, T. H., & Sebe, N. (2016). A quality adaptive multimodal affect recognition system for user-centric multimedia indexing. 317–320. Scopus. https://doi.org/10.1145/2911996.2912059",2016,dimensional,x,2,"LA, HA",-,x,-,-,-,-,-,,,,,,,,,,-,-,,,-,-,-,-,-,,,,,,,-,,-,-,-,-,-,,,,,,,-,,-,-,-,x,-,,x,"Furthermore, it is worth noting that quality adaptive arousal and
valence classifiers performed significantly above chance on all the
modalities except on valence recognition using GSR that is in corroboration
with the finding in [7]. It is worthy to mention that low
unimodal performances on GSR could be due to the fact that GSR
responses are slow. Therefore, GSR is an unsuitable modality for
an experiment with short recordings like ours.",-,-
29,168,"Gupta, R., Abadi, M. K., Cabré, J. A. C., Morreale, F., Falk, T. H., & Sebe, N. (2016). A quality adaptive multimodal affect recognition system for user-centric multimedia indexing. 317–320. Scopus. https://doi.org/10.1145/2911996.2912059",2016,dimensional,x,2,"LA, HA",-,-,-,-,-,-,x,,,,,,,,,,-,-,,,-,-,-,-,-,,,,,,,-,,-,-,-,-,-,,,,,,,-,,-,-,-,x,-,,x,"Furthermore, it is worth noting that quality adaptive arousal and
valence classifiers performed significantly above chance on all the
modalities except on valence recognition using GSR that is in corroboration
with the finding in [7]. It is worthy to mention that low
unimodal performances on GSR could be due to the fact that GSR
responses are slow. Therefore, GSR is an unsuitable modality for
an experiment with short recordings like ours.",-,-
29,169,"Gupta, R., Abadi, M. K., Cabré, J. A. C., Morreale, F., Falk, T. H., & Sebe, N. (2016). A quality adaptive multimodal affect recognition system for user-centric multimedia indexing. 317–320. Scopus. https://doi.org/10.1145/2911996.2912059",2016,dimensional,x,2,"LV, HV",-,x,-,-,-,-,-,,,,,,,,,,-,-,,,-,-,-,-,-,,,,,,,-,,-,-,-,-,-,,,,,,,-,,-,-,-,x,-,,x,"Furthermore, it is worth noting that quality adaptive arousal and
valence classifiers performed significantly above chance on all the
modalities except on valence recognition using GSR that is in corroboration
with the finding in [7]. It is worthy to mention that low
unimodal performances on GSR could be due to the fact that GSR
responses are slow. Therefore, GSR is an unsuitable modality for
an experiment with short recordings like ours.",-,-
29,170,"Gupta, R., Abadi, M. K., Cabré, J. A. C., Morreale, F., Falk, T. H., & Sebe, N. (2016). A quality adaptive multimodal affect recognition system for user-centric multimedia indexing. 317–320. Scopus. https://doi.org/10.1145/2911996.2912059",2016,dimensional,x,2,"LV, HV",-,-,-,-,-,-,x,,,,,,,,,,-,-,,,-,-,-,-,-,,,,,,,-,,-,-,-,-,-,,,,,,,-,,-,-,-,x,-,,x,"Furthermore, it is worth noting that quality adaptive arousal and
valence classifiers performed significantly above chance on all the
modalities except on valence recognition using GSR that is in corroboration
with the finding in [7]. It is worthy to mention that low
unimodal performances on GSR could be due to the fact that GSR
responses are slow. Therefore, GSR is an unsuitable modality for
an experiment with short recordings like ours.",-,-
29,171,"Gupta, R., Abadi, M. K., Cabré, J. A. C., Morreale, F., Falk, T. H., & Sebe, N. (2016). A quality adaptive multimodal affect recognition system for user-centric multimedia indexing. 317–320. Scopus. https://doi.org/10.1145/2911996.2912059",2016,dimensional,x,2,"LL, HL",-,x,-,-,-,-,-,,,,,,,,,,-,-,,,-,-,-,-,-,,,,,,,-,,-,-,-,-,-,,,,,,,-,,-,-,-,x,-,,x,"Furthermore, it is worth noting that quality adaptive arousal and
valence classifiers performed significantly above chance on all the
modalities except on valence recognition using GSR that is in corroboration
with the finding in [7]. It is worthy to mention that low
unimodal performances on GSR could be due to the fact that GSR
responses are slow. Therefore, GSR is an unsuitable modality for
an experiment with short recordings like ours.",-,-
29,172,"Gupta, R., Abadi, M. K., Cabré, J. A. C., Morreale, F., Falk, T. H., & Sebe, N. (2016). A quality adaptive multimodal affect recognition system for user-centric multimedia indexing. 317–320. Scopus. https://doi.org/10.1145/2911996.2912059",2016,dimensional,x,2,"LL, HL",-,-,-,-,-,-,x,,,,,,,,,,-,-,,,-,-,-,-,-,,,,,,,-,,-,-,-,-,-,,,,,,,-,,-,-,-,x,-,-,x,"Furthermore, it is worth noting that quality adaptive arousal and
valence classifiers performed significantly above chance on all the
modalities except on valence recognition using GSR that is in corroboration
with the finding in [7]. It is worthy to mention that low
unimodal performances on GSR could be due to the fact that GSR
responses are slow. Therefore, GSR is an unsuitable modality for
an experiment with short recordings like ours.",-,-
30,173,"Ooi, J. S. K., Ahmad, S. A., Chong, Y. Z., Ali, S. H. M., Ai, G., & Wagatsuma, H. (2016). Driver emotion recognition framework based on electrodermal activity measurements during simulated driving conditions. 365–369. Scopus. https://doi.org/10.1109/IECBES.2016.7843475",2016,categorical,x,2,"neutral, stress",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,-,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,x,"Poor classification accuracy may arise because anger, fear,
or stress emotions fall at the same section according to the
valence–arousal and pleasant–unpleasant models [20][25].
Consequently, humans possess similar physiological
characteristics during these two emotions, leading to poor
classification accuracy. A number of research have also
demonstrated that the emotions of drivers differ considerably
in vulnerability to disturbance. Therefore, EDA measurements
for this experiment are still insufficient in detecting slight
physiological changes between anger and stress.",-,-
30,174,"Ooi, J. S. K., Ahmad, S. A., Chong, Y. Z., Ali, S. H. M., Ai, G., & Wagatsuma, H. (2016). Driver emotion recognition framework based on electrodermal activity measurements during simulated driving conditions. 365–369. Scopus. https://doi.org/10.1109/IECBES.2016.7843475",2016,categorical,x,2,"neutral, anger",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,-,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,x,"Poor classification accuracy may arise because anger, fear,
or stress emotions fall at the same section according to the
valence–arousal and pleasant–unpleasant models [20][25].
Consequently, humans possess similar physiological
characteristics during these two emotions, leading to poor
classification accuracy. A number of research have also
demonstrated that the emotions of drivers differ considerably
in vulnerability to disturbance. Therefore, EDA measurements
for this experiment are still insufficient in detecting slight
physiological changes between anger and stress.",-,-
30,175,"Ooi, J. S. K., Ahmad, S. A., Chong, Y. Z., Ali, S. H. M., Ai, G., & Wagatsuma, H. (2016). Driver emotion recognition framework based on electrodermal activity measurements during simulated driving conditions. 365–369. Scopus. https://doi.org/10.1109/IECBES.2016.7843475",2016,categorical,x,2,"stress, anger",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,-,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,x,"Poor classification accuracy may arise because anger, fear,
or stress emotions fall at the same section according to the
valence–arousal and pleasant–unpleasant models [20][25].
Consequently, humans possess similar physiological
characteristics during these two emotions, leading to poor
classification accuracy. A number of research have also
demonstrated that the emotions of drivers differ considerably
in vulnerability to disturbance. Therefore, EDA measurements
for this experiment are still insufficient in detecting slight
physiological changes between anger and stress.",-,-
31,176,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2016). Fusion framework for emotional electrocardiogram and galvanic skin response recognition: Applying wavelet transform. Iranian Journal of Medical Physics, 13(3), 163–173. Scopus. https://doi.org/10.22038/ijmp.2016.7960",2016,categorical,x,5,"happy, sad, scary, peaceful, rest",-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,x,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
31,177,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2016). Fusion framework for emotional electrocardiogram and galvanic skin response recognition: Applying wavelet transform. Iranian Journal of Medical Physics, 13(3), 163–173. Scopus. https://doi.org/10.22038/ijmp.2016.7960",2016,dimensional,x,3,"LA, HA, rest",-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,x,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
31,178,"Goshvarpour, A., Abbasi, A., Goshvarpour, A., & Daneshvar, S. (2016). Fusion framework for emotional electrocardiogram and galvanic skin response recognition: Applying wavelet transform. Iranian Journal of Medical Physics, 13(3), 163–173. Scopus. https://doi.org/10.22038/ijmp.2016.7960",2016,dimensional,x,3,"LV, HV, rest",-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,x,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
32,179,"Siddharth,  null, Jung, T.-P., & Sejnowski, T. J. (2018). Multi-modal Approach for Affective Computing. Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Annual International Conference, 2018, 291–294. https://doi.org/10.1109/EMBC.2018.8512320",2018,dimensional,x,2,"LA, HA",-,-,-,-,-,-,-,,,,,,,,,,-,-,,,-,-,-,-,-,,x,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,128,-,-,-,-
32,180,"Siddharth,  null, Jung, T.-P., & Sejnowski, T. J. (2018). Multi-modal Approach for Affective Computing. Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Annual International Conference, 2018, 291–294. https://doi.org/10.1109/EMBC.2018.8512320",2018,dimensional,x,2,"LV, HV",-,-,-,-,-,-,-,,,,,,,,,,-,-,,,-,-,-,-,-,,x,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,128,-,-,-,-
32,181,"Siddharth,  null, Jung, T.-P., & Sejnowski, T. J. (2018). Multi-modal Approach for Affective Computing. Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Annual International Conference, 2018, 291–294. https://doi.org/10.1109/EMBC.2018.8512320",2018,dimensional,x,2,"LL, HL",-,-,-,-,-,-,-,,,,,,,,,,-,-,,,-,-,-,-,-,,x,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,128,-,-,-,-
32,182,"Siddharth,  null, Jung, T.-P., & Sejnowski, T. J. (2018). Multi-modal Approach for Affective Computing. Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Annual International Conference, 2018, 291–294. https://doi.org/10.1109/EMBC.2018.8512320",2018,dimensional,x,2,"LD, HD",-,-,-,-,-,-,-,,,,,,,,,,-,-,,,-,-,-,-,-,,x,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,128,-,-,-,-
32,183,"Siddharth,  null, Jung, T.-P., & Sejnowski, T. J. (2018). Multi-modal Approach for Affective Computing. Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Annual International Conference, 2018, 291–294. https://doi.org/10.1109/EMBC.2018.8512320",2018,dimensional,x,4,"HAHV, HALV, LAHV, LALV",-,-,-,-,-,-,-,,,,,,,,,,-,-,,,-,-,-,-,-,,x,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,128,-,-,-,-
32,184,"Siddharth,  null, Jung, T.-P., & Sejnowski, T. J. (2018). Multi-modal Approach for Affective Computing. Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Annual International Conference, 2018, 291–294. https://doi.org/10.1109/EMBC.2018.8512320",2018,dimensional,x,8,"pleased, excited, annoying, nervous, sad, sleepy, calm, relaxed",-,-,-,-,-,-,-,,,,,,,,,,-,-,,,-,-,-,-,-,,x,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,128,-,-,-,-
33,185,"Goshvarpour, A., Abbasi, A., & Goshvarpour, A. (2017). An accurate emotion recognition system using ECG and GSR signals and matching pursuit method. Biomedical Journal, 40(6), 355–368. https://doi.org/10.1016/j.bj.2017.11.001",2017,categorical,x,5,"happiness, sadness, scary, peacefulness, rest",-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,x,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
33,186,"Goshvarpour, A., Abbasi, A., & Goshvarpour, A. (2017). An accurate emotion recognition system using ECG and GSR signals and matching pursuit method. Biomedical Journal, 40(6), 355–368. https://doi.org/10.1016/j.bj.2017.11.001",2017,dimensional,x,3,"LA, HA, rest",-,-,-,-,-,-,,,,,,,,,,,-,-,-,,-,-,-,-,x,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
33,187,"Goshvarpour, A., Abbasi, A., & Goshvarpour, A. (2017). An accurate emotion recognition system using ECG and GSR signals and matching pursuit method. Biomedical Journal, 40(6), 355–368. https://doi.org/10.1016/j.bj.2017.11.001",2017,dimensional,x,3,"LV, HV, rest",-,-,-,-,-,-,-,,,,,,,,,,-,,-,,-,-,-,-,x,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
33,188,"Goshvarpour, A., Abbasi, A., & Goshvarpour, A. (2017). An accurate emotion recognition system using ECG and GSR signals and matching pursuit method. Biomedical Journal, 40(6), 355–368. https://doi.org/10.1016/j.bj.2017.11.001",2017,categorical,x,5,"happiness, sadness, scary, peacefulness, rest",-,-,-,-,-,-,-,,,,,,,,,,-,,-,,-,-,-,-,x,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,-,x,-,-,-,-,-
33,189,"Goshvarpour, A., Abbasi, A., & Goshvarpour, A. (2017). An accurate emotion recognition system using ECG and GSR signals and matching pursuit method. Biomedical Journal, 40(6), 355–368. https://doi.org/10.1016/j.bj.2017.11.001",2017,dimensional,x,3,"LA, HA, rest",-,-,-,-,-,-,-,,,,,,,,,,-,,-,,-,-,-,-,x,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,-,x,-,-,-,-,-
33,190,"Goshvarpour, A., Abbasi, A., & Goshvarpour, A. (2017). An accurate emotion recognition system using ECG and GSR signals and matching pursuit method. Biomedical Journal, 40(6), 355–368. https://doi.org/10.1016/j.bj.2017.11.001",2017,dimensional,x,3,"LV, HV, rest",-,-,-,-,-,-,-,,,,,,,,,,-,,-,,-,-,-,-,x,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,-,x,-,-,-,-,-
34,191,"Dumitriu, T., Cimpanu, C., Ungureanu, F., & Manta, V.-I. (2018). Experimental analysis of emotion classification techniques. 63–70. Scopus. https://doi.org/10.1109/ICCP.2018.8516647",2018,dimensional,x,2,"LV, HV, neutral",-,-,-,-,x,-,-,,,,,,,,,,-,-,-,,-,-,-,-,-,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
34,192,"Dumitriu, T., Cimpanu, C., Ungureanu, F., & Manta, V.-I. (2018). Experimental analysis of emotion classification techniques. 63–70. Scopus. https://doi.org/10.1109/ICCP.2018.8516648",2018,dimensional,x,3,"LV, HV, neutral",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,-,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
34,193,"Dumitriu, T., Cimpanu, C., Ungureanu, F., & Manta, V.-I. (2018). Experimental analysis of emotion classification techniques. 63–70. Scopus. https://doi.org/10.1109/ICCP.2018.8516649",2018,dimensional,x,2,"LV, HV, neutral",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,,-,-,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,,-,-,x,-,-,-,-,-,-
34,194,"Dumitriu, T., Cimpanu, C., Ungureanu, F., & Manta, V.-I. (2018). Experimental analysis of emotion classification techniques. 63–70. Scopus. https://doi.org/10.1109/ICCP.2018.8516649",2018,dimensional,x,2,"LV, HV, neutral",-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,x,-,-,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
35,195,"Ferdinando, H., & Alasaarela, E. (2018). Emotion recognition using cvxEDA-based features. Journal of Telecommunication, Electronic and Computer Engineering, 10(2–3), 19–23. Scopus.",2018,dimensional,x,3,"calm, medium aroused, excited",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,-,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,x,"Compare to some references [1], [3], [4], the proposed features used in this study offered better results for the 3-class problem, see highlighted results in Table 1 and 2. These are the second major findings in this study and will serve as baselines for future studies using the MAHNOB-HCI, especially for EDA-based features only. However, recognizing medium valence looked challenging, while low valence showed the easiest ones.
This study was limited by the absence of nonlinear features as Yang and Liu found that relationship between EDA signal and emotion is nonlinear [8]. Deeper studies using nonlinear features, e.g. Lanata et al. [6] proposed recurrent plot, deterministic chaos, and detrended fluctuation analysis, were left for future works.",-,-
35,196,"Ferdinando, H., & Alasaarela, E. (2018). Emotion recognition using cvxEDA-based features. Journal of Telecommunication, Electronic and Computer Engineering, 10(2–3), 19–23. Scopus.",2018,dimensional,x,3,"LV, neutral valence, HV",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,-,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,-,x,-,x,"Compare to some references [1], [3], [4], the proposed features used in this study offered better results for the 3-class problem, see highlighted results in Table 1 and 2. These are the second major findings in this study and will serve as baselines for future studies using the MAHNOB-HCI, especially for EDA-based features only. However, recognizing medium valence looked challenging, while low valence showed the easiest ones.
This study was limited by the absence of nonlinear features as Yang and Liu found that relationship between EDA signal and emotion is nonlinear [8]. Deeper studies using nonlinear features, e.g. Lanata et al. [6] proposed recurrent plot, deterministic chaos, and detrended fluctuation analysis, were left for future works.",-,-
35,197,"Ferdinando, H., & Alasaarela, E. (2018). Emotion recognition using cvxEDA-based features. Journal of Telecommunication, Electronic and Computer Engineering, 10(2–3), 19–23. Scopus.",2018,dimensional,x,3,"LV, neutral valence, HV",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,-,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,x,"Compare to some references [1], [3], [4], the proposed features used in this study offered better results for the 3-class problem, see highlighted results in Table 1 and 2. These are the second major findings in this study and will serve as baselines for future studies using the MAHNOB-HCI, especially for EDA-based features only. However, recognizing medium valence looked challenging, while low valence showed the easiest ones.
This study was limited by the absence of nonlinear features as Yang and Liu found that relationship between EDA signal and emotion is nonlinear [8]. Deeper studies using nonlinear features, e.g. Lanata et al. [6] proposed recurrent plot, deterministic chaos, and detrended fluctuation analysis, were left for future works.",-,-
35,198,"Ferdinando, H., & Alasaarela, E. (2018). Emotion recognition using cvxEDA-based features. Journal of Telecommunication, Electronic and Computer Engineering, 10(2–3), 19–23. Scopus.",2018,dimensional,x,3,"calm, medium aroused, excited",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,-,,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,-,x,-,x,"Compare to some references [1], [3], [4], the proposed features used in this study offered better results for the 3-class problem, see highlighted results in Table 1 and 2. These are the second major findings in this study and will serve as baselines for future studies using the MAHNOB-HCI, especially for EDA-based features only. However, recognizing medium valence looked challenging, while low valence showed the easiest ones.
This study was limited by the absence of nonlinear features as Yang and Liu found that relationship between EDA signal and emotion is nonlinear [8]. Deeper studies using nonlinear features, e.g. Lanata et al. [6] proposed recurrent plot, deterministic chaos, and detrended fluctuation analysis, were left for future works.",-,-
36,199,"Zhang, S., Liu, G., & Lai, X. (2015). Classification of evoked emotions using an artificial neural network based on single, short-term physiological signals. Journal of Advanced Computational Intelligence and Intelligent Informatics, 19(1), 118-126.",2015,categorical,x,5,"anger, fear, grief, happiness, calmness",-,-,-,-,-,,-,,,,,,,,,,-,-,-,,-,-,-,-,-,x,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
37,200,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018,dimensional,x,2,"LA, HA",-,-,-,-,-,x,-,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,-,-,-,-,-,,,,,,,--,-,-,-,-,x,-,-,-,-,-,-
37,201,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018,dimensional,x,2,"LA, HA",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,-,-,-,-,-,,,,,,,--,-,-,-,-,x,-,-,-,-,-,-
37,202,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018,dimensional,x,2,"LA, HA",-,-,-,-,-,-,-,,,,,,,,,x,-,-,-,,-,-,-,-,-,-,,,,,,-,,-,-,-,-,-,,,,,,,--,-,-,-,-,x,-,-,-,-,-,-
37,203,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018,dimensional,x,2,"LA, HA",-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,x,-,-,-,,,,,,-,,-,-,-,-,-,,,,,,,--,-,-,-,-,x,-,-,-,-,-,-
37,204,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018,dimensional,x,2,"LA, HA",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,-,-,-,-,-,,,,,,,--,-,-,-,-,x,-,-,-,-,-,-
37,205,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018,dimensional,x,2,"LA, HA",-,-,-,-,-,-,x,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,-,-,-,-,-,,,,,,,--,-,-,-,-,x,-,-,-,-,-,-
37,206,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018,dimensional,x,2,"LA, HA",-,-,-,-,-,x,-,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,-,-,-,-,-,,,,,,,--,-,-,-,-,x,-,-,-,-,-,-
37,207,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018,dimensional,x,2,"LA, HA",-,-,-,-,-,x,-,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,-,-,-,-,-,,,,,,,--,-,-,-,-,x,-,-,-,-,-,-
37,208,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018,dimensional,x,2,"LA, HA",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,-,-,-,-,-,,,,,,,--,-,-,-,-,x,-,-,-,-,-,-
37,209,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018,dimensional,x,2,"LA, HA",-,-,-,-,-,-,-,,,,,,,,,x,-,-,-,,-,-,-,-,-,-,,,,,,-,,-,-,-,-,-,,,,,,,--,-,-,-,-,x,-,-,-,-,-,-
37,210,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018,dimensional,x,2,"LA, HA",-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,x,-,-,-,,,,,,-,,-,-,-,-,-,,,,,,,--,-,-,-,-,x,-,-,-,-,-,-
37,211,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018,dimensional,x,2,"LA, HA",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,-,-,-,-,-,,,,,,,--,-,-,-,-,x,-,-,-,-,-,-
37,212,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018,dimensional,x,2,"LA, HA",-,-,-,-,-,-,x,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,-,-,-,-,-,,,,,,,--,-,-,-,-,x,-,-,-,-,-,-
37,213,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018,dimensional,x,2,"LA, HA",-,-,-,-,-,x,-,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,-,-,-,-,-,,,,,,,--,-,-,-,-,x,-,-,-,-,-,-
37,214,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018,dimensional,x,2,"LA, HA",-,-,-,-,-,x,-,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,-,-,-,-,-,,,,,,,--,-,-,-,-,x,-,-,-,-,-,-
37,215,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018,dimensional,x,2,"LA, HA",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,-,-,-,-,-,,,,,,,--,-,-,-,-,x,-,-,-,-,-,-
37,216,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018,dimensional,x,2,"LA, HA",-,-,-,-,-,-,-,,,,,,,,,x,-,-,-,,-,-,-,-,-,-,,,,,,-,,-,-,-,-,-,,,,,,,--,-,-,-,-,x,-,-,-,-,-,-
37,217,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018,dimensional,x,2,"LA, HA",-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,x,-,-,-,,,,,,-,,-,-,-,-,-,,,,,,,--,-,-,-,-,x,-,-,-,-,-,-
37,218,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018,dimensional,x,2,"LA, HA",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,-,-,-,-,-,,,,,,,--,-,-,-,-,x,-,-,-,-,-,-
37,219,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018,dimensional,x,2,"LA, HA",-,-,-,-,-,-,x,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,-,-,-,-,-,,,,,,,--,-,-,-,-,x,-,-,-,-,-,-
37,220,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018,dimensional,x,2,"LA, HA",-,-,-,-,-,x,-,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,-,-,-,-,-,,,,,,,--,-,-,-,-,x,-,-,-,-,-,-
37,221,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018,dimensional,x,2,"LA, HA",-,-,-,-,-,x,-,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,-,-,-,-,-,,,,,,,--,-,-,-,-,x,-,-,-,-,-,-
37,222,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018,dimensional,x,2,"LA, HA",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,-,-,-,-,-,,,,,,,--,-,-,-,-,x,-,-,-,-,-,-
37,223,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018,dimensional,x,2,"LA, HA",-,-,-,-,-,-,-,,,,,,,,,x,-,-,-,,-,-,-,-,-,-,,,,,,-,,-,-,-,-,-,,,,,,,--,-,-,-,-,x,-,-,-,-,-,-
37,224,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018,dimensional,x,2,"LA, HA",-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,x,-,-,-,,,,,,-,,-,-,-,-,-,,,,,,,--,-,-,-,-,x,-,-,-,-,-,-
37,225,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018,dimensional,x,2,"LA, HA",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,-,-,-,-,-,,,,,,,--,-,-,-,-,x,-,-,-,-,-,-
37,226,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018,dimensional,x,2,"LA, HA",-,-,-,-,-,-,x,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,-,-,-,-,-,,,,,,,--,-,-,-,-,x,-,-,-,-,-,-
37,227,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018,dimensional,x,2,"LA, HA",-,-,-,-,-,x,-,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,-,-,-,-,-,,,,,,,--,-,-,-,-,x,-,-,-,-,-,-
37,228,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018,dimensional,x,2,"LA, HA",-,-,-,-,-,x,-,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,-,-,-,-,-,,,,,,,--,-,-,-,-,x,-,-,-,-,-,-
37,229,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018,dimensional,x,2,"LA, HA",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,-,-,-,-,-,,,,,,,--,-,-,-,-,x,-,-,-,-,-,-
37,230,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018,dimensional,x,2,"LA, HA",-,-,-,-,-,-,-,,,,,,,,,x,-,-,-,,-,-,-,-,-,-,,,,,,-,,-,-,-,-,-,,,,,,,--,-,-,-,-,x,-,-,-,-,-,-
37,231,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018,dimensional,x,2,"LA, HA",-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,x,-,-,-,,,,,,-,,-,-,-,-,-,,,,,,,--,-,-,-,-,x,-,-,-,-,-,-
37,232,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018,dimensional,x,2,"LA, HA",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,-,-,-,-,-,,,,,,,--,-,-,-,-,x,-,-,-,-,-,-
37,233,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018,dimensional,x,2,"LA, HA",-,-,-,-,-,-,x,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,-,-,-,-,-,,,,,,,--,-,-,-,-,x,-,-,-,-,-,-
37,234,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018,dimensional,x,2,"LA, HA",-,-,-,-,-,x,-,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,-,-,-,-,-,,,,,,,--,-,-,-,-,x,-,-,-,-,-,-
37,235,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018,dimensional,x,2,"LA, HA",-,-,-,-,-,x,-,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,-,-,-,-,-,,,,,,,--,-,-,-,-,x,-,-,-,-,-,-
37,236,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018,dimensional,x,2,"LA, HA",-,x,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,-,-,-,-,-,,,,,,,--,-,-,-,-,x,-,-,-,-,-,-
37,237,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018,dimensional,x,2,"LA, HA",-,-,-,-,-,-,-,,,,,,,,,x,-,-,-,,-,-,-,-,-,-,,,,,,-,,-,-,-,-,-,,,,,,,--,-,-,-,-,x,-,-,-,-,-,-
37,238,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018,dimensional,x,2,"LA, HA",-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,-,x,-,-,-,,,,,,-,,-,-,-,-,-,,,,,,,--,-,-,-,-,x,-,-,-,-,-,-
37,239,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018,dimensional,x,2,"LA, HA",-,-,x,-,-,-,-,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,-,-,-,-,-,,,,,,,--,-,-,-,-,x,-,-,-,-,-,-
37,240,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018,dimensional,x,2,"LA, HA",-,-,-,-,-,-,x,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,-,-,-,-,-,,,,,,,--,-,-,-,-,x,-,-,-,-,-,-
37,241,"Gjoreski, M., Luštrek, M., Gams, M., & Mitrevski, B. (2018). An inter-domain study for arousal recognition from physiological signals. Informatica (Slovenia), 42(1), 61–68. Scopus.",2018,dimensional,x,2,"LA, HA",-,-,-,-,-,x,-,,,,,,,,,,-,-,-,,-,-,-,-,-,-,,,,,,-,,-,-,-,-,-,,,,,,,--,-,-,-,-,x,-,-,-,-,-,-
38,242,"Ayata, D., Yaslan, Y., & Kamasak, M. (2017). Emotion recognition via galvanic skin response: Comparison of machine learning algorithms and feature extraction methods. Istanbul University - Journal of Electrical and Electronics Engineering, 17, 3129–3136. Scopus.",2017,dimensional,x,2,"LA, HA",-,-,x,-,-,-,-,,,,,,,,,-,-,-,-,,-,-,-,-,-,-,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
38,243,"Ayata, D., Yaslan, Y., & Kamasak, M. (2017). Emotion recognition via galvanic skin response: Comparison of machine learning algorithms and feature extraction methods. Istanbul University - Journal of Electrical and Electronics Engineering, 17, 3129–3136. Scopus.",2017,dimensional,x,2,"LA, HA",-,-,-,-,-,x,-,,,,,,,,,-,-,-,-,,-,-,-,-,-,-,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
38,244,"Ayata, D., Yaslan, Y., & Kamasak, M. (2017). Emotion recognition via galvanic skin response: Comparison of machine learning algorithms and feature extraction methods. Istanbul University - Journal of Electrical and Electronics Engineering, 17, 3129–3136. Scopus.",2017,dimensional,x,2,"LA, HA",-,-,-,-,-,x,-,,,,,,,,,-,-,-,-,,-,-,-,-,-,-,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
38,245,"Ayata, D., Yaslan, Y., & Kamasak, M. (2017). Emotion recognition via galvanic skin response: Comparison of machine learning algorithms and feature extraction methods. Istanbul University - Journal of Electrical and Electronics Engineering, 17, 3129–3136. Scopus.",2017,dimensional,x,2,"LA, HA",-,x,-,-,-,-,-,,,,,,,,,-,-,-,-,,-,-,-,-,-,-,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
38,246,"Ayata, D., Yaslan, Y., & Kamasak, M. (2017). Emotion recognition via galvanic skin response: Comparison of machine learning algorithms and feature extraction methods. Istanbul University - Journal of Electrical and Electronics Engineering, 17, 3129–3136. Scopus.",2017,dimensional,x,2,"LV, HV",-,-,x,-,-,-,-,,,,,,,,,-,-,-,-,,-,-,-,-,-,-,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
38,247,"Ayata, D., Yaslan, Y., & Kamasak, M. (2017). Emotion recognition via galvanic skin response: Comparison of machine learning algorithms and feature extraction methods. Istanbul University - Journal of Electrical and Electronics Engineering, 17, 3129–3136. Scopus.",2017,dimensional,x,2,"LV, HV",-,-,-,-,-,x,-,,,,,,,,,-,-,-,-,,-,-,-,-,-,-,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
38,248,"Ayata, D., Yaslan, Y., & Kamasak, M. (2017). Emotion recognition via galvanic skin response: Comparison of machine learning algorithms and feature extraction methods. Istanbul University - Journal of Electrical and Electronics Engineering, 17, 3129–3136. Scopus.",2017,dimensional,x,2,"LV, HV",-,-,-,-,-,x,-,,,,,,,,,-,-,-,-,,-,-,-,-,-,-,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
38,249,"Ayata, D., Yaslan, Y., & Kamasak, M. (2017). Emotion recognition via galvanic skin response: Comparison of machine learning algorithms and feature extraction methods. Istanbul University - Journal of Electrical and Electronics Engineering, 17, 3129–3136. Scopus.",2017,dimensional,x,2,"LV, HV",-,x,-,-,-,-,-,,,,,,,,,-,-,-,-,,-,-,-,-,-,-,,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,x,-,-,-,-,-,-
39,250,"Martínez-Rodrigo, A., Zangróniz, R., Pastor, J. M., & Sokolova, M. V. (2017). Arousal level classification of the aging adult from electro-dermal activity: From hardware development to software architecture. Pervasive and Mobile Computing, 34, 46–59. Scopus. https://doi.org/10.1016/j.pmcj.2016.04.006",2017,dimensional,x,2,"sleepiness, stressed",x,-,-,-,-,-,-,,,,,,,,,-,-,-,-,,-,-,-,-,-,-,-,,,,,-,,-,-,-,-,-,,,,,,,-,-,-,-,-,,,,-,-,-,-
40,251,"Milchevski, A., Rozza, A., & Taskovski, D. (2015). Multimodal affective analysis combining regularized linear regression and boosted regression trees. 33–39. Scopus. https://doi.org/10.1145/2808196.2811636",2015,dimensional,,-,-,-,-,-,-,-,-,-,,,,,,,,,-,-,-,-,,-,-,-,-,-,-,-,,,,,-,x,1,arousal,x,-,-,,,,,,-,,-,-,-,-,-,-,-,-,-,-,-
40,252,"Milchevski, A., Rozza, A., & Taskovski, D. (2015). Multimodal affective analysis combining regularized linear regression and boosted regression trees. 33–39. Scopus. https://doi.org/10.1145/2808196.2811636",2015,dimensional,,-,-,-,-,-,-,-,-,-,,,,,,,,,-,-,-,-,,-,-,-,-,-,-,-,,,,,-,x,1,arousal,-,-,-,,,,,,x,,-,-,-,-,-,-,-,-,-,-,-
40,253,"Milchevski, A., Rozza, A., & Taskovski, D. (2015). Multimodal affective analysis combining regularized linear regression and boosted regression trees. 33–39. Scopus. https://doi.org/10.1145/2808196.2811636",2015,dimensional,,-,-,-,-,-,-,-,-,-,,,,,,,,,-,-,-,-,,-,-,-,-,-,-,-,,,,,-,x,1,valence,x,-,-,,,,,,-,,-,-,-,-,-,-,-,-,-,-,-
40,254,"Milchevski, A., Rozza, A., & Taskovski, D. (2015). Multimodal affective analysis combining regularized linear regression and boosted regression trees. 33–39. Scopus. https://doi.org/10.1145/2808196.2811636",2015,dimensional,,-,-,-,-,-,-,-,-,-,,,,,,,,,-,-,-,-,,-,-,-,-,-,-,-,,,,,-,x,1,valence,-,-,-,,,,,,x,,-,-,-,-,-,-,-,-,-,-,-
41,255,"Ringeval, F., Eyben, F., Kroupi, E., Yuce, A., Thiran, J.-P., Ebrahimi, T., Lalanne, D., & Schuller, B. (2015). Prediction of asynchronous dimensional emotion ratings from audiovisual and physiological data. Pattern Recognition Letters, 66, 22–30. Scopus. https://doi.org/10.1016/j.patrec.2014.11.007",2015,dimensional,,-,-,-,-,-,-,-,-,-,,,,,,,,,-,-,-,-,,-,-,-,-,-,-,-,,,,,-,x,1,arousal,-,-,-,,,,,,-,-,-,-,-,-,?,?,-,-,-,-,-
41,256,"Ringeval, F., Eyben, F., Kroupi, E., Yuce, A., Thiran, J.-P., Ebrahimi, T., Lalanne, D., & Schuller, B. (2015). Prediction of asynchronous dimensional emotion ratings from audiovisual and physiological data. Pattern Recognition Letters, 66, 22–30. Scopus. https://doi.org/10.1016/j.patrec.2014.11.007",2015,dimensional,,-,-,-,-,-,-,-,-,-,,,,,,,,,-,-,-,-,,-,-,-,-,-,-,-,,,,,-,x,1,valence,-,-,-,,,,,,-,-,-,-,-,-,?,?,-,-,-,-,-
41,257,"Ringeval, F., Eyben, F., Kroupi, E., Yuce, A., Thiran, J.-P., Ebrahimi, T., Lalanne, D., & Schuller, B. (2015). Prediction of asynchronous dimensional emotion ratings from audiovisual and physiological data. Pattern Recognition Letters, 66, 22–30. Scopus. https://doi.org/10.1016/j.patrec.2014.11.007",2015,dimensional,,-,-,-,-,-,-,-,-,-,,,,,,,,,-,-,-,-,,-,-,-,-,-,-,-,,,,,-,x,2,"arousal, valence",-,-,-,,,,,,-,-,-,-,-,-,?,?,-,-,-,-,-
41,258,"Ringeval, F., Eyben, F., Kroupi, E., Yuce, A., Thiran, J.-P., Ebrahimi, T., Lalanne, D., & Schuller, B. (2015). Prediction of asynchronous dimensional emotion ratings from audiovisual and physiological data. Pattern Recognition Letters, 66, 22–30. Scopus. https://doi.org/10.1016/j.patrec.2014.11.007",2015,dimensional,,-,-,-,-,-,-,-,-,-,,,,,,,,,-,-,-,-,,-,-,-,-,-,-,-,,,,,-,x,2,"arousal, valence",-,-,-,,,,,,-,-,-,-,-,-,?,?,-,-,-,-,-
42,259,"Kostoulas, T., Chanel, G., Muszynski, M., Lombardo, P., & Pun, T. (2017). Films, affective computing and aesthetic experience: Identifying emotional and aesthetic highlights from multimodal signals in a social setting. Frontiers in ICT, 4(JUN). Scopus. https://doi.org/10.3389/fict.2017.00011",2017,dimensional,x,2,"LV,HV",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,,
42,260,"Kostoulas, T., Chanel, G., Muszynski, M., Lombardo, P., & Pun, T. (2017). Films, affective computing and aesthetic experience: Identifying emotional and aesthetic highlights from multimodal signals in a social setting. Frontiers in ICT, 4(JUN). Scopus. https://doi.org/10.3389/fict.2017.00011",2017,categorical,x,2,"LA, HA",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,,
43,261,"Barral, O., Kosunen, I., & Jacucci, G. (2017). No need to laugh out loud: Predicting humor appraisal of comic strips based on physiological signals in a realistic environment. ACM Transactions on Computer-Human Interaction, 24(6). Scopus. https://doi.org/10.1145/3157730",2017,categorical,x,2,"funny, not funny",-,-,-,-,-,x,-,,,,,,,,,-,-,-,-,,-,-,-,-,-,-,-,,,,,-,,-,-,-,-,-,,,,,,-,-,-,-,-,-,,,,x," Electrodermal Activity. Interestingly, EDA seems to be the most generalizable signal as
it performed the best in the across prediction setup compared to the other physiological sources,
and also performed better than EDA in the within prediction setup. It is also interesting that the
low classification performances of some participants in the within setup (e.g., “P10,” “P17,” “P22”)
were largely improved in the across setup. One possible explanation is that EDA features are quite
generalizable across participants; for some participants, the effect might be small, and therefore the model’s performance improves when the amount of training data increases, even when the
data belongs to other participants.

Figure 5 shows the grand average across participants and trials of the EDA for the time-locked,
fixed-time windows (initial, end, and special windows). EDA is known to present a relatively high
latency as compared to other physiological signals. As a matter of fact, capturing the EDA responses to the humor appraisal was one of the main motivations to define the special window that
continues for 5 seconds after the end of a trial. The grand average of the EDA signal shows a very
large difference in the signal from 2 to 4 seconds after the end of a trial. More specifically, “Funny”
trials elicited higher EDA than “Not funny” trials. This is captured in the most relevant features
for the trained models (see Table 4), as the top EDA features are the ones capturing the amount of
activity (i.e., wS.sum.Eda) and amount of change (i.e., wS.diff.Eda, wS.diffsq.Eda) within the special
window


EDA
showed increased values for humorous content, as expected because of increased activity of the
sympathetic nervous system due to the feeling of amusement (Foster et al. 1998; Martin 2010)
(Figure 5). In addition, the results indicate that the most discriminative differences in the physiological signals related to humor appraisal occur in the later stages of the information consumption
process, as shown in the most highly weighted features of the predictive models (see Table 4). This
finding is compatible with the incongruity model of humor, which posits that humor results from
solving ambiguities and conceptual incongruities using alternative formulations to the discrepancy. To put it in colloquial terms, the punchline comes at the end (Polimeni and Reiss 2006).
As a matter of fact, the discriminative physiological differences were mostly found in the special
window, which continued for several seconds after the trial ended, overlapping with the next
stimulus. Initially, we expected this to be the case only for the EDA signal, which is known to have
a temporal delay; but the same post-decision changes were apparent in EEG and ECG features as
well. This holds important implications for the design of affective systems for humor appraisal, as
it proves the delayed nature of physiological responses related to humor appraisal, as well as their
capability to capture it, despite overlapping with the next stimulus",-,-
44,262,"Lanatà, A., Valenza, G., & Scilingo, E. P. (2012). A novel EDA glove based on textile-integrated electrodes for affective computing. Medical & Biological Engineering & Computing, 50(11), 1163–1172. doi:10.1007/s11517-012-0921-9",2012,dimensional,x,5,"neutral, arousal1, arousal2, arousal3, arousal4",-,-,-,X,-,,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,,,,-,,-,-,-
45,263,"Ren, P., Barreto, A., Huang, J., Gao, Y., Ortega, F. R., & Adjouadi, M. (2013). Off-line and On-line Stress Detection Through Processing of the Pupil Diameter Signal. Annals of Biomedical Engineering, 42(1), 162–176. doi:10.1007/s10439-013-0880-9 ",2013,dimensional,x,2,"relaxed, stress",-,-,X,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,,-,-,43,,-,-,-
45,264,"Ren, P., Barreto, A., Huang, J., Gao, Y., Ortega, F. R., & Adjouadi, M. (2013). Off-line and On-line Stress Detection Through Processing of the Pupil Diameter Signal. Annals of Biomedical Engineering, 42(1), 162–176. doi:10.1007/s10439-013-0880-9 ",2013,dimensional,x,2,"relaxed, stress",-,-,-,-,-,X,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,,-,-,43,,-,-,-
45,265,"Ren, P., Barreto, A., Huang, J., Gao, Y., Ortega, F. R., & Adjouadi, M. (2013). Off-line and On-line Stress Detection Through Processing of the Pupil Diameter Signal. Annals of Biomedical Engineering, 42(1), 162–176. doi:10.1007/s10439-013-0880-9 ",2013,dimensional,x,2,"relaxed, stress",-,-,-,-,-,,X,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,,-,-,43,,-,-,-
45,266,"Ren, P., Barreto, A., Huang, J., Gao, Y., Ortega, F. R., & Adjouadi, M. (2013). Off-line and On-line Stress Detection Through Processing of the Pupil Diameter Signal. Annals of Biomedical Engineering, 42(1), 162–176. doi:10.1007/s10439-013-0880-9 ",2013,dimensional,x,2,"relaxed, stress",-,-,-,-,-,,-,,,,,,,,,,X,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,,-,-,43,,-,-,-
45,267,"Ren, P., Barreto, A., Huang, J., Gao, Y., Ortega, F. R., & Adjouadi, M. (2013). Off-line and On-line Stress Detection Through Processing of the Pupil Diameter Signal. Annals of Biomedical Engineering, 42(1), 162–176. doi:10.1007/s10439-013-0880-9 ",2013,dimensional,x,2,"relaxed, stress",-,-,-,-,-,,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,X,,-,-,-,-,,,,,,,,-,-,-,-,,-,-,43,,-,-,-
46,268,"GOUIZI, K., BEREKSI REGUIG, F., & MAAOUI, C. (2011). Emotion recognition from physiological signals. Journal of Medical Engineering & Technology, 35(6-7), 300–307. doi:10.3109/03091902.2011.601784",2011,categorical,x,6,"joy, sadness, fear, disgust, neutrality,  amusement",-,X,-,-,-,,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,-,-,,-,,,,,,,,-,-,-,-,,-,-,-,-,-,-,-
47,269,"Bornoiu, I.-V., Strungaru, R., & Grigore, O. (2015). Intelligent System for Emotion Recognition Based on Electrodermal Activity Processing. 6th European Conference of the International Federation for Medical and Biological Engineering, 70–73. doi:10.1007/978-3-319-11128-5_18 ",2015,dimensional,x,2,"relaxed, stress",-,-,X,-,-,,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,-,-,-,?,,-,-,-
48,270,"Liapis, A., Katsanos, C., Sotiropoulos, D., Xenos, M., & Karousos, N. (2015). Subjective Assessment of Stress in HCI. Proceedings of the 11th Biannual Conference on Italian SIGCHI Chapter - CHItaly 2015. doi:10.1145/2808435.2808450",2015,categorical,x,2,"stress, not stress",,X,-,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,-,-,-,140,-,-,-,-
48,271,"Liapis, A., Katsanos, C., Sotiropoulos, D., Xenos, M., & Karousos, N. (2015). Subjective Assessment of Stress in HCI. Proceedings of the 11th Biannual Conference on Italian SIGCHI Chapter - CHItaly 2015. doi:10.1145/2808435.2808450",2015,dimensional,x,2,"stress, not stress",,-,X,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,-,-,-,140,-,-,-,-
48,272,"Liapis, A., Katsanos, C., Sotiropoulos, D., Xenos, M., & Karousos, N. (2015). Subjective Assessment of Stress in HCI. Proceedings of the 11th Biannual Conference on Italian SIGCHI Chapter - CHItaly 2015. doi:10.1145/2808435.2808450",2015,dimensional,x,2,"stress, not stress",,-,-,X,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,-,-,-,140,-,-,-,-
48,273,"Liapis, A., Katsanos, C., Sotiropoulos, D., Xenos, M., & Karousos, N. (2015). Subjective Assessment of Stress in HCI. Proceedings of the 11th Biannual Conference on Italian SIGCHI Chapter - CHItaly 2015. doi:10.1145/2808435.2808450",2015,dimensional,x,2,"stress, not stress",,-,-,-,X,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,-,-,-,140,-,-,-,-
48,274,"Liapis, A., Katsanos, C., Sotiropoulos, D., Xenos, M., & Karousos, N. (2015). Subjective Assessment of Stress in HCI. Proceedings of the 11th Biannual Conference on Italian SIGCHI Chapter - CHItaly 2015. doi:10.1145/2808435.2808450",2015,dimensional,x,2,"stress, not stress",,-,-,-,-,X,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,-,-,-,140,-,-,-,-
49,275,"Drungilas, D., Bielskis, A. A., & Denisov, V. (2010). An intelligent control system based on non-invasive man machine interaction. In Innovations in Computing Sciences and Software Engineering (pp. 63-68). Springer, Dordrecht.",2010,categorical,x,8,"Fear, Surprise, Happy, Calmness, Sleepiness, Sad, Disgust, Anger",-,-,-,-,-,-,-,,,,,,,,,,X,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,-,-,-,-,-,-,-,-
50,276,"Wu, G., Liu, G., & Hao, M. (2010). The Analysis of Emotion Recognition from GSR Based on PSO. 2010 International Symposium on Intelligence Information Processing and Trusted Computing. doi:10.1109/iptc.2010.60",2010,categorical,x,6,"happy, Suprise, Disgust, Grief, Angry, Fear",-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,-,-,-,-,-,-,-,-
51,277,"Giakoumis, D., Tzovaras, D., Moustakas, K., & Hassapis, G. (2011). Automatic Recognition of Boredom in Video Games Using Novel Biosignal Moment-Based Features. IEEE Transactions on Affective Computing, 2(3), 119–133. doi:10.1109/t-affc.2011.4 ",2011,categorical,x,2,"bored, not bored",-,-,-,-,X,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,-,X,-,-,-,-,-,-
52,278,"Safta, I., Grigore, O., & Căruntu, C.(2011). Emotion Detection Using Psycho-Physiological Signal Processing. Computer, 3, 4.",2011,dimensional,x,2,"pleaseant, unpleaseant ",-,-,X,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,,-,-,X,-,-,-,-,-,-
53,279,"Ren, P., Barreto, A., Gao, Y., & Adjouadi, M. (2012). Comparison of the use of pupil diameter and galvanic skin response signals for affective assessment of computer users. Biomedical sciences instrumentation, 48, 345-350.",2012,dimensional,x,2,"relaxed, stress",-,-,X,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,-,-,-,-,-,-,-,-
53,280,"Ren, P., Barreto, A., Gao, Y., & Adjouadi, M. (2012). Comparison of the use of pupil diameter and galvanic skin response signals for affective assessment of computer users. Biomedical sciences instrumentation, 48, 345-350.",2012,dimensional,x,2,"relaxed, stress",-,-,-,-,-,-,-,,,,,,,,,,X,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,-,-,-,-,-,-,-,-
53,281,"Ren, P., Barreto, A., Gao, Y., & Adjouadi, M. (2012). Comparison of the use of pupil diameter and galvanic skin response signals for affective assessment of computer users. Biomedical sciences instrumentation, 48, 345-350.",2012,dimensional,x,2,"relaxed, stress",-,-,-,-,-,-,X,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,-,-,-,-,-,-,-,-
53,282,"Ren, P., Barreto, A., Gao, Y., & Adjouadi, M. (2012). Comparison of the use of pupil diameter and galvanic skin response signals for affective assessment of computer users. Biomedical sciences instrumentation, 48, 345-350.",2012,dimensional,x,2,"relaxed, stress",-,-,-,-,-,X,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,-,-,-,-,-,-,-,-
53,283,"Ren, P., Barreto, A., Gao, Y., & Adjouadi, M. (2012). Comparison of the use of pupil diameter and galvanic skin response signals for affective assessment of computer users. Biomedical sciences instrumentation, 48, 345-350.",2012,dimensional,x,2,"relaxed, stress",-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,X,,-,-,-,-,,,,,,,,-,-,-,-,-,-,-,-,-,-,-,-
54,284,"Cheng, J., & Liu, G. (2013). Computing nonlinear features of skin conductance to build the affective detection model. 2013 International Conference on Communications, Circuits and Systems (ICCCAS). doi:10.1109/icccas.2013.6765349 ",2013,categorical,x,2,"hapinees, sadness and fear",-,X,-,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,-,X,-,-,-,-,-,-
54,285,"Cheng, J., & Liu, G. (2013). Computing nonlinear features of skin conductance to build the affective detection model. 2013 International Conference on Communications, Circuits and Systems (ICCCAS). doi:10.1109/icccas.2013.6765349 ",2013,categorical,x,2," sadness and fears , hapiness",-,X,-,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,-,X,-,-,-,-,-,-
54,286,"Cheng, J., & Liu, G. (2013). Computing nonlinear features of skin conductance to build the affective detection model. 2013 International Conference on Communications, Circuits and Systems (ICCCAS). doi:10.1109/icccas.2013.6765349 ",2013,categorical,x,2,"fear and hapiness, sadness",-,X,-,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,-,X,-,-,-,-,-,-
55,287,"Ren, P., Barreto, A., Gao, Y., & Adjouadi, M. (2013). Affective Assessment by Digital Processing of the Pupil Diameter. IEEE Transactions on Affective Computing, 4(1), 2–14. doi:10.1109/t-affc.2012.25",2013,dimensional,x,2,"relaxed, stress",-,-,X,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,,,,,,,,-,-,-,-,-
55,288,"Ren, P., Barreto, A., Gao, Y., & Adjouadi, M. (2013). Affective Assessment by Digital Processing of the Pupil Diameter. IEEE Transactions on Affective Computing, 4(1), 2–14. doi:10.1109/t-affc.2012.25",2013,dimensional,x,2,"relaxed, stress",-,-,-,-,-,-,-,,,,,,,,,,X,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,-,-,-,-,-,-,-,-
55,289,"Ren, P., Barreto, A., Gao, Y., & Adjouadi, M. (2013). Affective Assessment by Digital Processing of the Pupil Diameter. IEEE Transactions on Affective Computing, 4(1), 2–14. doi:10.1109/t-affc.2012.25",2013,dimensional,x,2,"relaxed, stress",-,-,-,-,-,-,X,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-
55,290,"Ren, P., Barreto, A., Gao, Y., & Adjouadi, M. (2013). Affective Assessment by Digital Processing of the Pupil Diameter. IEEE Transactions on Affective Computing, 4(1), 2–14. doi:10.1109/t-affc.2012.25",2013,dimensional,x,2,"relaxed, stress",-,-,-,-,-,X,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,-,-,-,-,,-,-,-
55,291,"Ren, P., Barreto, A., Gao, Y., & Adjouadi, M. (2013). Affective Assessment by Digital Processing of the Pupil Diameter. IEEE Transactions on Affective Computing, 4(1), 2–14. doi:10.1109/t-affc.2012.25",2013,dimensional,x,2,"relaxed, stress",-,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,X,,-,-,-,-,,,,,,,,-,-,-,-,-,-,-,-,-,-,-,-
56,292,"Guo, R., Li, S., He, L., Gao, W., Qi, H., & Owens, G. (2013, May). Pervasive and unobtrusive emotion sensing for human mental health. In 2013 7th International Conference on Pervasive Computing Technologies for Healthcare and Workshops (pp. 436-439). IEEE.",2013,categorical,x,4,"Amusement, fear, relax, sadness",-,-,X,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,-,-,-,-,-,-,-,-
56,293,"Guo, R., Li, S., He, L., Gao, W., Qi, H., & Owens, G. (2013, May). Pervasive and unobtrusive emotion sensing for human mental health. In 2013 7th International Conference on Pervasive Computing Technologies for Healthcare and Workshops (pp. 436-439). IEEE.",2013,categorical,x,4,"Amusement, fear, relax, sadness",-,-,X,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,-,-,-,-,-,-,-,-
57,294,"Henriques, R., Paiva, A., & Antunes, C. (2013). Accessing Emotion Patterns from Affective Interactions Using Electrodermal Activity. 2013 Humaine Association Conference on Affective Computing and Intelligent Interaction. doi:10.1109/acii.2013.14 ",2013,categorical,x,5,"empathy, expectation, positive-surprise, stress, frustration",-,-,X,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,-,-,-,-,-,-,-,-
57,295,"Henriques, R., Paiva, A., & Antunes, C. (2013). Accessing Emotion Patterns from Affective Interactions Using Electrodermal Activity. 2013 Humaine Association Conference on Affective Computing and Intelligent Interaction. doi:10.1109/acii.2013.14 ",2013,categorical,x,5,"empathy, expectation, positive-surprise, stress, frustration",-,-,,-,-,X,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,,,,,,-,-,-,x,"Additionally, we showed that psychological traits can guide this task by correcting profile-driven differences, opening a new direction on how to measure affective interactions. The quantitative assessment shows that emotion recognition significantly improves when adopting more flexible methods to mine the electrodermal signal. Additionally, feature correlation
analysis and discriminative mining of generative models show meaningful differences among emotional stimuli and experimental settings. These answers to the target research questions trigger new implications not only for psychophysiology and neuroscience, but especially to human-robot and social interaction research.",-,-
57,296,"Henriques, R., Paiva, A., & Antunes, C. (2013). Accessing Emotion Patterns from Affective Interactions Using Electrodermal Activity. 2013 Humaine Association Conference on Affective Computing and Intelligent Interaction. doi:10.1109/acii.2013.14 ",2013,categorical,x,5,"empathy, expectation, positive-surprise, stress, frustration",-,-,-,-,-,-,X,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,-,,-,-,-,-,-,-,x,"Additionally, we showed that psychological traits can guide this task by correcting profile-driven differences, opening a new direction on how to measure affective interactions. The quantitative assessment shows that emotion recognition significantly improves when adopting more flexible methods to mine the electrodermal signal. Additionally, feature correlation
analysis and discriminative mining of generative models show meaningful differences among emotional stimuli and experimental settings. These answers to the target research questions trigger new implications not only for psychophysiology and neuroscience, but especially to human-robot and social interaction research.",-,
57,297,"Henriques, R., Paiva, A., & Antunes, C. (2013). Accessing Emotion Patterns from Affective Interactions Using Electrodermal Activity. 2013 Humaine Association Conference on Affective Computing and Intelligent Interaction. doi:10.1109/acii.2013.14 ",2013,categorical,x,5,"empathy, expectation, positive-surprise, stress, frustration",-,X,-,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,-,-,-,-,x,"Additionally, we showed that psychological traits can guide this task by correcting profile-driven differences, opening a new direction on how to measure affective interactions. The quantitative assessment shows that emotion recognition significantly improves when adopting more flexible methods to mine the electrodermal signal. Additionally, feature correlation
analysis and discriminative mining of generative models show meaningful differences among emotional stimuli and experimental settings. These answers to the target research questions trigger new implications not only for psychophysiology and neuroscience, but especially to human-robot and social interaction research.",-,-
57,298,"Henriques, R., Paiva, A., & Antunes, C. (2013). Accessing Emotion Patterns from Affective Interactions Using Electrodermal Activity. 2013 Humaine Association Conference on Affective Computing and Intelligent Interaction. doi:10.1109/acii.2013.14 ",2013,categorical,x,5,"empathy, expectation, positive-surprise, stress, frustration",X,-,-,-,-,-,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,-,-,-,-,x,"Additionally, we showed that psychological traits can guide this task by correcting profile-driven differences, opening a new direction on how to measure affective interactions. The quantitative assessment shows that emotion recognition significantly improves when adopting more flexible methods to mine the electrodermal signal. Additionally, feature correlation
analysis and discriminative mining of generative models show meaningful differences among emotional stimuli and experimental settings. These answers to the target research questions trigger new implications not only for psychophysiology and neuroscience, but especially to human-robot and social interaction research.",-,-
57,299,"Henriques, R., Paiva, A., & Antunes, C. (2013). Accessing Emotion Patterns from Affective Interactions Using Electrodermal Activity. 2013 Humaine Association Conference on Affective Computing and Intelligent Interaction. doi:10.1109/acii.2013.14 ",2013,categorical,x,5,"empathy, expectation, positive-surprise, stress, frustration",X,-,-,-,-,-,-,,,,,,,,x,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,-,-,-,-,x,"Additionally, we showed that psychological traits can guide this task by correcting profile-driven differences, opening a new direction on how to measure affective interactions. The quantitative assessment shows that emotion recognition significantly improves when adopting more flexible methods to mine the electrodermal signal. Additionally, feature correlation
analysis and discriminative mining of generative models show meaningful differences among emotional stimuli and experimental settings. These answers to the target research questions trigger new implications not only for psychophysiology and neuroscience, but especially to human-robot and social interaction research.",-,-
57,300,"Henriques, R., Paiva, A., & Antunes, C. (2013). Accessing Emotion Patterns from Affective Interactions Using Electrodermal Activity. 2013 Humaine Association Conference on Affective Computing and Intelligent Interaction. doi:10.1109/acii.2013.14 ",2013,categorical,x,5,"empathy, expectation, positive-surprise, stress, frustration",X,-,-,-,-,-,-,,,,,,,,x,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,-,-,-,-,x,"Additionally, we showed that psychological traits can guide this task by correcting profile-driven differences, opening a new direction on how to measure affective interactions. The quantitative assessment shows that emotion recognition significantly improves when adopting more flexible methods to mine the electrodermal signal. Additionally, feature correlation
analysis and discriminative mining of generative models show meaningful differences among emotional stimuli and experimental settings. These answers to the target research questions trigger new implications not only for psychophysiology and neuroscience, but especially to human-robot and social interaction research.",-,-
57,301,"Henriques, R., Paiva, A., & Antunes, C. (2013). Accessing Emotion Patterns from Affective Interactions Using Electrodermal Activity. 2013 Humaine Association Conference on Affective Computing and Intelligent Interaction. doi:10.1109/acii.2013.14 ",2013,categorical,x,5,"empathy, expectation, positive-surprise, stress, frustration",X,-,-,-,-,-,-,,,,,,,,x,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,-,-,-,-,x,"Additionally, we showed that psychological traits can guide this task by correcting profile-driven differences, opening a new direction on how to measure affective interactions. The quantitative assessment shows that emotion recognition significantly improves when adopting more flexible methods to mine the electrodermal signal. Additionally, feature correlation
analysis and discriminative mining of generative models show meaningful differences among emotional stimuli and experimental settings. These answers to the target research questions trigger new implications not only for psychophysiology and neuroscience, but especially to human-robot and social interaction research.",-,-
58,302,"Li, S., Guo, R., He, L., Gao, W., Qi, H., & Owens, G. (2014). MoodMagician. Proceedings of the 12th ACM Conference on Embedded Network Sensor Systems - SenSys ’14. doi:10.1145/2668332.2668371",2014,categorical,x,4,"amusement,fear, relax, sadness",-,-,-,-,-,X,-,,,,,,,,,,-,-,-,,-,,,,,,,,,,,-,,-,-,-,-,,,,,,,,-,-,-,-,-,-,-,-,-,-,-,-
59,303,"Yu, D., & Sun, S. (2020). A systematic exploration of deep neural networks for EDA-based emotion recognition. Information, 11(4), 212.",2020,dimensional,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,1,arousal,,,,,,,,,,,x,,,,-,-,-,-,-,,
59,304,"Yu, D., & Sun, S. (2020). A systematic exploration of deep neural networks for EDA-based emotion recognition. Information, 11(4), 212.",2020,dimensional,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,1,arousal,,,,,,,,,,,,x,,,-,-,-,-,-,,
59,305,"Yu, D., & Sun, S. (2020). A systematic exploration of deep neural networks for EDA-based emotion recognition. Information, 11(4), 212.",2020,dimensional,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,1,arousal,,,,,,,,,,,x,x,,,-,-,-,-,-,,
59,306,"Yu, D., & Sun, S. (2020). A systematic exploration of deep neural networks for EDA-based emotion recognition. Information, 11(4), 212.",2020,dimensional,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,1,valence,,,,,,,,,,,x,,,,-,-,-,-,-,,
59,307,"Yu, D., & Sun, S. (2020). A systematic exploration of deep neural networks for EDA-based emotion recognition. Information, 11(4), 212.",2020,dimensional,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,1,valence,,,,,,,,,,,,x,,,-,-,-,-,-,,
59,308,"Yu, D., & Sun, S. (2020). A systematic exploration of deep neural networks for EDA-based emotion recognition. Information, 11(4), 212.",2020,dimensional,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,1,valence,,,,,,,,,,,x,x,,,-,-,-,-,-,,
60,309,"Al Machot, F., Elmachot, A., Ali, M., Al Machot, E., & Kyamakya, K. (2019). A deep-learning model for subject-independent human emotion recognition using electrodermal activity sensors. Sensors, 19(7), 1659.",2019,dimensional,x,4,"HAHV, HALV, LAHV, LALV",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Additionally, analyzing the results of the state-of-art, clearly, feature engineering for
subject-independent and subject-dependent human emotion detection based on EDA does not lead
to high performance. In particular, when the number of classes is higher than two. This is because
extracting the sympathetic response patterns which are part of each emotion is difficult. Furthermore,
when trying to overcome this fact by analyzing more basic features such as level, response amplitude,
rate, rise time, and recovery time, they discard flexible elicited behavior which might improve emotion
recognition. Therefore, it has been proven in this work that DL can overcome this drawback quite well.
Regarding the point of testing the proposed model using different datasets from different labs,
it is because human emotions do not form similar patterns. Consequently, the research community
should develop generalized models to recognize human emotions, where subjects, elicitation materials,
and physiological sensors brands are different from the ones involved in the initial training.",,
60,310,"Al Machot, F., Elmachot, A., Ali, M., Al Machot, E., & Kyamakya, K. (2019). A deep-learning model for subject-independent human emotion recognition using electrodermal activity sensors. Sensors, 19(7), 1659.",2019,dimensional,x,4,"HAHV, HALV, LAHV, LALV",,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Additionally, analyzing the results of the state-of-art, clearly, feature engineering for
subject-independent and subject-dependent human emotion detection based on EDA does not lead
to high performance. In particular, when the number of classes is higher than two. This is because
extracting the sympathetic response patterns which are part of each emotion is difficult. Furthermore,
when trying to overcome this fact by analyzing more basic features such as level, response amplitude,
rate, rise time, and recovery time, they discard flexible elicited behavior which might improve emotion
recognition. Therefore, it has been proven in this work that DL can overcome this drawback quite well.
Regarding the point of testing the proposed model using different datasets from different labs,
it is because human emotions do not form similar patterns. Consequently, the research community
should develop generalized models to recognize human emotions, where subjects, elicitation materials,
and physiological sensors brands are different from the ones involved in the initial training.",,
60,311,"Al Machot, F., Elmachot, A., Ali, M., Al Machot, E., & Kyamakya, K. (2019). A deep-learning model for subject-independent human emotion recognition using electrodermal activity sensors. Sensors, 19(7), 1659.",2019,dimensional,x,4,"HAHV, HALV, LAHV, LALV",,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Additionally, analyzing the results of the state-of-art, clearly, feature engineering for
subject-independent and subject-dependent human emotion detection based on EDA does not lead
to high performance. In particular, when the number of classes is higher than two. This is because
extracting the sympathetic response patterns which are part of each emotion is difficult. Furthermore,
when trying to overcome this fact by analyzing more basic features such as level, response amplitude,
rate, rise time, and recovery time, they discard flexible elicited behavior which might improve emotion
recognition. Therefore, it has been proven in this work that DL can overcome this drawback quite well.
Regarding the point of testing the proposed model using different datasets from different labs,
it is because human emotions do not form similar patterns. Consequently, the research community
should develop generalized models to recognize human emotions, where subjects, elicitation materials,
and physiological sensors brands are different from the ones involved in the initial training.",,
60,312,"Al Machot, F., Elmachot, A., Ali, M., Al Machot, E., & Kyamakya, K. (2019). A deep-learning model for subject-independent human emotion recognition using electrodermal activity sensors. Sensors, 19(7), 1659.",2019,dimensional,x,4,"HAHV, HALV, LAHV, LALV",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Additionally, analyzing the results of the state-of-art, clearly, feature engineering for
subject-independent and subject-dependent human emotion detection based on EDA does not lead
to high performance. In particular, when the number of classes is higher than two. This is because
extracting the sympathetic response patterns which are part of each emotion is difficult. Furthermore,
when trying to overcome this fact by analyzing more basic features such as level, response amplitude,
rate, rise time, and recovery time, they discard flexible elicited behavior which might improve emotion
recognition. Therefore, it has been proven in this work that DL can overcome this drawback quite well.
Regarding the point of testing the proposed model using different datasets from different labs,
it is because human emotions do not form similar patterns. Consequently, the research community
should develop generalized models to recognize human emotions, where subjects, elicitation materials,
and physiological sensors brands are different from the ones involved in the initial training.",,
60,313,"Al Machot, F., Elmachot, A., Ali, M., Al Machot, E., & Kyamakya, K. (2019). A deep-learning model for subject-independent human emotion recognition using electrodermal activity sensors. Sensors, 19(7), 1659.",2019,dimensional,x,4,"HAHV, HALV, LAHV, LALV",,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Additionally, analyzing the results of the state-of-art, clearly, feature engineering for
subject-independent and subject-dependent human emotion detection based on EDA does not lead
to high performance. In particular, when the number of classes is higher than two. This is because
extracting the sympathetic response patterns which are part of each emotion is difficult. Furthermore,
when trying to overcome this fact by analyzing more basic features such as level, response amplitude,
rate, rise time, and recovery time, they discard flexible elicited behavior which might improve emotion
recognition. Therefore, it has been proven in this work that DL can overcome this drawback quite well.
Regarding the point of testing the proposed model using different datasets from different labs,
it is because human emotions do not form similar patterns. Consequently, the research community
should develop generalized models to recognize human emotions, where subjects, elicitation materials,
and physiological sensors brands are different from the ones involved in the initial training.",,
60,314,"Al Machot, F., Elmachot, A., Ali, M., Al Machot, E., & Kyamakya, K. (2019). A deep-learning model for subject-independent human emotion recognition using electrodermal activity sensors. Sensors, 19(7), 1659.",2019,dimensional,x,4,"HAHV, HALV, LAHV, LALV",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Additionally, analyzing the results of the state-of-art, clearly, feature engineering for
subject-independent and subject-dependent human emotion detection based on EDA does not lead
to high performance. In particular, when the number of classes is higher than two. This is because
extracting the sympathetic response patterns which are part of each emotion is difficult. Furthermore,
when trying to overcome this fact by analyzing more basic features such as level, response amplitude,
rate, rise time, and recovery time, they discard flexible elicited behavior which might improve emotion
recognition. Therefore, it has been proven in this work that DL can overcome this drawback quite well.
Regarding the point of testing the proposed model using different datasets from different labs,
it is because human emotions do not form similar patterns. Consequently, the research community
should develop generalized models to recognize human emotions, where subjects, elicitation materials,
and physiological sensors brands are different from the ones involved in the initial training.",,
60,315,"Al Machot, F., Elmachot, A., Ali, M., Al Machot, E., & Kyamakya, K. (2019). A deep-learning model for subject-independent human emotion recognition using electrodermal activity sensors. Sensors, 19(7), 1659.",2019,dimensional,x,4,"HAHV, HALV, LAHV, LALV",,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Additionally, analyzing the results of the state-of-art, clearly, feature engineering for
subject-independent and subject-dependent human emotion detection based on EDA does not lead
to high performance. In particular, when the number of classes is higher than two. This is because
extracting the sympathetic response patterns which are part of each emotion is difficult. Furthermore,
when trying to overcome this fact by analyzing more basic features such as level, response amplitude,
rate, rise time, and recovery time, they discard flexible elicited behavior which might improve emotion
recognition. Therefore, it has been proven in this work that DL can overcome this drawback quite well.
Regarding the point of testing the proposed model using different datasets from different labs,
it is because human emotions do not form similar patterns. Consequently, the research community
should develop generalized models to recognize human emotions, where subjects, elicitation materials,
and physiological sensors brands are different from the ones involved in the initial training.",,
60,316,"Al Machot, F., Elmachot, A., Ali, M., Al Machot, E., & Kyamakya, K. (2019). A deep-learning model for subject-independent human emotion recognition using electrodermal activity sensors. Sensors, 19(7), 1659.",2019,dimensional,x,4,"HAHV, HALV, LAHV, LALV",,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Additionally, analyzing the results of the state-of-art, clearly, feature engineering for
subject-independent and subject-dependent human emotion detection based on EDA does not lead
to high performance. In particular, when the number of classes is higher than two. This is because
extracting the sympathetic response patterns which are part of each emotion is difficult. Furthermore,
when trying to overcome this fact by analyzing more basic features such as level, response amplitude,
rate, rise time, and recovery time, they discard flexible elicited behavior which might improve emotion
recognition. Therefore, it has been proven in this work that DL can overcome this drawback quite well.
Regarding the point of testing the proposed model using different datasets from different labs,
it is because human emotions do not form similar patterns. Consequently, the research community
should develop generalized models to recognize human emotions, where subjects, elicitation materials,
and physiological sensors brands are different from the ones involved in the initial training.",,
60,317,"Al Machot, F., Elmachot, A., Ali, M., Al Machot, E., & Kyamakya, K. (2019). A deep-learning model for subject-independent human emotion recognition using electrodermal activity sensors. Sensors, 19(7), 1659.",2019,dimensional,x,4,"HAHV, HALV, LAHV, LALV",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Additionally, analyzing the results of the state-of-art, clearly, feature engineering for
subject-independent and subject-dependent human emotion detection based on EDA does not lead
to high performance. In particular, when the number of classes is higher than two. This is because
extracting the sympathetic response patterns which are part of each emotion is difficult. Furthermore,
when trying to overcome this fact by analyzing more basic features such as level, response amplitude,
rate, rise time, and recovery time, they discard flexible elicited behavior which might improve emotion
recognition. Therefore, it has been proven in this work that DL can overcome this drawback quite well.
Regarding the point of testing the proposed model using different datasets from different labs,
it is because human emotions do not form similar patterns. Consequently, the research community
should develop generalized models to recognize human emotions, where subjects, elicitation materials,
and physiological sensors brands are different from the ones involved in the initial training.",,
60,318,"Al Machot, F., Elmachot, A., Ali, M., Al Machot, E., & Kyamakya, K. (2019). A deep-learning model for subject-independent human emotion recognition using electrodermal activity sensors. Sensors, 19(7), 1659.",2019,dimensional,x,4,"HAHV, HALV, LAHV, LALV",,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Additionally, analyzing the results of the state-of-art, clearly, feature engineering for
subject-independent and subject-dependent human emotion detection based on EDA does not lead
to high performance. In particular, when the number of classes is higher than two. This is because
extracting the sympathetic response patterns which are part of each emotion is difficult. Furthermore,
when trying to overcome this fact by analyzing more basic features such as level, response amplitude,
rate, rise time, and recovery time, they discard flexible elicited behavior which might improve emotion
recognition. Therefore, it has been proven in this work that DL can overcome this drawback quite well.
Regarding the point of testing the proposed model using different datasets from different labs,
it is because human emotions do not form similar patterns. Consequently, the research community
should develop generalized models to recognize human emotions, where subjects, elicitation materials,
and physiological sensors brands are different from the ones involved in the initial training.",,
60,319,"Al Machot, F., Elmachot, A., Ali, M., Al Machot, E., & Kyamakya, K. (2019). A deep-learning model for subject-independent human emotion recognition using electrodermal activity sensors. Sensors, 19(7), 1659.",2019,dimensional,x,4,"HAHV, HALV, LAHV, LALV",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Additionally, analyzing the results of the state-of-art, clearly, feature engineering for
subject-independent and subject-dependent human emotion detection based on EDA does not lead
to high performance. In particular, when the number of classes is higher than two. This is because
extracting the sympathetic response patterns which are part of each emotion is difficult. Furthermore,
when trying to overcome this fact by analyzing more basic features such as level, response amplitude,
rate, rise time, and recovery time, they discard flexible elicited behavior which might improve emotion
recognition. Therefore, it has been proven in this work that DL can overcome this drawback quite well.
Regarding the point of testing the proposed model using different datasets from different labs,
it is because human emotions do not form similar patterns. Consequently, the research community
should develop generalized models to recognize human emotions, where subjects, elicitation materials,
and physiological sensors brands are different from the ones involved in the initial training.",,
60,320,"Al Machot, F., Elmachot, A., Ali, M., Al Machot, E., & Kyamakya, K. (2019). A deep-learning model for subject-independent human emotion recognition using electrodermal activity sensors. Sensors, 19(7), 1659.",2019,dimensional,x,4,"HAHV, HALV, LAHV, LALV",,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Additionally, analyzing the results of the state-of-art, clearly, feature engineering for
subject-independent and subject-dependent human emotion detection based on EDA does not lead
to high performance. In particular, when the number of classes is higher than two. This is because
extracting the sympathetic response patterns which are part of each emotion is difficult. Furthermore,
when trying to overcome this fact by analyzing more basic features such as level, response amplitude,
rate, rise time, and recovery time, they discard flexible elicited behavior which might improve emotion
recognition. Therefore, it has been proven in this work that DL can overcome this drawback quite well.
Regarding the point of testing the proposed model using different datasets from different labs,
it is because human emotions do not form similar patterns. Consequently, the research community
should develop generalized models to recognize human emotions, where subjects, elicitation materials,
and physiological sensors brands are different from the ones involved in the initial training.",,
60,321,"Al Machot, F., Elmachot, A., Ali, M., Al Machot, E., & Kyamakya, K. (2019). A deep-learning model for subject-independent human emotion recognition using electrodermal activity sensors. Sensors, 19(7), 1659.",2019,dimensional,x,4,"HAHV, HALV, LAHV, LALV",,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Additionally, analyzing the results of the state-of-art, clearly, feature engineering for
subject-independent and subject-dependent human emotion detection based on EDA does not lead
to high performance. In particular, when the number of classes is higher than two. This is because
extracting the sympathetic response patterns which are part of each emotion is difficult. Furthermore,
when trying to overcome this fact by analyzing more basic features such as level, response amplitude,
rate, rise time, and recovery time, they discard flexible elicited behavior which might improve emotion
recognition. Therefore, it has been proven in this work that DL can overcome this drawback quite well.
Regarding the point of testing the proposed model using different datasets from different labs,
it is because human emotions do not form similar patterns. Consequently, the research community
should develop generalized models to recognize human emotions, where subjects, elicitation materials,
and physiological sensors brands are different from the ones involved in the initial training.",,
60,322,"Al Machot, F., Elmachot, A., Ali, M., Al Machot, E., & Kyamakya, K. (2019). A deep-learning model for subject-independent human emotion recognition using electrodermal activity sensors. Sensors, 19(7), 1659.",2019,dimensional,x,4,"HAHV, HALV, LAHV, LALV",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Additionally, analyzing the results of the state-of-art, clearly, feature engineering for
subject-independent and subject-dependent human emotion detection based on EDA does not lead
to high performance. In particular, when the number of classes is higher than two. This is because
extracting the sympathetic response patterns which are part of each emotion is difficult. Furthermore,
when trying to overcome this fact by analyzing more basic features such as level, response amplitude,
rate, rise time, and recovery time, they discard flexible elicited behavior which might improve emotion
recognition. Therefore, it has been proven in this work that DL can overcome this drawback quite well.
Regarding the point of testing the proposed model using different datasets from different labs,
it is because human emotions do not form similar patterns. Consequently, the research community
should develop generalized models to recognize human emotions, where subjects, elicitation materials,
and physiological sensors brands are different from the ones involved in the initial training.",,
60,323,"Al Machot, F., Elmachot, A., Ali, M., Al Machot, E., & Kyamakya, K. (2019). A deep-learning model for subject-independent human emotion recognition using electrodermal activity sensors. Sensors, 19(7), 1659.",2019,dimensional,x,4,"HAHV, HALV, LAHV, LALV",,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Additionally, analyzing the results of the state-of-art, clearly, feature engineering for
subject-independent and subject-dependent human emotion detection based on EDA does not lead
to high performance. In particular, when the number of classes is higher than two. This is because
extracting the sympathetic response patterns which are part of each emotion is difficult. Furthermore,
when trying to overcome this fact by analyzing more basic features such as level, response amplitude,
rate, rise time, and recovery time, they discard flexible elicited behavior which might improve emotion
recognition. Therefore, it has been proven in this work that DL can overcome this drawback quite well.
Regarding the point of testing the proposed model using different datasets from different labs,
it is because human emotions do not form similar patterns. Consequently, the research community
should develop generalized models to recognize human emotions, where subjects, elicitation materials,
and physiological sensors brands are different from the ones involved in the initial training.",,
60,324,"Al Machot, F., Elmachot, A., Ali, M., Al Machot, E., & Kyamakya, K. (2019). A deep-learning model for subject-independent human emotion recognition using electrodermal activity sensors. Sensors, 19(7), 1659.",2019,dimensional,x,4,"HAHV, HALV, LAHV, LALV",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Additionally, analyzing the results of the state-of-art, clearly, feature engineering for
subject-independent and subject-dependent human emotion detection based on EDA does not lead
to high performance. In particular, when the number of classes is higher than two. This is because
extracting the sympathetic response patterns which are part of each emotion is difficult. Furthermore,
when trying to overcome this fact by analyzing more basic features such as level, response amplitude,
rate, rise time, and recovery time, they discard flexible elicited behavior which might improve emotion
recognition. Therefore, it has been proven in this work that DL can overcome this drawback quite well.
Regarding the point of testing the proposed model using different datasets from different labs,
it is because human emotions do not form similar patterns. Consequently, the research community
should develop generalized models to recognize human emotions, where subjects, elicitation materials,
and physiological sensors brands are different from the ones involved in the initial training.",,
60,325,"Al Machot, F., Elmachot, A., Ali, M., Al Machot, E., & Kyamakya, K. (2019). A deep-learning model for subject-independent human emotion recognition using electrodermal activity sensors. Sensors, 19(7), 1659.",2019,dimensional,x,4,"HAHV, HALV, LAHV, LALV",,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Additionally, analyzing the results of the state-of-art, clearly, feature engineering for
subject-independent and subject-dependent human emotion detection based on EDA does not lead
to high performance. In particular, when the number of classes is higher than two. This is because
extracting the sympathetic response patterns which are part of each emotion is difficult. Furthermore,
when trying to overcome this fact by analyzing more basic features such as level, response amplitude,
rate, rise time, and recovery time, they discard flexible elicited behavior which might improve emotion
recognition. Therefore, it has been proven in this work that DL can overcome this drawback quite well.
Regarding the point of testing the proposed model using different datasets from different labs,
it is because human emotions do not form similar patterns. Consequently, the research community
should develop generalized models to recognize human emotions, where subjects, elicitation materials,
and physiological sensors brands are different from the ones involved in the initial training.",,
60,326,"Al Machot, F., Elmachot, A., Ali, M., Al Machot, E., & Kyamakya, K. (2019). A deep-learning model for subject-independent human emotion recognition using electrodermal activity sensors. Sensors, 19(7), 1659.",2019,dimensional,x,4,"HAHV, HALV, LAHV, LALV",,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Additionally, analyzing the results of the state-of-art, clearly, feature engineering for
subject-independent and subject-dependent human emotion detection based on EDA does not lead
to high performance. In particular, when the number of classes is higher than two. This is because
extracting the sympathetic response patterns which are part of each emotion is difficult. Furthermore,
when trying to overcome this fact by analyzing more basic features such as level, response amplitude,
rate, rise time, and recovery time, they discard flexible elicited behavior which might improve emotion
recognition. Therefore, it has been proven in this work that DL can overcome this drawback quite well.
Regarding the point of testing the proposed model using different datasets from different labs,
it is because human emotions do not form similar patterns. Consequently, the research community
should develop generalized models to recognize human emotions, where subjects, elicitation materials,
and physiological sensors brands are different from the ones involved in the initial training.",,
60,327,"Al Machot, F., Elmachot, A., Ali, M., Al Machot, E., & Kyamakya, K. (2019). A deep-learning model for subject-independent human emotion recognition using electrodermal activity sensors. Sensors, 19(7), 1659.",2019,dimensional,x,4,"HAHV, HALV, LAHV, LALV",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Additionally, analyzing the results of the state-of-art, clearly, feature engineering for
subject-independent and subject-dependent human emotion detection based on EDA does not lead
to high performance. In particular, when the number of classes is higher than two. This is because
extracting the sympathetic response patterns which are part of each emotion is difficult. Furthermore,
when trying to overcome this fact by analyzing more basic features such as level, response amplitude,
rate, rise time, and recovery time, they discard flexible elicited behavior which might improve emotion
recognition. Therefore, it has been proven in this work that DL can overcome this drawback quite well.
Regarding the point of testing the proposed model using different datasets from different labs,
it is because human emotions do not form similar patterns. Consequently, the research community
should develop generalized models to recognize human emotions, where subjects, elicitation materials,
and physiological sensors brands are different from the ones involved in the initial training.",,
60,328,"Al Machot, F., Elmachot, A., Ali, M., Al Machot, E., & Kyamakya, K. (2019). A deep-learning model for subject-independent human emotion recognition using electrodermal activity sensors. Sensors, 19(7), 1659.",2019,dimensional,x,4,"HAHV, HALV, LAHV, LALV",,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Additionally, analyzing the results of the state-of-art, clearly, feature engineering for
subject-independent and subject-dependent human emotion detection based on EDA does not lead
to high performance. In particular, when the number of classes is higher than two. This is because
extracting the sympathetic response patterns which are part of each emotion is difficult. Furthermore,
when trying to overcome this fact by analyzing more basic features such as level, response amplitude,
rate, rise time, and recovery time, they discard flexible elicited behavior which might improve emotion
recognition. Therefore, it has been proven in this work that DL can overcome this drawback quite well.
Regarding the point of testing the proposed model using different datasets from different labs,
it is because human emotions do not form similar patterns. Consequently, the research community
should develop generalized models to recognize human emotions, where subjects, elicitation materials,
and physiological sensors brands are different from the ones involved in the initial training.",,
61,329,"Seo, J., Laine, T. H., & Sohn, K. A. (2019). An exploration of machine learning methods for robust boredom classification using EEG and GSR data. Sensors, 19(20), 4561.",2019,dimensional,x,2,"weak boredom, strong boredom",,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Another major finding is that EEG and GSR appear to correlate with boredom, thus supporting
the conclusion of Bench and Lench [34] that boredom and autonomic nervous system are linked.",,
61,330,"Seo, J., Laine, T. H., & Sohn, K. A. (2019). An exploration of machine learning methods for robust boredom classification using EEG and GSR data. Sensors, 19(20), 4561.",2019,dimensional,x,2,"weak boredom, strong boredom",,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Another major finding is that EEG and GSR appear to correlate with boredom, thus supporting
the conclusion of Bench and Lench [34] that boredom and autonomic nervous system are linked.",,
61,331,"Seo, J., Laine, T. H., & Sohn, K. A. (2019). An exploration of machine learning methods for robust boredom classification using EEG and GSR data. Sensors, 19(20), 4561.",2019,dimensional,x,2,"weak boredom, strong boredom",,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Another major finding is that EEG and GSR appear to correlate with boredom, thus supporting
the conclusion of Bench and Lench [34] that boredom and autonomic nervous system are linked.",,
62,332,"Martinez, R., Salazar-Ramirez, A., Arruti, A., Irigoyen, E., Martin, J. I., & Muguerza, J. (2019). A self-paced relaxation response detection system based on galvanic skin response analysis. IEEE Access, 7, 43730-43741.",2019,dimensional,x,4,"Low Relaxation Response, Medium Relaxation Response, high relaxation Response, no relaxation response",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
62,333,"Martinez, R., Salazar-Ramirez, A., Arruti, A., Irigoyen, E., Martin, J. I., & Muguerza, J. (2019). A self-paced relaxation response detection system based on galvanic skin response analysis. IEEE Access, 7, 43730-43741.",2019,dimensional,x,4,"Low Relaxation Response, Medium Relaxation Response, high relaxation Response, no relaxation response",,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
62,334,"Martinez, R., Salazar-Ramirez, A., Arruti, A., Irigoyen, E., Martin, J. I., & Muguerza, J. (2019). A self-paced relaxation response detection system based on galvanic skin response analysis. IEEE Access, 7, 43730-43741.",2019,dimensional,x,4,"Low Relaxation Response, Medium Relaxation Response, high relaxation Response, no relaxation response",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
62,335,"Martinez, R., Salazar-Ramirez, A., Arruti, A., Irigoyen, E., Martin, J. I., & Muguerza, J. (2019). A self-paced relaxation response detection system based on galvanic skin response analysis. IEEE Access, 7, 43730-43741.",2019,dimensional,x,4,"Low Relaxation Response, Medium Relaxation Response, high relaxation Response, no relaxation response",,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
62,336,"Martinez, R., Salazar-Ramirez, A., Arruti, A., Irigoyen, E., Martin, J. I., & Muguerza, J. (2019). A self-paced relaxation response detection system based on galvanic skin response analysis. IEEE Access, 7, 43730-43741.",2019,dimensional,x,4,"Low Relaxation Response, Medium Relaxation Response, high relaxation Response, no relaxation response",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
62,337,"Martinez, R., Salazar-Ramirez, A., Arruti, A., Irigoyen, E., Martin, J. I., & Muguerza, J. (2019). A self-paced relaxation response detection system based on galvanic skin response analysis. IEEE Access, 7, 43730-43741.",2019,dimensional,x,4,"Low Relaxation Response, Medium Relaxation Response, high relaxation Response, no relaxation response",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
62,338,"Martinez, R., Salazar-Ramirez, A., Arruti, A., Irigoyen, E., Martin, J. I., & Muguerza, J. (2019). A self-paced relaxation response detection system based on galvanic skin response analysis. IEEE Access, 7, 43730-43741.",2019,dimensional,x,4,"Low Relaxation Response, Medium Relaxation Response, high relaxation Response, no relaxation response",x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
62,339,"Martinez, R., Salazar-Ramirez, A., Arruti, A., Irigoyen, E., Martin, J. I., & Muguerza, J. (2019). A self-paced relaxation response detection system based on galvanic skin response analysis. IEEE Access, 7, 43730-43741.",2019,dimensional,x,4,"Low Relaxation Response, Medium Relaxation Response, high relaxation Response, no relaxation response",,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
63,340,"Sharma, V., Prakash, N. R., & Kalra, P. (2019). Audio-video emotional response mapping based upon electrodermal activity. Biomedical Signal Processing and Control, 47, 324-333.",2019,dimensional,x,2,"HA, LA",,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
63,341,"Sharma, V., Prakash, N. R., & Kalra, P. (2019). Audio-video emotional response mapping based upon electrodermal activity. Biomedical Signal Processing and Control, 47, 324-333.",2019,dimensional,x,2,"HV, LV",,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
63,342,"Sharma, V., Prakash, N. R., & Kalra, P. (2019). Audio-video emotional response mapping based upon electrodermal activity. Biomedical Signal Processing and Control, 47, 324-333.",2019,dimensional,x,2,"high dominance, low dominance",,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
64,343,"Dar, M. N., Akram, M. U., Khawaja, S. G., & Pujari, A. N. (2020). Cnn and lstm-based emotion charting using physiological signals. Sensors, 20(16), 4551.",2020,dimensional,x,4,"HAHV, HALV, LAHV, LALV",,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Another
reason for the better performance of AMIGOS as compared to DREAMER is due to the nature of
the self-assessment acquisition process. Self-assessment for the AMIGOS dataset was obtained on
a scale of 1–9 for arousal and valence separately. However, for the DREAMER dataset, self-assessment rom subjects was acquired on the scale of 1–5 for both valence and arousal. The scale of 1–5 not only
exhibits half the freedom of choice on an intensity scale of emotion but also restricts the imbalance
created by avoiding the midpoint between 1–5 scale as participants can only provide integer data for
the intensity of arousal and valence. However, AMIGOS gives participants the liberty to self-assess
in a floating-point number for the scale of 1–9, hence better categorization of emotion can be made
which implied better performance of the algorithm on this dataset comparatively",,
65,344,"Greco, A., Marzi, C., Lanata, A., Scilingo, E. P., & Vanello, N. (2019, July). Combining electrodermal activity and speech analysis towards a more accurate emotion recognition system. In 2019 41st Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC) (pp. 229-232). IEEE.",2019,dimensional,x,2,"HA, LA",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Particularly, although EDA is one of
the most popular signals for measuring emotional arousal,
and the same processing methods have been successfully
applied in previous studies using emotional videos, images,
sounds, and touch [28]–[30], the recognition accuracy obtained in this case was not much higher than 50%. The cause
could be found in the altered respiration activity induced
by speech that affects ANS dynamics and covers up the
sympathetic arousal response",,
66,345,"Ganapathy, N., Veeranki, Y. R., & Swaminathan, R. (2020). Convolutional neural network based emotion classification using electrodermal activity signals and time-frequency features. Expert Systems with Applications, 159, 113571.",2020,dimensional,x,2,"HV, LV",,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
66,346,"Ganapathy, N., Veeranki, Y. R., & Swaminathan, R. (2020). Convolutional neural network based emotion classification using electrodermal activity signals and time-frequency features. Expert Systems with Applications, 159, 113571.",2020,dimensional,x,2,"HV, LV",,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
66,347,"Ganapathy, N., Veeranki, Y. R., & Swaminathan, R. (2020). Convolutional neural network based emotion classification using electrodermal activity signals and time-frequency features. Expert Systems with Applications, 159, 113571.",2020,dimensional,x,2,"HV, LV",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
66,348,"Ganapathy, N., Veeranki, Y. R., & Swaminathan, R. (2020). Convolutional neural network based emotion classification using electrodermal activity signals and time-frequency features. Expert Systems with Applications, 159, 113571.",2020,dimensional,x,2,"HV, LV",,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
66,349,"Ganapathy, N., Veeranki, Y. R., & Swaminathan, R. (2020). Convolutional neural network based emotion classification using electrodermal activity signals and time-frequency features. Expert Systems with Applications, 159, 113571.",2020,dimensional,x,2,"HV, LV",,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
66,350,"Ganapathy, N., Veeranki, Y. R., & Swaminathan, R. (2020). Convolutional neural network based emotion classification using electrodermal activity signals and time-frequency features. Expert Systems with Applications, 159, 113571.",2020,dimensional,x,2,"HV, LV",,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
66,351,"Ganapathy, N., Veeranki, Y. R., & Swaminathan, R. (2020). Convolutional neural network based emotion classification using electrodermal activity signals and time-frequency features. Expert Systems with Applications, 159, 113571.",2020,dimensional,x,2,"HA, LA",,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
66,352,"Ganapathy, N., Veeranki, Y. R., & Swaminathan, R. (2020). Convolutional neural network based emotion classification using electrodermal activity signals and time-frequency features. Expert Systems with Applications, 159, 113571.",2020,dimensional,x,2,"HA, LA",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
66,353,"Ganapathy, N., Veeranki, Y. R., & Swaminathan, R. (2020). Convolutional neural network based emotion classification using electrodermal activity signals and time-frequency features. Expert Systems with Applications, 159, 113571.",2020,dimensional,x,2,"HA, LA",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
66,354,"Ganapathy, N., Veeranki, Y. R., & Swaminathan, R. (2020). Convolutional neural network based emotion classification using electrodermal activity signals and time-frequency features. Expert Systems with Applications, 159, 113571.",2020,dimensional,x,2,"HA, LA",,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
66,355,"Ganapathy, N., Veeranki, Y. R., & Swaminathan, R. (2020). Convolutional neural network based emotion classification using electrodermal activity signals and time-frequency features. Expert Systems with Applications, 159, 113571.",2020,dimensional,x,2,"HA, LA",,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
66,356,"Ganapathy, N., Veeranki, Y. R., & Swaminathan, R. (2020). Convolutional neural network based emotion classification using electrodermal activity signals and time-frequency features. Expert Systems with Applications, 159, 113571.",2020,dimensional,x,2,"HA, LA",x,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
67,357,"Lee, S., Lee, T., Yang, T., Yoon, C., & Kim, S. P. (2020). Detection of drivers’ anxiety invoked by driving situations using multimodal biosignals. Processes, 8(2), 155.",2020,categorical,x,2,"anxiety, neutral",x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
68,358,"García-Faura, Á., Hernández-García, A., Fernández-Martínez, F., Díaz-de-María, F., & San-Segundo, R. (2019, January). Emotion and attention: Audiovisual models for group-level skin response recognition in short movies. In Web Intelligence (Vol. 17, No. 1, pp. 29-40). IOS Press.",2019,dimensional,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,1,arousal,x,,,,,,,,,,,,,,,,,-,-,,
69,359,"Wei, W., Jia, Q., Feng, Y., & Chen, G. (2018). Emotion recognition based on weighted fusion strategy of multichannel physiological signals. Computational intelligence and neuroscience, 2018.",2018,categorical,x,5,"sadness, happiness, disgust, neutral, fear",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
70,360,"El-Amir, M. M., Al-Atabany, W., & Eldosoky, M. A. (2019, April). Emotion Recognition via Detrended Fluctuation Analysis and Fractal Dimensions. In 2019 36th National Radio Science Conference (NRSC) (pp. 200-208). IEEE.",2019,dimensional,x,3,"happy, neutral, sad",,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
70,361,"El-Amir, M. M., Al-Atabany, W., & Eldosoky, M. A. (2019, April). Emotion Recognition via Detrended Fluctuation Analysis and Fractal Dimensions. In 2019 36th National Radio Science Conference (NRSC) (pp. 200-208). IEEE.",2019,dimensional,x,3,"happy, neutral, sad",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
70,362,"El-Amir, M. M., Al-Atabany, W., & Eldosoky, M. A. (2019, April). Emotion Recognition via Detrended Fluctuation Analysis and Fractal Dimensions. In 2019 36th National Radio Science Conference (NRSC) (pp. 200-208). IEEE.",2019,dimensional,x,3,"happy, neutral, sad",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
70,363,"El-Amir, M. M., Al-Atabany, W., & Eldosoky, M. A. (2019, April). Emotion Recognition via Detrended Fluctuation Analysis and Fractal Dimensions. In 2019 36th National Radio Science Conference (NRSC) (pp. 200-208). IEEE.",2019,dimensional,x,3,"excited, calm, sleepy",,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
70,364,"El-Amir, M. M., Al-Atabany, W., & Eldosoky, M. A. (2019, April). Emotion Recognition via Detrended Fluctuation Analysis and Fractal Dimensions. In 2019 36th National Radio Science Conference (NRSC) (pp. 200-208). IEEE.",2019,dimensional,x,3,"excited, calm, sleepy",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
70,365,"El-Amir, M. M., Al-Atabany, W., & Eldosoky, M. A. (2019, April). Emotion Recognition via Detrended Fluctuation Analysis and Fractal Dimensions. In 2019 36th National Radio Science Conference (NRSC) (pp. 200-208). IEEE.",2019,dimensional,x,3,"excited, calm, sleepy",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
71,366,"Tung, K., Liu, P. K., Chuang, Y. C., Wang, S. H., & Wu, A. Y. A. (2018, December). Entropy-assisted multi-modal emotion recognition framework based on physiological signals. In 2018 IEEE-EMBS Conference on Biomedical Engineering and Sciences (IECBES) (pp. 22-26). IEEE.",2019,dimensional,x,2,"HA, LA",,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
71,367,"Tung, K., Liu, P. K., Chuang, Y. C., Wang, S. H., & Wu, A. Y. A. (2018, December). Entropy-assisted multi-modal emotion recognition framework based on physiological signals. In 2018 IEEE-EMBS Conference on Biomedical Engineering and Sciences (IECBES) (pp. 22-26). IEEE.",2019,dimensional,x,2,"HV, LV",,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
72,368,"Golgouneh, A., & Tarvirdizadeh, B. (2020). Fabrication of a portable device for stress monitoring using wearable sensors and soft computing algorithms. Neural Computing and Applications, 32(11), 7515-7537.",2020,dimensional,x,3,"stressful, normal, relaxing",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
72,369,"Golgouneh, A., & Tarvirdizadeh, B. (2020). Fabrication of a portable device for stress monitoring using wearable sensors and soft computing algorithms. Neural Computing and Applications, 32(11), 7515-7537.",2020,dimensional,x,3,"stressful, normal, relaxing",,,,,,,,,,,,,,,,,x,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
72,370,"Golgouneh, A., & Tarvirdizadeh, B. (2020). Fabrication of a portable device for stress monitoring using wearable sensors and soft computing algorithms. Neural Computing and Applications, 32(11), 7515-7537.",2020,dimensional,x,3,"stressful, normal, relaxing",,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,x,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
72,371,"Golgouneh, A., & Tarvirdizadeh, B. (2020). Fabrication of a portable device for stress monitoring using wearable sensors and soft computing algorithms. Neural Computing and Applications, 32(11), 7515-7537.",2020,dimensional,x,3,"stressful, normal, relaxing",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
72,372,"Golgouneh, A., & Tarvirdizadeh, B. (2020). Fabrication of a portable device for stress monitoring using wearable sensors and soft computing algorithms. Neural Computing and Applications, 32(11), 7515-7537.",2020,dimensional,x,3,"stressful, normal, relaxing",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
73,373,"Sun, X., Hong, T., Li, C., & Ren, F. (2019). Hybrid spatiotemporal models for sentiment classification via galvanic skin response. Neurocomputing, 358, 385-400.",2019,categorical,x,6,"sad, angry, happy, surprise, fear, disgust ",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
73,374,"Sun, X., Hong, T., Li, C., & Ren, F. (2019). Hybrid spatiotemporal models for sentiment classification via galvanic skin response. Neurocomputing, 358, 385-400.",2019,categorical,x,6,"sad, angry, happy, surprise, feadr, disgust ",,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
73,375,"Sun, X., Hong, T., Li, C., & Ren, F. (2019). Hybrid spatiotemporal models for sentiment classification via galvanic skin response. Neurocomputing, 358, 385-400.",2019,categorical,x,6,"sad, angry, happy, surprise, feadr, disgust ",,,,,,,,,,,,,,,,,,x,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
74,376,"Chang, E. J., Rahimi, A., Benini, L., & Wu, A. Y. A. (2019, March). Hyperdimensional computing-based multimodality emotion recognition with physiological signals. In 2019 IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS) (pp. 137-141). IEEE.",2019,dimensional,x,2,"HV, LV",,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
74,377,"Chang, E. J., Rahimi, A., Benini, L., & Wu, A. Y. A. (2019, March). Hyperdimensional computing-based multimodality emotion recognition with physiological signals. In 2019 IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS) (pp. 137-141). IEEE.",2019,dimensional,x,2,"HV, LV",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
74,378,"Chang, E. J., Rahimi, A., Benini, L., & Wu, A. Y. A. (2019, March). Hyperdimensional computing-based multimodality emotion recognition with physiological signals. In 2019 IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS) (pp. 137-141). IEEE.",2019,dimensional,x,2,"HV, LV",,,,,,,,,,,,,,,,X,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
74,379,"Chang, E. J., Rahimi, A., Benini, L., & Wu, A. Y. A. (2019, March). Hyperdimensional computing-based multimodality emotion recognition with physiological signals. In 2019 IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS) (pp. 137-141). IEEE.",2019,dimensional,x,2,"HV, LV",,,,,,,,,,,,,,X,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
74,380,"Chang, E. J., Rahimi, A., Benini, L., & Wu, A. Y. A. (2019, March). Hyperdimensional computing-based multimodality emotion recognition with physiological signals. In 2019 IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS) (pp. 137-141). IEEE.",2019,dimensional,x,2,"HA, LA",,,,,,,X,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
74,381,"Chang, E. J., Rahimi, A., Benini, L., & Wu, A. Y. A. (2019, March). Hyperdimensional computing-based multimodality emotion recognition with physiological signals. In 2019 IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS) (pp. 137-141). IEEE.",2019,dimensional,x,2,"HA, LA",,X,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
74,382,"Chang, E. J., Rahimi, A., Benini, L., & Wu, A. Y. A. (2019, March). Hyperdimensional computing-based multimodality emotion recognition with physiological signals. In 2019 IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS) (pp. 137-141). IEEE.",2019,dimensional,x,2,"HA, LA",,,,,,,,,,,,,,,,X,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
74,383,"Chang, E. J., Rahimi, A., Benini, L., & Wu, A. Y. A. (2019, March). Hyperdimensional computing-based multimodality emotion recognition with physiological signals. In 2019 IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS) (pp. 137-141). IEEE.",2019,dimensional,x,2,"HA, LA",,,,,,,,,,,,,,X,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
75,384,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019,categorical,x,7,"joy, funny, anger, fear, disgust, sad, neutrality",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
75,385,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019,categorical,x,7,"joy, funny, anger, fear, disgust, sad, neutrality",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
75,386,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019,categorical,x,7,"joy, funny, anger, fear, disgust, sad, neutrality",,,,,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
75,387,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019,categorical,x,7,"joy, funny, anger, fear, disgust, sad, neutrality",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,
75,388,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019,categorical,x,7,"joy, funny, anger, fear, disgust, sad, neutrality",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,
75,389,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019,categorical,x,7,"joy, funny, anger, fear, disgust, sad, neutrality",,,,,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,
75,390,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019,categorical,x,7,"joy, funny, anger, fear, disgust, sad, neutrality",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,
75,391,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019,categorical,x,7,"joy, funny, anger, fear, disgust, sad, neutrality",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,
75,392,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019,categorical,x,7,"joy, funny, anger, fear, disgust, sad, neutrality",,,,,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,
75,393,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019,categorical,x,3,"joy, neutral, anger",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,
75,394,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019,categorical,x,3,"joy, neutral, anger",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,
75,395,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019,categorical,x,3,"joy, neutral, anger",,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,
75,396,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019,categorical,x,3,"joy, neutral, fear",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,
75,397,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019,categorical,x,3,"joy, neutral, fear",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,
75,398,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019,categorical,x,3,"joy, neutral, fear",,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,
75,399,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019,categorical,x,3,"joy, neutral, disgust",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,
75,400,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019,categorical,x,3,"joy, neutral, disgust",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,
75,401,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019,categorical,x,3,"joy, neutral, disgust",,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,
75,402,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019,categorical,x,3,"joy, neutral, sad",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,
75,403,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019,categorical,x,3,"joy, neutral, sad",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,
75,404,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019,categorical,x,3,"joy, neutral, sad",,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,
75,405,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019,categorical,x,3,"funny, neutral, anger",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,
75,406,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019,categorical,x,3,"funny, neutral, anger",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,
75,407,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019,categorical,x,3,"funny, neutral, anger",,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,
75,408,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019,categorical,x,3,"funny, neutral, fear",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,
75,409,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019,categorical,x,3,"funny, neutral, fear",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,
75,410,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019,categorical,x,3,"funny, neutral, fear",,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,
75,411,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019,categorical,x,3,"funny, neutral, disgust",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,
75,412,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019,categorical,x,3,"funny, neutral, disgust",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,
75,413,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019,categorical,x,3,"funny, neutral, disgust",,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,
75,414,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019,categorical,x,3,"funny, neutral, sad",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,
75,415,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019,categorical,x,3,"funny, neutral, sad",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,
75,416,"Song, T., Zheng, W., Lu, C., Zong, Y., Zhang, X., & Cui, Z. (2019). MPED: A multi-modal physiological emotion database for discrete emotion recognition. IEEE Access, 7, 12177-12191.",2019,categorical,x,3,"funny, neutral, sad",,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,"Finally, significant correlates were found between the participant ratings and EEG signals. The spearman correlation
coefficients analysis of this database demonstrated that the
energy in prefrontal part is positively correlated with the level
of positive emotion states and negative correlated with the
level of negative emotion states. The difference of coefficients distribution between positive emotions and negative
emotions was apparent to be distinguished and The coefficient distributions among negative emotions were similar,
which validated that negative emotion categories are to a
large extent overlapped.",,
76,417,"Thammasan, N., Hagad, J. L., Fukui, K. I., & Numao, M. (2017, October). Multimodal stability-sensitive emotion recognition based on brainwave and physiological signals. In 2017 Seventh International Conference on Affective Computing and Intelligent Interaction Workshops and Demos (ACIIW) (pp. 44-49). IEEE.",2018,dimensional,x,2,"HV, LV",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
76,418,"Thammasan, N., Hagad, J. L., Fukui, K. I., & Numao, M. (2017, October). Multimodal stability-sensitive emotion recognition based on brainwave and physiological signals. In 2017 Seventh International Conference on Affective Computing and Intelligent Interaction Workshops and Demos (ACIIW) (pp. 44-49). IEEE.",2018,dimensional,x,2,"HA, LA",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
77,419,"Pinto, G., Carvalho, J. M., Barros, F., Soares, S. C., Pinho, A. J., & Brás, S. (2020). Multimodal emotion evaluation: A physiological model for cost-effective emotion classification. Sensors, 20(12), 3510.",2020,categorical,x,3,"neutral, fear, happy",,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"This research analyzed the physiological component of emotion in different emotional conditions
(fear, happiness and neutral), using automatic systems for emotion identification. Our results suggest
that the ECG signal seems to be the most informative in emotion stratification. The use of facial EMG
in emotion is dependent on monitoring two (or more) muscles, allowing to identify facial expression
changes by corresponding muscular contractions. Nevertheless, if all signals are used on emotion
identification, a higher accuracy is achieved, since all signals are representative of different information.
This physiological model of emotions has important research and clinical implications, by providing
valuable information about the value and weight of physiological signals for emotional classification,
which can critically drive effective evaluation, monitoring, and intervention regarding emotional
processing and regulation, considering multiple contexts",,
77,420,"Pinto, G., Carvalho, J. M., Barros, F., Soares, S. C., Pinho, A. J., & Brás, S. (2020). Multimodal emotion evaluation: A physiological model for cost-effective emotion classification. Sensors, 20(12), 3510.",2020,categorical,x,3,"neutral, fear, happy",,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"This research analyzed the physiological component of emotion in different emotional conditions
(fear, happiness and neutral), using automatic systems for emotion identification. Our results suggest
that the ECG signal seems to be the most informative in emotion stratification. The use of facial EMG
in emotion is dependent on monitoring two (or more) muscles, allowing to identify facial expression
changes by corresponding muscular contractions. Nevertheless, if all signals are used on emotion
identification, a higher accuracy is achieved, since all signals are representative of different information.
This physiological model of emotions has important research and clinical implications, by providing
valuable information about the value and weight of physiological signals for emotional classification,
which can critically drive effective evaluation, monitoring, and intervention regarding emotional
processing and regulation, considering multiple contexts",,
78,421,"Raheel, A., Majid, M., Alnowami, M., & Anwar, S. M. (2020). Physiological sensors based emotion recognition while experiencing tactile enhanced multimedia. Sensors, 20(14), 4037.",2020,categorical,x,4,"happy, relaxed, angry, sad",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"While our study shows that with TEM, the emotion
recognition accuracy increases, which could mean that the users were able to better feel the emotions
as the video content intended to deliver. The use of physiological sensors also ensures that the true
sensation of emotion is detected which is subjectively independent of users.",,
79,422,"Liu, Y., & Jiang, C. (2019). Recognition of shooter’s emotions under stress based on affective computing. IEEE Access, 7, 62338-62343.",2019,categorical,x,4,"happiness, sadness, anger, fear",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
79,423,"Liu, Y., & Jiang, C. (2019). Recognition of shooter’s emotions under stress based on affective computing. IEEE Access, 7, 62338-62343.",2019,categorical,x,4,"happiness, sadness, anger, fear",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
79,424,"Liu, Y., & Jiang, C. (2019). Recognition of shooter’s emotions under stress based on affective computing. IEEE Access, 7, 62338-62343.",2019,categorical,x,4,"happiness, sadness, anger, fear",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
79,425,"Liu, Y., & Jiang, C. (2019). Recognition of shooter’s emotions under stress based on affective computing. IEEE Access, 7, 62338-62343.",2019,categorical,x,4,"happiness, sadness, anger, fear",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
80,426,"Zhang, K., Zhang, H., Li, S., Yang, C., & Sun, L. (2018, June). The pmemo dataset for music emotion recognition. In Proceedings of the 2018 acm on international conference on multimedia retrieval (pp. 135-142).",2018,dimensional,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,1,valence,,,,,,,,x,,,,,,,-,-,-,-,-,,
80,427,"Zhang, K., Zhang, H., Li, S., Yang, C., & Sun, L. (2018, June). The pmemo dataset for music emotion recognition. In Proceedings of the 2018 acm on international conference on multimedia retrieval (pp. 135-142).",2018,dimensional,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,1,valence,,x,,,,,,,,,,,,,-,-,-,-,-,,
80,428,"Zhang, K., Zhang, H., Li, S., Yang, C., & Sun, L. (2018, June). The pmemo dataset for music emotion recognition. In Proceedings of the 2018 acm on international conference on multimedia retrieval (pp. 135-142).",2018,dimensional,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,1,arousal,,,,,,,,x,,,,,,,-,-,-,-,-,,
80,429,"Zhang, K., Zhang, H., Li, S., Yang, C., & Sun, L. (2018, June). The pmemo dataset for music emotion recognition. In Proceedings of the 2018 acm on international conference on multimedia retrieval (pp. 135-142).",2018,dimensional,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,1,arousal,,x,,,,,,,,,,,,,-,-,-,-,-,,
81,430,"Niu, Y., Wang, D., Wang, Z., Sun, F., Yue, K., & Zheng, N. (2020). User experience evaluation in virtual reality based on subjective feelings and physiological signals. Electronic Imaging, 2020(13), 60413-1.",2020,dimensional,x,4,"HAHV, HALV, LAHV, LALV",,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,,-,-,-,-,-,,
81,431,"Niu, Y., Wang, D., Wang, Z., Sun, F., Yue, K., & Zheng, N. (2020). User experience evaluation in virtual reality based on subjective feelings and physiological signals. Electronic Imaging, 2020(13), 60413-1.",2020,dimensional,x,4,"HAHV, HALV, LAHV, LALV",x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,,,,-,-,-,-,-,,
81,432,"Niu, Y., Wang, D., Wang, Z., Sun, F., Yue, K., & Zheng, N. (2020). User experience evaluation in virtual reality based on subjective feelings and physiological signals. Electronic Imaging, 2020(13), 60413-1.",2020,dimensional,x,4,"HAHV, HALV, LAHV, LALV",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,,,-,-,-,-,-,,
81,433,"Niu, Y., Wang, D., Wang, Z., Sun, F., Yue, K., & Zheng, N. (2020). User experience evaluation in virtual reality based on subjective feelings and physiological signals. Electronic Imaging, 2020(13), 60413-1.",2020,dimensional,x,4,"HAHV, HALV, LAHV, LALV",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
81,434,"Niu, Y., Wang, D., Wang, Z., Sun, F., Yue, K., & Zheng, N. (2020). User experience evaluation in virtual reality based on subjective feelings and physiological signals. Electronic Imaging, 2020(13), 60413-1.",2020,dimensional,x,4,"HAHV, HALV, LAHV, LALV",,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,,-,-,-,-,-,,
81,435,"Niu, Y., Wang, D., Wang, Z., Sun, F., Yue, K., & Zheng, N. (2020). User experience evaluation in virtual reality based on subjective feelings and physiological signals. Electronic Imaging, 2020(13), 60413-1.",2020,dimensional,x,4,"HAHV, HALV, LAHV, LALV",x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,,,,-,-,-,-,-,,
81,436,"Niu, Y., Wang, D., Wang, Z., Sun, F., Yue, K., & Zheng, N. (2020). User experience evaluation in virtual reality based on subjective feelings and physiological signals. Electronic Imaging, 2020(13), 60413-1.",2020,dimensional,x,4,"HAHV, HALV, LAHV, LALV",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,,,-,-,-,-,-,,
81,437,"Niu, Y., Wang, D., Wang, Z., Sun, F., Yue, K., & Zheng, N. (2020). User experience evaluation in virtual reality based on subjective feelings and physiological signals. Electronic Imaging, 2020(13), 60413-1.",2020,dimensional,x,4,"HAHV, HALV, LAHV, LALV",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
82,438,"Santamaria-Granados, L., Munoz-Organero, M., Ramirez-Gonzalez, G., Abdulhay, E., & Arunkumar, N. J. I. A. (2018). Using deep convolutional neural network for emotion detection on a physiological signals dataset (AMIGOS). IEEE Access, 7, 57-67.",2019,dimensional,x,2,"HA, LA",,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Physiological datasets with a large number of instances are
optimal for the proposed experiments since these directly
influence the emotion prediction, a the greater the number
of instances, the more effective the model. Consequently,
several annotations of arousal and valence must be recorded,
since, when subjecting a participant to the stimulus of a short
video, it can manifest different levels of emotion during of
experiment.",,
82,439,"Santamaria-Granados, L., Munoz-Organero, M., Ramirez-Gonzalez, G., Abdulhay, E., & Arunkumar, N. J. I. A. (2018). Using deep convolutional neural network for emotion detection on a physiological signals dataset (AMIGOS). IEEE Access, 7, 57-67.",2019,dimensional,x,2,"HV, LV",,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Physiological datasets with a large number of instances are
optimal for the proposed experiments since these directly
influence the emotion prediction, a the greater the number
of instances, the more effective the model. Consequently,
several annotations of arousal and valence must be recorded,
since, when subjecting a participant to the stimulus of a short
video, it can manifest different levels of emotion during of
experiment.",,
83,440,"Zhang, L. K., Sun, S. Q., Xing, B. X., Luo, R. M., & Zhang, K. J. (2019). Using psychophysiological measures to recognize personal music emotional experience. Frontiers of Information Technology & Electronic Engineering, 20(7), 964-974.",2019,dimensional,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,1,valence,,,,,,,x,,,,,,,,-,-,-,-,-,,
83,441,"Zhang, L. K., Sun, S. Q., Xing, B. X., Luo, R. M., & Zhang, K. J. (2019). Using psychophysiological measures to recognize personal music emotional experience. Frontiers of Information Technology & Electronic Engineering, 20(7), 964-974.",2019,dimensional,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,1,valence,,x,,,,,,,,,,,,,-,-,-,-,-,,
83,442,"Zhang, L. K., Sun, S. Q., Xing, B. X., Luo, R. M., & Zhang, K. J. (2019). Using psychophysiological measures to recognize personal music emotional experience. Frontiers of Information Technology & Electronic Engineering, 20(7), 964-974.",2019,dimensional,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,1,valence,x,,,,,,,,,,,,,,-,-,-,-,-,,
83,443,"Zhang, L. K., Sun, S. Q., Xing, B. X., Luo, R. M., & Zhang, K. J. (2019). Using psychophysiological measures to recognize personal music emotional experience. Frontiers of Information Technology & Electronic Engineering, 20(7), 964-974.",2019,dimensional,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,1,valence,,,,x,,,,,,,,,,,-,-,-,-,-,,
83,444,"Zhang, L. K., Sun, S. Q., Xing, B. X., Luo, R. M., & Zhang, K. J. (2019). Using psychophysiological measures to recognize personal music emotional experience. Frontiers of Information Technology & Electronic Engineering, 20(7), 964-974.",2019,dimensional,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,1,valence,,,,,,,,,,x,,,,,-,-,-,-,-,,
83,445,"Zhang, L. K., Sun, S. Q., Xing, B. X., Luo, R. M., & Zhang, K. J. (2019). Using psychophysiological measures to recognize personal music emotional experience. Frontiers of Information Technology & Electronic Engineering, 20(7), 964-974.",2019,dimensional,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,1,valence,,,,,,x,,,,,,,,,-,-,-,-,-,,
83,446,"Zhang, L. K., Sun, S. Q., Xing, B. X., Luo, R. M., & Zhang, K. J. (2019). Using psychophysiological measures to recognize personal music emotional experience. Frontiers of Information Technology & Electronic Engineering, 20(7), 964-974.",2019,dimensional,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,1,arousal,,,,,,,x,,,,,,,,-,-,-,-,-,,
83,447,"Zhang, L. K., Sun, S. Q., Xing, B. X., Luo, R. M., & Zhang, K. J. (2019). Using psychophysiological measures to recognize personal music emotional experience. Frontiers of Information Technology & Electronic Engineering, 20(7), 964-974.",2019,dimensional,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,1,arousal,,x,,,,,,,,,,,,,-,-,-,-,-,,
83,448,"Zhang, L. K., Sun, S. Q., Xing, B. X., Luo, R. M., & Zhang, K. J. (2019). Using psychophysiological measures to recognize personal music emotional experience. Frontiers of Information Technology & Electronic Engineering, 20(7), 964-974.",2019,dimensional,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,1,arousal,x,,,,,,,,,,,,,,-,-,-,-,-,,
83,449,"Zhang, L. K., Sun, S. Q., Xing, B. X., Luo, R. M., & Zhang, K. J. (2019). Using psychophysiological measures to recognize personal music emotional experience. Frontiers of Information Technology & Electronic Engineering, 20(7), 964-974.",2019,dimensional,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,1,arousal,,,,x,,,,,,,,,,,-,-,-,-,-,,
83,450,"Zhang, L. K., Sun, S. Q., Xing, B. X., Luo, R. M., & Zhang, K. J. (2019). Using psychophysiological measures to recognize personal music emotional experience. Frontiers of Information Technology & Electronic Engineering, 20(7), 964-974.",2019,dimensional,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,1,arousal,,,,,,,,,,x,,,,,-,-,-,-,-,,
83,451,"Zhang, L. K., Sun, S. Q., Xing, B. X., Luo, R. M., & Zhang, K. J. (2019). Using psychophysiological measures to recognize personal music emotional experience. Frontiers of Information Technology & Electronic Engineering, 20(7), 964-974.",2019,dimensional,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,1,arousal,,,,,,x,,,,,,,,,-,-,-,-,-,,
84,452,"Liapis, A., Katsanos, C., Karousos, N., Xenos, M., & Orphanoudakis, T. (2019, September). UDSP+ stress detection based on user-reported emotional ratings and wearable skin conductance sensor. In Adjunct Proceedings of the 2019 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2019 ACM International Symposium on Wearable Computers (pp. 125-128).",2019,dimensional,x,2,"stress, not stress",,X,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
84,453,"Liapis, A., Katsanos, C., Karousos, N., Xenos, M., & Orphanoudakis, T. (2019, September). UDSP+ stress detection based on user-reported emotional ratings and wearable skin conductance sensor. In Adjunct Proceedings of the 2019 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2019 ACM International Symposium on Wearable Computers (pp. 125-128).",2019,dimensional,x,2,"stress, not stress",,,,,,X,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
85,454,"Xie, J., Xu, X., & Shu, L. (2018, May). WT feature based emotion recognition from multi-channel physiological signals with decision fusion. In 2018 First Asian Conference on Affective Computing and Intelligent Interaction (ACII Asia) (pp. 1-6). IEEE.",2018,categorical,x,5,"amusement, sadness, anger, disgust, fear",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"The proposed framework has enhanced the performance of
emotion recognition. The reason might be as follows. First, as
human being has the multivariate characteristics, it is difficult
to accurately reflect the emotional changes by means of
specific peripheral physiological signal. ECG, EMG and SCL
might complement each other to reflect the emotional changes
well. Second, the most emotion-related physiological features
might be discovered by using feature selection. Furthermore,
the adverse interference between different physiological signals could be totally avoided with decision fusion. As for
future work, the following attempts are deserved. We will try
to extract the unseen features with deep neural networks to
form multi-level feature set in order to get rid of the problem
of weak generalization ability caused by using features in lowdimension space. On the other hand, other dataset could be
considered, such as DEAP and MAHNOB to evaluate and
optimize our framework. Last but not least, as feature selection
methods greatly affect the recognition results, we will try
more feature selection methods. And further experiments on
classifying extensive emotion states would be conducted in the
next stage.",,
85,455,"Xie, J., Xu, X., & Shu, L. (2018, May). WT feature based emotion recognition from multi-channel physiological signals with decision fusion. In 2018 First Asian Conference on Affective Computing and Intelligent Interaction (ACII Asia) (pp. 1-6). IEEE.",2018,categorical,x,5,"amusement, sadness, anger, disgust, fear",,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"The proposed framework has enhanced the performance of
emotion recognition. The reason might be as follows. First, as
human being has the multivariate characteristics, it is difficult
to accurately reflect the emotional changes by means of
specific peripheral physiological signal. ECG, EMG and SCL
might complement each other to reflect the emotional changes
well. Second, the most emotion-related physiological features
might be discovered by using feature selection. Furthermore,
the adverse interference between different physiological signals could be totally avoided with decision fusion. As for
future work, the following attempts are deserved. We will try
to extract the unseen features with deep neural networks to
form multi-level feature set in order to get rid of the problem
of weak generalization ability caused by using features in lowdimension space. On the other hand, other dataset could be
considered, such as DEAP and MAHNOB to evaluate and
optimize our framework. Last but not least, as feature selection
methods greatly affect the recognition results, we will try
more feature selection methods. And further experiments on
classifying extensive emotion states would be conducted in the
next stage.",,
85,456,"Xie, J., Xu, X., & Shu, L. (2018, May). WT feature based emotion recognition from multi-channel physiological signals with decision fusion. In 2018 First Asian Conference on Affective Computing and Intelligent Interaction (ACII Asia) (pp. 1-6). IEEE.",2018,categorical,x,5,"amusement, sadness, anger, disgust, fear",,,,,,,,,,,,,,,,X,,,,,,,,,,,,,,,,,,,,,,,,,,X,,,,,,,,-,-,-,x,"The proposed framework has enhanced the performance of
emotion recognition. The reason might be as follows. First, as
human being has the multivariate characteristics, it is difficult
to accurately reflect the emotional changes by means of
specific peripheral physiological signal. ECG, EMG and SCL
might complement each other to reflect the emotional changes
well. Second, the most emotion-related physiological features
might be discovered by using feature selection. Furthermore,
the adverse interference between different physiological signals could be totally avoided with decision fusion. As for
future work, the following attempts are deserved. We will try
to extract the unseen features with deep neural networks to
form multi-level feature set in order to get rid of the problem
of weak generalization ability caused by using features in lowdimension space. On the other hand, other dataset could be
considered, such as DEAP and MAHNOB to evaluate and
optimize our framework. Last but not least, as feature selection
methods greatly affect the recognition results, we will try
more feature selection methods. And further experiments on
classifying extensive emotion states would be conducted in the
next stage.",,
85,457,"Xie, J., Xu, X., & Shu, L. (2018, May). WT feature based emotion recognition from multi-channel physiological signals with decision fusion. In 2018 First Asian Conference on Affective Computing and Intelligent Interaction (ACII Asia) (pp. 1-6). IEEE.",2018,categorical,x,5,"amusement, sadness, anger, disgust, fear",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,X,,,,,,,,-,-,-,x,"The proposed framework has enhanced the performance of
emotion recognition. The reason might be as follows. First, as
human being has the multivariate characteristics, it is difficult
to accurately reflect the emotional changes by means of
specific peripheral physiological signal. ECG, EMG and SCL
might complement each other to reflect the emotional changes
well. Second, the most emotion-related physiological features
might be discovered by using feature selection. Furthermore,
the adverse interference between different physiological signals could be totally avoided with decision fusion. As for
future work, the following attempts are deserved. We will try
to extract the unseen features with deep neural networks to
form multi-level feature set in order to get rid of the problem
of weak generalization ability caused by using features in lowdimension space. On the other hand, other dataset could be
considered, such as DEAP and MAHNOB to evaluate and
optimize our framework. Last but not least, as feature selection
methods greatly affect the recognition results, we will try
more feature selection methods. And further experiments on
classifying extensive emotion states would be conducted in the
next stage.",,
85,458,"Xie, J., Xu, X., & Shu, L. (2018, May). WT feature based emotion recognition from multi-channel physiological signals with decision fusion. In 2018 First Asian Conference on Affective Computing and Intelligent Interaction (ACII Asia) (pp. 1-6). IEEE.",2018,categorical,x,5,"amusement, sadness, anger, disgust, fear",,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"The proposed framework has enhanced the performance of
emotion recognition. The reason might be as follows. First, as
human being has the multivariate characteristics, it is difficult
to accurately reflect the emotional changes by means of
specific peripheral physiological signal. ECG, EMG and SCL
might complement each other to reflect the emotional changes
well. Second, the most emotion-related physiological features
might be discovered by using feature selection. Furthermore,
the adverse interference between different physiological signals could be totally avoided with decision fusion. As for
future work, the following attempts are deserved. We will try
to extract the unseen features with deep neural networks to
form multi-level feature set in order to get rid of the problem
of weak generalization ability caused by using features in lowdimension space. On the other hand, other dataset could be
considered, such as DEAP and MAHNOB to evaluate and
optimize our framework. Last but not least, as feature selection
methods greatly affect the recognition results, we will try
more feature selection methods. And further experiments on
classifying extensive emotion states would be conducted in the
next stage.",,
85,459,"Xie, J., Xu, X., & Shu, L. (2018, May). WT feature based emotion recognition from multi-channel physiological signals with decision fusion. In 2018 First Asian Conference on Affective Computing and Intelligent Interaction (ACII Asia) (pp. 1-6). IEEE.",2018,categorical,x,5,"amusement, sadness, anger, disgust, fear",,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"The proposed framework has enhanced the performance of
emotion recognition. The reason might be as follows. First, as
human being has the multivariate characteristics, it is difficult
to accurately reflect the emotional changes by means of
specific peripheral physiological signal. ECG, EMG and SCL
might complement each other to reflect the emotional changes
well. Second, the most emotion-related physiological features
might be discovered by using feature selection. Furthermore,
the adverse interference between different physiological signals could be totally avoided with decision fusion. As for
future work, the following attempts are deserved. We will try
to extract the unseen features with deep neural networks to
form multi-level feature set in order to get rid of the problem
of weak generalization ability caused by using features in lowdimension space. On the other hand, other dataset could be
considered, such as DEAP and MAHNOB to evaluate and
optimize our framework. Last but not least, as feature selection
methods greatly affect the recognition results, we will try
more feature selection methods. And further experiments on
classifying extensive emotion states would be conducted in the
next stage.",,
86,460,"Ganapathy, N., & Swaminathan, R. (2020). Emotion Analysis Using Electrodermal Signals and Spiking Deep Belief Network. In Digital Personalized Health and Medicine (pp. 1269-1270). IOS Press.",2020,dimensional,x,2,"HA, LA",,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
86,461,"Ganapathy, N., & Swaminathan, R. (2020). Emotion Analysis Using Electrodermal Signals and Spiking Deep Belief Network. In Digital Personalized Health and Medicine (pp. 1269-1270). IOS Press.",2020,dimensional,x,2,"HV, LV",,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
87,462,"Yasemin, M., Sarıkaya, M. A., & Ince, G. (2019, July). Emotional state estimation using sensor fusion of EEG and EDA. In 2019 41st Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC) (pp. 5609-5612). IEEE.",2019,categorical,x,3,"funny, horror, weepy",,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
88,463,"Ghiasi, S., Greco, A., Barbieri, R., Scilingo, E. P., & Valenza, G. (2020). Assessing autonomic function from electrodermal activity and heart rate variability during cold-pressor test and emotional challenge. Scientific reports, 10(1), 1-13.",2020,dimensional,x,2,"pleasent, unpleasent",,X,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x," relevant information on the ANS activity can be retrieved from the superimposed phasic behavior of
HRV time-varying bispectral measures. Furthermore, the proposed new indices characterizing the cardiovascular
control through EDA and HRV seem to provide a more effective indicator of the sympathovagal balance then
traditional indices from HRV series onl",,
89,464,"Gümüslü, E., Erol Barkana, D., & Köse, H. (2020, October). Emotion recognition using EEG and physiological data for robot-assisted rehabilitation systems. In Companion Publication of the 2020 International Conference on Multimodal Interaction (pp. 379-387).",2020,dimensional,x,2,"pleasant, unpleasant",,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
89,465,"Gümüslü, E., Erol Barkana, D., & Köse, H. (2020, October). Emotion recognition using EEG and physiological data for robot-assisted rehabilitation systems. In Companion Publication of the 2020 International Conference on Multimodal Interaction (pp. 379-387).",2020,dimensional,x,2,"pleasant, neutral",,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
89,466,"Gümüslü, E., Erol Barkana, D., & Köse, H. (2020, October). Emotion recognition using EEG and physiological data for robot-assisted rehabilitation systems. In Companion Publication of the 2020 International Conference on Multimodal Interaction (pp. 379-387).",2020,dimensional,x,2,"neutral, unpleasant",,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
89,467,"Gümüslü, E., Erol Barkana, D., & Köse, H. (2020, October). Emotion recognition using EEG and physiological data for robot-assisted rehabilitation systems. In Companion Publication of the 2020 International Conference on Multimodal Interaction (pp. 379-387).",2020,dimensional,x,3,"pleasant, neutral, unpleasant",,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
90,468,"Katada, S., Okada, S., Hirano, Y., & Komatani, K. (2020, October). Is She Truly Enjoying the Conversation? Analysis of Physiological Signals toward Adaptive Dialogue Systems. In Proceedings of the 2020 International Conference on Multimodal Interaction (pp. 315-323).",2020,dimensional,x,2,"high enjoy, low enjoy",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,,
90,469,"Katada, S., Okada, S., Hirano, Y., & Komatani, K. (2020, October). Is She Truly Enjoying the Conversation? Analysis of Physiological Signals toward Adaptive Dialogue Systems. In Proceedings of the 2020 International Conference on Multimodal Interaction (pp. 315-323).",2020,dimensional,x,2,"high enjoy, low enjoy",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,x,,,,,,-,-,-,-,,
91,470,"Susanto, I. Y., Pan, T. Y., Chen, C. W., Hu, M. C., & Cheng, W. H. (2020, June). Emotion recognition from galvanic skin response signal based on deep hybrid neural networks. In Proceedings of the 2020 International Conference on Multimedia Retrieval (pp. 341-345).",2020,dimensional,x,2,"HA, LA",,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
91,471,"Susanto, I. Y., Pan, T. Y., Chen, C. W., Hu, M. C., & Cheng, W. H. (2020, June). Emotion recognition from galvanic skin response signal based on deep hybrid neural networks. In Proceedings of the 2020 International Conference on Multimedia Retrieval (pp. 341-345).",2020,dimensional,x,2,"HA, LA",,,,,,,,,,,,,,,,,,x,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
91,472,"Susanto, I. Y., Pan, T. Y., Chen, C. W., Hu, M. C., & Cheng, W. H. (2020, June). Emotion recognition from galvanic skin response signal based on deep hybrid neural networks. In Proceedings of the 2020 International Conference on Multimedia Retrieval (pp. 341-345).",2020,dimensional,x,2,"HA, LA",,,,,,,,,,,,,,,,,,x,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
91,473,"Susanto, I. Y., Pan, T. Y., Chen, C. W., Hu, M. C., & Cheng, W. H. (2020, June). Emotion recognition from galvanic skin response signal based on deep hybrid neural networks. In Proceedings of the 2020 International Conference on Multimedia Retrieval (pp. 341-345).",2020,dimensional,x,2,"HV, LV",,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
91,474,"Susanto, I. Y., Pan, T. Y., Chen, C. W., Hu, M. C., & Cheng, W. H. (2020, June). Emotion recognition from galvanic skin response signal based on deep hybrid neural networks. In Proceedings of the 2020 International Conference on Multimedia Retrieval (pp. 341-345).",2020,dimensional,x,2,"HV, LV",,,,,,,,,,,,,,,,,,x,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
91,475,"Susanto, I. Y., Pan, T. Y., Chen, C. W., Hu, M. C., & Cheng, W. H. (2020, June). Emotion recognition from galvanic skin response signal based on deep hybrid neural networks. In Proceedings of the 2020 International Conference on Multimedia Retrieval (pp. 341-345).",2020,dimensional,x,2,"HV, LV",,,,,,,,,,,,,,,,,,x,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
92,476,"Rahman, J. S., Hossain, M. Z., & Gedeon, T. (2019, December). Measuring Observers' EDA Responses to Emotional Videos. In Proceedings of the 31st Australian Conference on Human-Computer-Interaction (pp. 457-461).",2019,categorical,x,7,"surprise, sad, neutral, happy, fear, disgust, anger",,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"the initial analysis also shows some noticeable difference
of our data driven arousal model from our observers’ perspective, when compared to the (abstract) standard models
in the literature. The data-derived model with neutral as the
baseline is quite similar to the standard abstract model, with
the only changes being Happy and Sad changing sides as
Low/High arousal. Further analysis will be conducted and
evaluated to identify the reasons. Questions to be answered
are whether the dataset was biased, whether our 20 participants were somehow different from the expected population
reaction, or whether the abstract model is just incorrect. It
is also important to point out that EDA activity can vary
according to the difference in stimuli types, participants’ age,
gender etc [6]. Also the number of samples might be considered small, although experiments have shown that it is
reasonable [9]. Arguably, it makes more sense to use the overall average reaction to be the baseline between high and low
arousal, which spreads the emotional reactions over a wider
range. This differs more from the standard model.",,
93,477,"Rahim, A., Sagheer, A., Nadeem, K., Dar, M. N., Rahim, A., & Akram, U. (2019, October). Emotion Charting Using Real-time Monitoring of Physiological Signals. In 2019 International Conference on Robotics and Automation in Industry (ICRAI) (pp. 1-5). IEEE.",2020,categorical,x,7,"anger, disgust, fear, happy, neutral, sad, surprise",,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
93,478,"Rahim, A., Sagheer, A., Nadeem, K., Dar, M. N., Rahim, A., & Akram, U. (2019, October). Emotion Charting Using Real-time Monitoring of Physiological Signals. In 2019 International Conference on Robotics and Automation in Industry (ICRAI) (pp. 1-5). IEEE.",2020,categorical,x,7,"anger, disgust, fear, happy, neutral, sad, surprise",,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
94,479,"Yin, G., Sun, S., Zhang, H., Yu, D., Li, C., Zhang, K., & Zou, N. (2019, September). User Independent Emotion Recognition with Residual Signal-Image Network. In 2019 IEEE International Conference on Image Processing (ICIP) (pp. 3277-3281). IEEE.",2020,dimensional,x,2,"HV, LV",,,,,,,,,,,,,,,,,,X,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
94,480,"Yin, G., Sun, S., Zhang, H., Yu, D., Li, C., Zhang, K., & Zou, N. (2019, September). User Independent Emotion Recognition with Residual Signal-Image Network. In 2019 IEEE International Conference on Image Processing (ICIP) (pp. 3277-3281). IEEE.",2020,dimensional,x,2,"HA, LA",,,,,,,,,,,,,,,,,,X,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
95,481,"Yang, H. C., & Lee, C. C. (2019, September). Annotation matters: A comprehensive study on recognizing intended, self-reported, and observed emotion labels using physiology. In 2019 8th International Conference on Affective Computing and Intelligent Interaction (ACII) (pp. 1-7). IEEE.",2020,dimensional,x,2,"HA, LA",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Second, our error analysis suggests that
the types of stimuli could also be a key component in affecting
the physiological responses and potentially inducing the bias
in the self emotion assessment. Through better understanding
the relationship of these multiple perspectives of emotion
annotations and the measured physiological responses could
help enhance the robustness of affective recognition module
that can be integrated for many human behavior modeling
applications ",,
95,482,"Yang, H. C., & Lee, C. C. (2019, September). Annotation matters: A comprehensive study on recognizing intended, self-reported, and observed emotion labels using physiology. In 2019 8th International Conference on Affective Computing and Intelligent Interaction (ACII) (pp. 1-7). IEEE.",2020,dimensional,x,2,"HA, LA",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Second, our error analysis suggests that
the types of stimuli could also be a key component in affecting
the physiological responses and potentially inducing the bias
in the self emotion assessment. Through better understanding
the relationship of these multiple perspectives of emotion
annotations and the measured physiological responses could
help enhance the robustness of affective recognition module
that can be integrated for many human behavior modeling
applications ",,
95,483,"Yang, H. C., & Lee, C. C. (2019, September). Annotation matters: A comprehensive study on recognizing intended, self-reported, and observed emotion labels using physiology. In 2019 8th International Conference on Affective Computing and Intelligent Interaction (ACII) (pp. 1-7). IEEE.",2020,dimensional,x,2,"HA, LA",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Second, our error analysis suggests that
the types of stimuli could also be a key component in affecting
the physiological responses and potentially inducing the bias
in the self emotion assessment. Through better understanding
the relationship of these multiple perspectives of emotion
annotations and the measured physiological responses could
help enhance the robustness of affective recognition module
that can be integrated for many human behavior modeling
applications ",,
95,484,"Yang, H. C., & Lee, C. C. (2019, September). Annotation matters: A comprehensive study on recognizing intended, self-reported, and observed emotion labels using physiology. In 2019 8th International Conference on Affective Computing and Intelligent Interaction (ACII) (pp. 1-7). IEEE.",2020,dimensional,x,2,"HA, LA",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Second, our error analysis suggests that
the types of stimuli could also be a key component in affecting
the physiological responses and potentially inducing the bias
in the self emotion assessment. Through better understanding
the relationship of these multiple perspectives of emotion
annotations and the measured physiological responses could
help enhance the robustness of affective recognition module
that can be integrated for many human behavior modeling
applications ",,
95,485,"Yang, H. C., & Lee, C. C. (2019, September). Annotation matters: A comprehensive study on recognizing intended, self-reported, and observed emotion labels using physiology. In 2019 8th International Conference on Affective Computing and Intelligent Interaction (ACII) (pp. 1-7). IEEE.",2020,dimensional,x,2,"HA, LA",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Second, our error analysis suggests that
the types of stimuli could also be a key component in affecting
the physiological responses and potentially inducing the bias
in the self emotion assessment. Through better understanding
the relationship of these multiple perspectives of emotion
annotations and the measured physiological responses could
help enhance the robustness of affective recognition module
that can be integrated for many human behavior modeling
applications ",,
95,486,"Yang, H. C., & Lee, C. C. (2019, September). Annotation matters: A comprehensive study on recognizing intended, self-reported, and observed emotion labels using physiology. In 2019 8th International Conference on Affective Computing and Intelligent Interaction (ACII) (pp. 1-7). IEEE.",2020,dimensional,x,2,"HV, LV",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Second, our error analysis suggests that
the types of stimuli could also be a key component in affecting
the physiological responses and potentially inducing the bias
in the self emotion assessment. Through better understanding
the relationship of these multiple perspectives of emotion
annotations and the measured physiological responses could
help enhance the robustness of affective recognition module
that can be integrated for many human behavior modeling
applications ",,
95,487,"Yang, H. C., & Lee, C. C. (2019, September). Annotation matters: A comprehensive study on recognizing intended, self-reported, and observed emotion labels using physiology. In 2019 8th International Conference on Affective Computing and Intelligent Interaction (ACII) (pp. 1-7). IEEE.",2020,dimensional,x,2,"HV, LV",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Second, our error analysis suggests that
the types of stimuli could also be a key component in affecting
the physiological responses and potentially inducing the bias
in the self emotion assessment. Through better understanding
the relationship of these multiple perspectives of emotion
annotations and the measured physiological responses could
help enhance the robustness of affective recognition module
that can be integrated for many human behavior modeling
applications ",,
95,488,"Yang, H. C., & Lee, C. C. (2019, September). Annotation matters: A comprehensive study on recognizing intended, self-reported, and observed emotion labels using physiology. In 2019 8th International Conference on Affective Computing and Intelligent Interaction (ACII) (pp. 1-7). IEEE.",2020,dimensional,x,2,"HV, LV",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Second, our error analysis suggests that
the types of stimuli could also be a key component in affecting
the physiological responses and potentially inducing the bias
in the self emotion assessment. Through better understanding
the relationship of these multiple perspectives of emotion
annotations and the measured physiological responses could
help enhance the robustness of affective recognition module
that can be integrated for many human behavior modeling
applications ",,
95,489,"Yang, H. C., & Lee, C. C. (2019, September). Annotation matters: A comprehensive study on recognizing intended, self-reported, and observed emotion labels using physiology. In 2019 8th International Conference on Affective Computing and Intelligent Interaction (ACII) (pp. 1-7). IEEE.",2020,dimensional,x,2,"HV, LV",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Second, our error analysis suggests that
the types of stimuli could also be a key component in affecting
the physiological responses and potentially inducing the bias
in the self emotion assessment. Through better understanding
the relationship of these multiple perspectives of emotion
annotations and the measured physiological responses could
help enhance the robustness of affective recognition module
that can be integrated for many human behavior modeling
applications ",,
95,490,"Yang, H. C., & Lee, C. C. (2019, September). Annotation matters: A comprehensive study on recognizing intended, self-reported, and observed emotion labels using physiology. In 2019 8th International Conference on Affective Computing and Intelligent Interaction (ACII) (pp. 1-7). IEEE.",2020,dimensional,x,2,"HV, LV",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"Second, our error analysis suggests that
the types of stimuli could also be a key component in affecting
the physiological responses and potentially inducing the bias
in the self emotion assessment. Through better understanding
the relationship of these multiple perspectives of emotion
annotations and the measured physiological responses could
help enhance the robustness of affective recognition module
that can be integrated for many human behavior modeling
applications ",,
96,491,"Kołodziej, M., Tarnowski, P., Majkowski, A., & Rak, R. J. (2019). Electrodermal activity measurements for detection of emotional arousal. Bulletin of the Polish Academy of Sciences. Technical Sciences, 67(4).",2020,dimensional,x,2,"HA, LA",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,x,"The best features that were repeated
in the selection results were: MaxAmpPeak, VarAmpPeak,
StdAmpPeak, MaxAbsAmpPeak, VarSC, StdSC, ActivitySC,
MaxDeltaForward, MaxDeltaBack, KurtosisAmpPeak,
SkewnessAmpPeak. These features are related to the maximum
values, energy or statistical properties of the phasic component.
The results indicate that such features should be used in the
analysis of the EDA for the level of arousal recognition. Of
great importance is the quality of the recorded SC signals and
the pre-processing methods. In conjunction with the features
of other physiological signals (such as ECG, EEG, and EMG),
the proposed analysis can produce better results.",,
97,492,"Ganapathy, N., & Swaminathan, R. (2019). Emotion Recognition Using Electrodermal Activity Signals and Multiscale Deep Convolution Neural Network. Studies in health technology and informatics, 258, 140-140.",2020,dimensional,x,2,"HA, LA",,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
97,493,"Ganapathy, N., & Swaminathan, R. (2019). Emotion Recognition Using Electrodermal Activity Signals and Multiscale Deep Convolution Neural Network. Studies in health technology and informatics, 258, 140-140.",2020,dimensional,x,2,"HV, LV",,,,,,,,,,,,,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
98,494,"Subramanian, R., Wache, J., Abadi, M. K., Vieriu, R. L., Winkler, S., & Sebe, N. (2016). ASCERTAIN: Emotion and personality recognition using commercial sensors. IEEE Transactions on Affective Computing, 9(2), 147-160.",2018,dimensional,x,2,"HV, LV",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
98,495,"Subramanian, R., Wache, J., Abadi, M. K., Vieriu, R. L., Winkler, S., & Sebe, N. (2016). ASCERTAIN: Emotion and personality recognition using commercial sensors. IEEE Transactions on Affective Computing, 9(2), 147-160.",2018,dimensional,x,2,"HV, LV",,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
98,496,"Subramanian, R., Wache, J., Abadi, M. K., Vieriu, R. L., Winkler, S., & Sebe, N. (2016). ASCERTAIN: Emotion and personality recognition using commercial sensors. IEEE Transactions on Affective Computing, 9(2), 147-160.",2018,dimensional,x,2,"HA, LA",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
98,497,"Subramanian, R., Wache, J., Abadi, M. K., Vieriu, R. L., Winkler, S., & Sebe, N. (2016). ASCERTAIN: Emotion and personality recognition using commercial sensors. IEEE Transactions on Affective Computing, 9(2), 147-160.",2018,dimensional,x,2,"HA, LA",,,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,-,-,-,,
99,498,"Yun, H., Fortenbacher, A., Helbig, R., & Pinkwart, N. (2019). In Search of Learning Indicators: A Study on Sensor Data and IAPS Emotional Pictures. In CSEDU (2) (pp. 111-121).",2019,dimensional,x,4,"HAHV, HALV, LAHV, LALV",,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,,
99,499,"Yun, H., Fortenbacher, A., Helbig, R., & Pinkwart, N. (2019). In Search of Learning Indicators: A Study on Sensor Data and IAPS Emotional Pictures. In CSEDU (2) (pp. 111-121).",2019,dimensional,x,4,"HAHV, HALV, LAHV, LALV",,,,,,x,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,-,-,,